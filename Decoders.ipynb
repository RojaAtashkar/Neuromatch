{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Import Libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load the dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3092)\n",
      "(100, 1)\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "fmri_dataset = torch.load('data/fMRI_data/demo1/digits-fmri')\n",
    "# load the labels\n",
    "labels = torch.load('data/images/demo1/raw_imgs/digits-labels') - 1\n",
    "# print the shape\n",
    "print(fmri_dataset.shape)\n",
    "print(labels.shape)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total blocks : 100\n",
      "input fmri size : 3092\n"
     ]
    }
   ],
   "source": [
    "total_blocks = fmri_dataset.shape[0]\n",
    "fmri_size = fmri_dataset.shape[1]\n",
    "print('total blocks : '+str(total_blocks))\n",
    "print('input fmri size : '+str(fmri_size))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 10\n",
    "test_size = 10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# define the model\n",
    "\n",
    "\n",
    "class SemanticDecoder(nn.Module):\n",
    "  \"\"\"\n",
    "  Initialize MLP Network\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, actv, input_feature_num, hidden_unit_nums, output_feature_num):\n",
    "    \"\"\"\n",
    "    Initialize MLP Network parameters\n",
    "\n",
    "    Args:\n",
    "      actv: string\n",
    "        Activation function\n",
    "      input_feature_num: int\n",
    "        Number of input features\n",
    "      hidden_unit_nums: list\n",
    "        Number of units in the hidden layer\n",
    "      output_feature_num: int\n",
    "        Number of output features\n",
    "\n",
    "    Returns:\n",
    "      Nothing\n",
    "    \"\"\"\n",
    "    super(SemanticDecoder, self).__init__()\n",
    "    self.input_feature_num = input_feature_num # Save the input size for reshaping later\n",
    "    self.model = nn.Sequential() # Initialize layers of MLP\n",
    "\n",
    "    in_num = input_feature_num # Initialize the temporary input feature to each layer\n",
    "    for i in range(len(hidden_unit_nums)): # Loop over layers and create each one\n",
    "\n",
    "      out_num = hidden_unit_nums[i] # Assign the current layer hidden unit from list\n",
    "      layer = nn.Linear(in_num, out_num) # Use nn.Linear to define the layer\n",
    "\n",
    "      in_num = out_num # Assign next layer input using current layer output\n",
    "      self.model.add_module('Linear_%d'%i, layer) # Append layer to the model with a name\n",
    "\n",
    "      actv_layer = eval('nn.%s'%actv) # Assign activation function (eval allows us to instantiate object from string)\n",
    "      self.model.add_module('Activation_%d'%i, actv_layer) # Append activation to the model with a name\n",
    "\n",
    "    out_layer = nn.Linear(in_num, output_feature_num) # Create final layer\n",
    "    self.model.add_module('Output_Linear', out_layer) # Append the final layer\n",
    "\n",
    "    actv_layer = nn.Sigmoid()\n",
    "    self.model.add_module('LastActivation', actv_layer)\n",
    "\n",
    "  def forward(self, x):\n",
    "    \"\"\"\n",
    "    Simulate forward pass of MLP Network\n",
    "\n",
    "    Args:\n",
    "      x: torch.tensor\n",
    "        Input data\n",
    "\n",
    "    Returns:\n",
    "      logits: Instance of MLP\n",
    "        Forward pass of MLP\n",
    "    \"\"\"\n",
    "    # Reshape inputs to (batch_size, input_feature_num)\n",
    "    # Just in case the input vector is not 2D, like an image!\n",
    "    x = x.view(x.shape[0], -1)\n",
    "    logits = self.model(x) # Forward pass of MLP\n",
    "    return logits\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "hidden_layers_shape = [1024, 64]\n",
    "activation = 'Tanh()'\n",
    "semanticDecoder = SemanticDecoder(actv=activation, input_feature_num=fmri_size, hidden_unit_nums=hidden_layers_shape, output_feature_num=2)\n",
    "# y = net()\n",
    "# print(f'The output shape is {y.shape} for an input of shape {fmri_size.shape}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[0.4747, 0.4893],\n        [0.4757, 0.4898],\n        [0.4754, 0.4903],\n        [0.4726, 0.4909],\n        [0.4727, 0.4909],\n        [0.4739, 0.4905],\n        [0.4736, 0.4914],\n        [0.4747, 0.4914],\n        [0.4741, 0.4905],\n        [0.4734, 0.4909],\n        [0.4739, 0.4901],\n        [0.4732, 0.4909],\n        [0.4747, 0.4895],\n        [0.4757, 0.4905],\n        [0.4744, 0.4916],\n        [0.4756, 0.4914],\n        [0.4751, 0.4897],\n        [0.4745, 0.4893],\n        [0.4746, 0.4917],\n        [0.4728, 0.4918],\n        [0.4756, 0.4907],\n        [0.4747, 0.4920],\n        [0.4747, 0.4907],\n        [0.4742, 0.4913],\n        [0.4754, 0.4908],\n        [0.4732, 0.4917],\n        [0.4741, 0.4907],\n        [0.4736, 0.4911],\n        [0.4735, 0.4918],\n        [0.4745, 0.4902],\n        [0.4738, 0.4921],\n        [0.4735, 0.4912],\n        [0.4737, 0.4917],\n        [0.4734, 0.4910],\n        [0.4748, 0.4914],\n        [0.4743, 0.4904],\n        [0.4737, 0.4918],\n        [0.4733, 0.4915],\n        [0.4741, 0.4908],\n        [0.4737, 0.4911],\n        [0.4744, 0.4900],\n        [0.4747, 0.4904],\n        [0.4742, 0.4915],\n        [0.4741, 0.4923],\n        [0.4741, 0.4907],\n        [0.4754, 0.4909],\n        [0.4746, 0.4905],\n        [0.4757, 0.4906],\n        [0.4738, 0.4899],\n        [0.4745, 0.4903],\n        [0.4750, 0.4918],\n        [0.4733, 0.4927],\n        [0.4727, 0.4914],\n        [0.4731, 0.4916],\n        [0.4743, 0.4909],\n        [0.4742, 0.4911],\n        [0.4742, 0.4910],\n        [0.4741, 0.4904],\n        [0.4750, 0.4909],\n        [0.4749, 0.4909],\n        [0.4737, 0.4912],\n        [0.4746, 0.4904],\n        [0.4740, 0.4909],\n        [0.4731, 0.4920],\n        [0.4735, 0.4907],\n        [0.4730, 0.4904],\n        [0.4735, 0.4913],\n        [0.4748, 0.4912],\n        [0.4746, 0.4899],\n        [0.4744, 0.4900],\n        [0.4744, 0.4903],\n        [0.4751, 0.4907],\n        [0.4745, 0.4908],\n        [0.4749, 0.4910],\n        [0.4740, 0.4910],\n        [0.4749, 0.4897],\n        [0.4742, 0.4907],\n        [0.4739, 0.4903],\n        [0.4752, 0.4916],\n        [0.4740, 0.4912],\n        [0.4742, 0.4906],\n        [0.4740, 0.4919],\n        [0.4740, 0.4917],\n        [0.4736, 0.4916],\n        [0.4737, 0.4917],\n        [0.4738, 0.4921],\n        [0.4739, 0.4913],\n        [0.4728, 0.4928],\n        [0.4738, 0.4906],\n        [0.4732, 0.4917],\n        [0.4730, 0.4911],\n        [0.4738, 0.4907],\n        [0.4735, 0.4908],\n        [0.4744, 0.4921],\n        [0.4746, 0.4903],\n        [0.4746, 0.4903],\n        [0.4748, 0.4905],\n        [0.4736, 0.4914],\n        [0.4747, 0.4911],\n        [0.4743, 0.4900]], grad_fn=<SigmoidBackward0>)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda = True if torch.cuda.is_available() else False\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "fmri = torch.from_numpy(fmri_dataset)\n",
    "fmri = fmri.type(Tensor)\n",
    "print(type(fmri_dataset))\n",
    "semanticDecoder.forward(fmri)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# define the loss function\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# define optimizer\n",
    "# tuning the hyperparameters\n",
    "lr = 0.0002\n",
    "b1 = 0.5\n",
    "b2 = 0.999\n",
    "\n",
    "gamma_1 = 0.8\n",
    "step_1 = 10\n",
    "last_epoch_1 = -1\n",
    "optimizer = torch.optim.Adam(semanticDecoder.parameters(), lr=lr, betas=(b1, b2))\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_1, gamma=gamma_1, last_epoch=last_epoch_1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3092)\n"
     ]
    }
   ],
   "source": [
    "train_fmri = np.concatenate([fmri[0:45], fmri[50:95]])\n",
    "test_fmri = np.concatenate([fmri[45:50], fmri[95:100]])\n",
    "\n",
    "rand_id = np.random.randint(low=0, high=train_fmri.shape[0], size=train_fmri.shape[0])\n",
    "train_fmri = train_fmri[rand_id]\n",
    "fmri = np.concatenate([train_fmri, test_fmri])\n",
    "print(fmri.shape)\n",
    "\n",
    "train_labels = np.concatenate([labels[0:45], labels[50:95]])\n",
    "test_labels = np.concatenate([labels[45:50], labels[95:100]])\n",
    "train_labels = train_labels[rand_id]\n",
    "labels = np.concatenate([train_labels, test_labels])\n",
    "\n",
    "fmri = torch.from_numpy(fmri)\n",
    "fmri = fmri.type(Tensor)\n",
    "\n",
    "train_fmri = torch.from_numpy(train_fmri)\n",
    "train_labels = torch.from_numpy(train_labels)\n",
    "train_labels = train_labels.squeeze()\n",
    "train_fmri = train_fmri.type(Tensor)\n",
    "train_labels = train_labels.type(Tensor)\n",
    "\n",
    "test_fmri = torch.from_numpy(test_fmri)\n",
    "test_labels = torch.from_numpy(test_labels)\n",
    "test_labels = test_labels.squeeze()\n",
    "test_fmri = test_fmri.type(Tensor)\n",
    "test_labels = test_labels.type(Tensor)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "n_epochs = 100"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/100] [Batch 0] [loss: 0.695015] \n",
      "[Epoch 0/100] [Batch 1] [loss: 0.692108] \n",
      "[Epoch 0/100] [Batch 2] [loss: 0.681354] \n",
      "[Epoch 0/100] [Batch 3] [loss: 0.715985] \n",
      "[Epoch 0/100] [Batch 4] [loss: 0.699409] \n",
      "[Epoch 0/100] [Batch 5] [loss: 0.688866] \n",
      "[Epoch 0/100] [Batch 6] [loss: 0.680165] \n",
      "[Epoch 0/100] [Batch 7] [loss: 0.679078] \n",
      "[Epoch 0/100] [Batch 8] [loss: 0.684479] \n",
      "[Epoch 1/100] [Batch 0] [loss: 0.674496] \n",
      "[Epoch 1/100] [Batch 1] [loss: 0.668145] \n",
      "[Epoch 1/100] [Batch 2] [loss: 0.645291] \n",
      "[Epoch 1/100] [Batch 3] [loss: 0.749052] \n",
      "[Epoch 1/100] [Batch 4] [loss: 0.707656] \n",
      "[Epoch 1/100] [Batch 5] [loss: 0.679307] \n",
      "[Epoch 1/100] [Batch 6] [loss: 0.641026] \n",
      "[Epoch 1/100] [Batch 7] [loss: 0.647887] \n",
      "[Epoch 1/100] [Batch 8] [loss: 0.668223] \n",
      "[Epoch 2/100] [Batch 0] [loss: 0.650306] \n",
      "[Epoch 2/100] [Batch 1] [loss: 0.639435] \n",
      "[Epoch 2/100] [Batch 2] [loss: 0.602445] \n",
      "[Epoch 2/100] [Batch 3] [loss: 0.783117] \n",
      "[Epoch 2/100] [Batch 4] [loss: 0.713521] \n",
      "[Epoch 2/100] [Batch 5] [loss: 0.665416] \n",
      "[Epoch 2/100] [Batch 6] [loss: 0.597864] \n",
      "[Epoch 2/100] [Batch 7] [loss: 0.614910] \n",
      "[Epoch 2/100] [Batch 8] [loss: 0.649182] \n",
      "[Epoch 3/100] [Batch 0] [loss: 0.623870] \n",
      "[Epoch 3/100] [Batch 1] [loss: 0.612880] \n",
      "[Epoch 3/100] [Batch 2] [loss: 0.570031] \n",
      "[Epoch 3/100] [Batch 3] [loss: 0.782639] \n",
      "[Epoch 3/100] [Batch 4] [loss: 0.700058] \n",
      "[Epoch 3/100] [Batch 5] [loss: 0.643033] \n",
      "[Epoch 3/100] [Batch 6] [loss: 0.569396] \n",
      "[Epoch 3/100] [Batch 7] [loss: 0.589307] \n",
      "[Epoch 3/100] [Batch 8] [loss: 0.626772] \n",
      "[Epoch 4/100] [Batch 0] [loss: 0.592709] \n",
      "[Epoch 4/100] [Batch 1] [loss: 0.586252] \n",
      "[Epoch 4/100] [Batch 2] [loss: 0.548359] \n",
      "[Epoch 4/100] [Batch 3] [loss: 0.728937] \n",
      "[Epoch 4/100] [Batch 4] [loss: 0.652665] \n",
      "[Epoch 4/100] [Batch 5] [loss: 0.601876] \n",
      "[Epoch 4/100] [Batch 6] [loss: 0.556210] \n",
      "[Epoch 4/100] [Batch 7] [loss: 0.563904] \n",
      "[Epoch 4/100] [Batch 8] [loss: 0.592976] \n",
      "[Epoch 5/100] [Batch 0] [loss: 0.546976] \n",
      "[Epoch 5/100] [Batch 1] [loss: 0.547737] \n",
      "[Epoch 5/100] [Batch 2] [loss: 0.525048] \n",
      "[Epoch 5/100] [Batch 3] [loss: 0.624777] \n",
      "[Epoch 5/100] [Batch 4] [loss: 0.574022] \n",
      "[Epoch 5/100] [Batch 5] [loss: 0.543818] \n",
      "[Epoch 5/100] [Batch 6] [loss: 0.537792] \n",
      "[Epoch 5/100] [Batch 7] [loss: 0.526632] \n",
      "[Epoch 5/100] [Batch 8] [loss: 0.545429] \n",
      "[Epoch 6/100] [Batch 0] [loss: 0.490537] \n",
      "[Epoch 6/100] [Batch 1] [loss: 0.497821] \n",
      "[Epoch 6/100] [Batch 2] [loss: 0.489311] \n",
      "[Epoch 6/100] [Batch 3] [loss: 0.518923] \n",
      "[Epoch 6/100] [Batch 4] [loss: 0.501796] \n",
      "[Epoch 6/100] [Batch 5] [loss: 0.489091] \n",
      "[Epoch 6/100] [Batch 6] [loss: 0.490527] \n",
      "[Epoch 6/100] [Batch 7] [loss: 0.480238] \n",
      "[Epoch 6/100] [Batch 8] [loss: 0.497189] \n",
      "[Epoch 7/100] [Batch 0] [loss: 0.440754] \n",
      "[Epoch 7/100] [Batch 1] [loss: 0.452197] \n",
      "[Epoch 7/100] [Batch 2] [loss: 0.451215] \n",
      "[Epoch 7/100] [Batch 3] [loss: 0.442864] \n",
      "[Epoch 7/100] [Batch 4] [loss: 0.450901] \n",
      "[Epoch 7/100] [Batch 5] [loss: 0.445532] \n",
      "[Epoch 7/100] [Batch 6] [loss: 0.439338] \n",
      "[Epoch 7/100] [Batch 7] [loss: 0.440138] \n",
      "[Epoch 7/100] [Batch 8] [loss: 0.457678] \n",
      "[Epoch 8/100] [Batch 0] [loss: 0.404846] \n",
      "[Epoch 8/100] [Batch 1] [loss: 0.416718] \n",
      "[Epoch 8/100] [Batch 2] [loss: 0.421621] \n",
      "[Epoch 8/100] [Batch 3] [loss: 0.396970] \n",
      "[Epoch 8/100] [Batch 4] [loss: 0.416435] \n",
      "[Epoch 8/100] [Batch 5] [loss: 0.413567] \n",
      "[Epoch 8/100] [Batch 6] [loss: 0.402088] \n",
      "[Epoch 8/100] [Batch 7] [loss: 0.409544] \n",
      "[Epoch 8/100] [Batch 8] [loss: 0.426734] \n",
      "[Epoch 9/100] [Batch 0] [loss: 0.380471] \n",
      "[Epoch 9/100] [Batch 1] [loss: 0.390526] \n",
      "[Epoch 9/100] [Batch 2] [loss: 0.399971] \n",
      "[Epoch 9/100] [Batch 3] [loss: 0.371071] \n",
      "[Epoch 9/100] [Batch 4] [loss: 0.392642] \n",
      "[Epoch 9/100] [Batch 5] [loss: 0.390947] \n",
      "[Epoch 9/100] [Batch 6] [loss: 0.378348] \n",
      "[Epoch 9/100] [Batch 7] [loss: 0.386924] \n",
      "[Epoch 9/100] [Batch 8] [loss: 0.402485] \n",
      "[Epoch 10/100] [Batch 0] [loss: 0.364134] \n",
      "[Epoch 10/100] [Batch 1] [loss: 0.372174] \n",
      "[Epoch 10/100] [Batch 2] [loss: 0.383561] \n",
      "[Epoch 10/100] [Batch 3] [loss: 0.355763] \n",
      "[Epoch 10/100] [Batch 4] [loss: 0.376681] \n",
      "[Epoch 10/100] [Batch 5] [loss: 0.376161] \n",
      "[Epoch 10/100] [Batch 6] [loss: 0.364255] \n",
      "[Epoch 10/100] [Batch 7] [loss: 0.372500] \n",
      "[Epoch 10/100] [Batch 8] [loss: 0.385758] \n",
      "[Epoch 11/100] [Batch 0] [loss: 0.355010] \n",
      "[Epoch 11/100] [Batch 1] [loss: 0.361501] \n",
      "[Epoch 11/100] [Batch 2] [loss: 0.372527] \n",
      "[Epoch 11/100] [Batch 3] [loss: 0.348152] \n",
      "[Epoch 11/100] [Batch 4] [loss: 0.366642] \n",
      "[Epoch 11/100] [Batch 5] [loss: 0.366266] \n",
      "[Epoch 11/100] [Batch 6] [loss: 0.355877] \n",
      "[Epoch 11/100] [Batch 7] [loss: 0.362560] \n",
      "[Epoch 11/100] [Batch 8] [loss: 0.373524] \n",
      "[Epoch 12/100] [Batch 0] [loss: 0.348210] \n",
      "[Epoch 12/100] [Batch 1] [loss: 0.353474] \n",
      "[Epoch 12/100] [Batch 2] [loss: 0.363584] \n",
      "[Epoch 12/100] [Batch 3] [loss: 0.342629] \n",
      "[Epoch 12/100] [Batch 4] [loss: 0.358758] \n",
      "[Epoch 12/100] [Batch 5] [loss: 0.358511] \n",
      "[Epoch 12/100] [Batch 6] [loss: 0.349525] \n",
      "[Epoch 12/100] [Batch 7] [loss: 0.354913] \n",
      "[Epoch 12/100] [Batch 8] [loss: 0.363747] \n",
      "[Epoch 13/100] [Batch 0] [loss: 0.343043] \n",
      "[Epoch 13/100] [Batch 1] [loss: 0.347381] \n",
      "[Epoch 13/100] [Batch 2] [loss: 0.356277] \n",
      "[Epoch 13/100] [Batch 3] [loss: 0.338509] \n",
      "[Epoch 13/100] [Batch 4] [loss: 0.352482] \n",
      "[Epoch 13/100] [Batch 5] [loss: 0.352369] \n",
      "[Epoch 13/100] [Batch 6] [loss: 0.344606] \n",
      "[Epoch 13/100] [Batch 7] [loss: 0.348966] \n",
      "[Epoch 13/100] [Batch 8] [loss: 0.356029] \n",
      "[Epoch 14/100] [Batch 0] [loss: 0.339044] \n",
      "[Epoch 14/100] [Batch 1] [loss: 0.342676] \n",
      "[Epoch 14/100] [Batch 2] [loss: 0.350377] \n",
      "[Epoch 14/100] [Batch 3] [loss: 0.335333] \n",
      "[Epoch 14/100] [Batch 4] [loss: 0.347429] \n",
      "[Epoch 14/100] [Batch 5] [loss: 0.347447] \n",
      "[Epoch 14/100] [Batch 6] [loss: 0.340718] \n",
      "[Epoch 14/100] [Batch 7] [loss: 0.344276] \n",
      "[Epoch 14/100] [Batch 8] [loss: 0.349961] \n",
      "[Epoch 15/100] [Batch 0] [loss: 0.335891] \n",
      "[Epoch 15/100] [Batch 1] [loss: 0.338973] \n",
      "[Epoch 15/100] [Batch 2] [loss: 0.345629] \n",
      "[Epoch 15/100] [Batch 3] [loss: 0.332816] \n",
      "[Epoch 15/100] [Batch 4] [loss: 0.343319] \n",
      "[Epoch 15/100] [Batch 5] [loss: 0.343455] \n",
      "[Epoch 15/100] [Batch 6] [loss: 0.337587] \n",
      "[Epoch 15/100] [Batch 7] [loss: 0.340522] \n",
      "[Epoch 15/100] [Batch 8] [loss: 0.345163] \n",
      "[Epoch 16/100] [Batch 0] [loss: 0.333360] \n",
      "[Epoch 16/100] [Batch 1] [loss: 0.336006] \n",
      "[Epoch 16/100] [Batch 2] [loss: 0.341789] \n",
      "[Epoch 16/100] [Batch 3] [loss: 0.330774] \n",
      "[Epoch 16/100] [Batch 4] [loss: 0.339942] \n",
      "[Epoch 16/100] [Batch 5] [loss: 0.340178] \n",
      "[Epoch 16/100] [Batch 6] [loss: 0.335025] \n",
      "[Epoch 16/100] [Batch 7] [loss: 0.337473] \n",
      "[Epoch 16/100] [Batch 8] [loss: 0.341327] \n",
      "[Epoch 17/100] [Batch 0] [loss: 0.331294] \n",
      "[Epoch 17/100] [Batch 1] [loss: 0.333588] \n",
      "[Epoch 17/100] [Batch 2] [loss: 0.338654] \n",
      "[Epoch 17/100] [Batch 3] [loss: 0.329089] \n",
      "[Epoch 17/100] [Batch 4] [loss: 0.337141] \n",
      "[Epoch 17/100] [Batch 5] [loss: 0.337456] \n",
      "[Epoch 17/100] [Batch 6] [loss: 0.332900] \n",
      "[Epoch 17/100] [Batch 7] [loss: 0.334964] \n",
      "[Epoch 17/100] [Batch 8] [loss: 0.338217] \n",
      "[Epoch 18/100] [Batch 0] [loss: 0.329583] \n",
      "[Epoch 18/100] [Batch 1] [loss: 0.331588] \n",
      "[Epoch 18/100] [Batch 2] [loss: 0.336063] \n",
      "[Epoch 18/100] [Batch 3] [loss: 0.327678] \n",
      "[Epoch 18/100] [Batch 4] [loss: 0.334795] \n",
      "[Epoch 18/100] [Batch 5] [loss: 0.335169] \n",
      "[Epoch 18/100] [Batch 6] [loss: 0.331114] \n",
      "[Epoch 18/100] [Batch 7] [loss: 0.332872] \n",
      "[Epoch 18/100] [Batch 8] [loss: 0.335661] \n",
      "[Epoch 19/100] [Batch 0] [loss: 0.328146] \n",
      "[Epoch 19/100] [Batch 1] [loss: 0.329913] \n",
      "[Epoch 19/100] [Batch 2] [loss: 0.333897] \n",
      "[Epoch 19/100] [Batch 3] [loss: 0.326480] \n",
      "[Epoch 19/100] [Batch 4] [loss: 0.332812] \n",
      "[Epoch 19/100] [Batch 5] [loss: 0.333229] \n",
      "[Epoch 19/100] [Batch 6] [loss: 0.329595] \n",
      "[Epoch 19/100] [Batch 7] [loss: 0.331109] \n",
      "[Epoch 19/100] [Batch 8] [loss: 0.333532] \n",
      "[Epoch 20/100] [Batch 0] [loss: 0.326924] \n",
      "[Epoch 20/100] [Batch 1] [loss: 0.328519] \n",
      "[Epoch 20/100] [Batch 2] [loss: 0.332070] \n",
      "[Epoch 20/100] [Batch 3] [loss: 0.325483] \n",
      "[Epoch 20/100] [Batch 4] [loss: 0.331222] \n",
      "[Epoch 20/100] [Batch 5] [loss: 0.331710] \n",
      "[Epoch 20/100] [Batch 6] [loss: 0.328418] \n",
      "[Epoch 20/100] [Batch 7] [loss: 0.329795] \n",
      "[Epoch 20/100] [Batch 8] [loss: 0.331954] \n",
      "[Epoch 21/100] [Batch 0] [loss: 0.326075] \n",
      "[Epoch 21/100] [Batch 1] [loss: 0.327529] \n",
      "[Epoch 21/100] [Batch 2] [loss: 0.330805] \n",
      "[Epoch 21/100] [Batch 3] [loss: 0.324762] \n",
      "[Epoch 21/100] [Batch 4] [loss: 0.330032] \n",
      "[Epoch 21/100] [Batch 5] [loss: 0.330530] \n",
      "[Epoch 21/100] [Batch 6] [loss: 0.327487] \n",
      "[Epoch 21/100] [Batch 7] [loss: 0.328724] \n",
      "[Epoch 21/100] [Batch 8] [loss: 0.330692] \n",
      "[Epoch 22/100] [Batch 0] [loss: 0.325315] \n",
      "[Epoch 22/100] [Batch 1] [loss: 0.326645] \n",
      "[Epoch 22/100] [Batch 2] [loss: 0.329678] \n",
      "[Epoch 22/100] [Batch 3] [loss: 0.324110] \n",
      "[Epoch 22/100] [Batch 4] [loss: 0.328968] \n",
      "[Epoch 22/100] [Batch 5] [loss: 0.329470] \n",
      "[Epoch 22/100] [Batch 6] [loss: 0.326651] \n",
      "[Epoch 22/100] [Batch 7] [loss: 0.327766] \n",
      "[Epoch 22/100] [Batch 8] [loss: 0.329567] \n",
      "[Epoch 23/100] [Batch 0] [loss: 0.324631] \n",
      "[Epoch 23/100] [Batch 1] [loss: 0.325851] \n",
      "[Epoch 23/100] [Batch 2] [loss: 0.328669] \n",
      "[Epoch 23/100] [Batch 3] [loss: 0.323521] \n",
      "[Epoch 23/100] [Batch 4] [loss: 0.328011] \n",
      "[Epoch 23/100] [Batch 5] [loss: 0.328515] \n",
      "[Epoch 23/100] [Batch 6] [loss: 0.325897] \n",
      "[Epoch 23/100] [Batch 7] [loss: 0.326905] \n",
      "[Epoch 23/100] [Batch 8] [loss: 0.328560] \n",
      "[Epoch 24/100] [Batch 0] [loss: 0.324012] \n",
      "[Epoch 24/100] [Batch 1] [loss: 0.325137] \n",
      "[Epoch 24/100] [Batch 2] [loss: 0.327760] \n",
      "[Epoch 24/100] [Batch 3] [loss: 0.322986] \n",
      "[Epoch 24/100] [Batch 4] [loss: 0.327148] \n",
      "[Epoch 24/100] [Batch 5] [loss: 0.327651] \n",
      "[Epoch 24/100] [Batch 6] [loss: 0.325212] \n",
      "[Epoch 24/100] [Batch 7] [loss: 0.326128] \n",
      "[Epoch 24/100] [Batch 8] [loss: 0.327656] \n",
      "[Epoch 25/100] [Batch 0] [loss: 0.323451] \n",
      "[Epoch 25/100] [Batch 1] [loss: 0.324490] \n",
      "[Epoch 25/100] [Batch 2] [loss: 0.326938] \n",
      "[Epoch 25/100] [Batch 3] [loss: 0.322498] \n",
      "[Epoch 25/100] [Batch 4] [loss: 0.326367] \n",
      "[Epoch 25/100] [Batch 5] [loss: 0.326866] \n",
      "[Epoch 25/100] [Batch 6] [loss: 0.324590] \n",
      "[Epoch 25/100] [Batch 7] [loss: 0.325425] \n",
      "[Epoch 25/100] [Batch 8] [loss: 0.326840] \n",
      "[Epoch 26/100] [Batch 0] [loss: 0.322940] \n",
      "[Epoch 26/100] [Batch 1] [loss: 0.323902] \n",
      "[Epoch 26/100] [Batch 2] [loss: 0.326193] \n",
      "[Epoch 26/100] [Batch 3] [loss: 0.322053] \n",
      "[Epoch 26/100] [Batch 4] [loss: 0.325658] \n",
      "[Epoch 26/100] [Batch 5] [loss: 0.326151] \n",
      "[Epoch 26/100] [Batch 6] [loss: 0.324021] \n",
      "[Epoch 26/100] [Batch 7] [loss: 0.324785] \n",
      "[Epoch 26/100] [Batch 8] [loss: 0.326100] \n",
      "[Epoch 27/100] [Batch 0] [loss: 0.322473] \n",
      "[Epoch 27/100] [Batch 1] [loss: 0.323366] \n",
      "[Epoch 27/100] [Batch 2] [loss: 0.325515] \n",
      "[Epoch 27/100] [Batch 3] [loss: 0.321644] \n",
      "[Epoch 27/100] [Batch 4] [loss: 0.325011] \n",
      "[Epoch 27/100] [Batch 5] [loss: 0.325497] \n",
      "[Epoch 27/100] [Batch 6] [loss: 0.323501] \n",
      "[Epoch 27/100] [Batch 7] [loss: 0.324202] \n",
      "[Epoch 27/100] [Batch 8] [loss: 0.325427] \n",
      "[Epoch 28/100] [Batch 0] [loss: 0.322045] \n",
      "[Epoch 28/100] [Batch 1] [loss: 0.322876] \n",
      "[Epoch 28/100] [Batch 2] [loss: 0.324895] \n",
      "[Epoch 28/100] [Batch 3] [loss: 0.321268] \n",
      "[Epoch 28/100] [Batch 4] [loss: 0.324419] \n",
      "[Epoch 28/100] [Batch 5] [loss: 0.324897] \n",
      "[Epoch 28/100] [Batch 6] [loss: 0.323022] \n",
      "[Epoch 28/100] [Batch 7] [loss: 0.323667] \n",
      "[Epoch 28/100] [Batch 8] [loss: 0.324813] \n",
      "[Epoch 29/100] [Batch 0] [loss: 0.321650] \n",
      "[Epoch 29/100] [Batch 1] [loss: 0.322426] \n",
      "[Epoch 29/100] [Batch 2] [loss: 0.324327] \n",
      "[Epoch 29/100] [Batch 3] [loss: 0.320921] \n",
      "[Epoch 29/100] [Batch 4] [loss: 0.323877] \n",
      "[Epoch 29/100] [Batch 5] [loss: 0.324346] \n",
      "[Epoch 29/100] [Batch 6] [loss: 0.322581] \n",
      "[Epoch 29/100] [Batch 7] [loss: 0.323177] \n",
      "[Epoch 29/100] [Batch 8] [loss: 0.324250] \n",
      "[Epoch 30/100] [Batch 0] [loss: 0.321286] \n",
      "[Epoch 30/100] [Batch 1] [loss: 0.322020] \n",
      "[Epoch 30/100] [Batch 2] [loss: 0.323812] \n",
      "[Epoch 30/100] [Batch 3] [loss: 0.320611] \n",
      "[Epoch 30/100] [Batch 4] [loss: 0.323410] \n",
      "[Epoch 30/100] [Batch 5] [loss: 0.323885] \n",
      "[Epoch 30/100] [Batch 6] [loss: 0.322213] \n",
      "[Epoch 30/100] [Batch 7] [loss: 0.322785] \n",
      "[Epoch 30/100] [Batch 8] [loss: 0.323805] \n",
      "[Epoch 31/100] [Batch 0] [loss: 0.321015] \n",
      "[Epoch 31/100] [Batch 1] [loss: 0.321711] \n",
      "[Epoch 31/100] [Batch 2] [loss: 0.323425] \n",
      "[Epoch 31/100] [Batch 3] [loss: 0.320370] \n",
      "[Epoch 31/100] [Batch 4] [loss: 0.323037] \n",
      "[Epoch 31/100] [Batch 5] [loss: 0.323503] \n",
      "[Epoch 31/100] [Batch 6] [loss: 0.321906] \n",
      "[Epoch 31/100] [Batch 7] [loss: 0.322444] \n",
      "[Epoch 31/100] [Batch 8] [loss: 0.323416] \n",
      "[Epoch 32/100] [Batch 0] [loss: 0.320759] \n",
      "[Epoch 32/100] [Batch 1] [loss: 0.321420] \n",
      "[Epoch 32/100] [Batch 2] [loss: 0.323060] \n",
      "[Epoch 32/100] [Batch 3] [loss: 0.320142] \n",
      "[Epoch 32/100] [Batch 4] [loss: 0.322686] \n",
      "[Epoch 32/100] [Batch 5] [loss: 0.323143] \n",
      "[Epoch 32/100] [Batch 6] [loss: 0.321616] \n",
      "[Epoch 32/100] [Batch 7] [loss: 0.322123] \n",
      "[Epoch 32/100] [Batch 8] [loss: 0.323051] \n",
      "[Epoch 33/100] [Batch 0] [loss: 0.320516] \n",
      "[Epoch 33/100] [Batch 1] [loss: 0.321145] \n",
      "[Epoch 33/100] [Batch 2] [loss: 0.322715] \n",
      "[Epoch 33/100] [Batch 3] [loss: 0.319926] \n",
      "[Epoch 33/100] [Batch 4] [loss: 0.322355] \n",
      "[Epoch 33/100] [Batch 5] [loss: 0.322803] \n",
      "[Epoch 33/100] [Batch 6] [loss: 0.321342] \n",
      "[Epoch 33/100] [Batch 7] [loss: 0.321820] \n",
      "[Epoch 33/100] [Batch 8] [loss: 0.322706] \n",
      "[Epoch 34/100] [Batch 0] [loss: 0.320287] \n",
      "[Epoch 34/100] [Batch 1] [loss: 0.320885] \n",
      "[Epoch 34/100] [Batch 2] [loss: 0.322390] \n",
      "[Epoch 34/100] [Batch 3] [loss: 0.319722] \n",
      "[Epoch 34/100] [Batch 4] [loss: 0.322042] \n",
      "[Epoch 34/100] [Batch 5] [loss: 0.322481] \n",
      "[Epoch 34/100] [Batch 6] [loss: 0.321083] \n",
      "[Epoch 34/100] [Batch 7] [loss: 0.321534] \n",
      "[Epoch 34/100] [Batch 8] [loss: 0.322381] \n",
      "[Epoch 35/100] [Batch 0] [loss: 0.320069] \n",
      "[Epoch 35/100] [Batch 1] [loss: 0.320640] \n",
      "[Epoch 35/100] [Batch 2] [loss: 0.322083] \n",
      "[Epoch 35/100] [Batch 3] [loss: 0.319528] \n",
      "[Epoch 35/100] [Batch 4] [loss: 0.321747] \n",
      "[Epoch 35/100] [Batch 5] [loss: 0.322176] \n",
      "[Epoch 35/100] [Batch 6] [loss: 0.320836] \n",
      "[Epoch 35/100] [Batch 7] [loss: 0.321264] \n",
      "[Epoch 35/100] [Batch 8] [loss: 0.322074] \n",
      "[Epoch 36/100] [Batch 0] [loss: 0.319863] \n",
      "[Epoch 36/100] [Batch 1] [loss: 0.320407] \n",
      "[Epoch 36/100] [Batch 2] [loss: 0.321792] \n",
      "[Epoch 36/100] [Batch 3] [loss: 0.319343] \n",
      "[Epoch 36/100] [Batch 4] [loss: 0.321467] \n",
      "[Epoch 36/100] [Batch 5] [loss: 0.321888] \n",
      "[Epoch 36/100] [Batch 6] [loss: 0.320603] \n",
      "[Epoch 36/100] [Batch 7] [loss: 0.321007] \n",
      "[Epoch 36/100] [Batch 8] [loss: 0.321783] \n",
      "[Epoch 37/100] [Batch 0] [loss: 0.319666] \n",
      "[Epoch 37/100] [Batch 1] [loss: 0.320187] \n",
      "[Epoch 37/100] [Batch 2] [loss: 0.321517] \n",
      "[Epoch 37/100] [Batch 3] [loss: 0.319167] \n",
      "[Epoch 37/100] [Batch 4] [loss: 0.321203] \n",
      "[Epoch 37/100] [Batch 5] [loss: 0.321614] \n",
      "[Epoch 37/100] [Batch 6] [loss: 0.320381] \n",
      "[Epoch 37/100] [Batch 7] [loss: 0.320764] \n",
      "[Epoch 37/100] [Batch 8] [loss: 0.321508] \n",
      "[Epoch 38/100] [Batch 0] [loss: 0.319480] \n",
      "[Epoch 38/100] [Batch 1] [loss: 0.319977] \n",
      "[Epoch 38/100] [Batch 2] [loss: 0.321256] \n",
      "[Epoch 38/100] [Batch 3] [loss: 0.319000] \n",
      "[Epoch 38/100] [Batch 4] [loss: 0.320952] \n",
      "[Epoch 38/100] [Batch 5] [loss: 0.321354] \n",
      "[Epoch 38/100] [Batch 6] [loss: 0.320170] \n",
      "[Epoch 38/100] [Batch 7] [loss: 0.320534] \n",
      "[Epoch 38/100] [Batch 8] [loss: 0.321247] \n",
      "[Epoch 39/100] [Batch 0] [loss: 0.319302] \n",
      "[Epoch 39/100] [Batch 1] [loss: 0.319778] \n",
      "[Epoch 39/100] [Batch 2] [loss: 0.321008] \n",
      "[Epoch 39/100] [Batch 3] [loss: 0.318841] \n",
      "[Epoch 39/100] [Batch 4] [loss: 0.320713] \n",
      "[Epoch 39/100] [Batch 5] [loss: 0.321108] \n",
      "[Epoch 39/100] [Batch 6] [loss: 0.319969] \n",
      "[Epoch 39/100] [Batch 7] [loss: 0.320315] \n",
      "[Epoch 39/100] [Batch 8] [loss: 0.321000] \n",
      "[Epoch 40/100] [Batch 0] [loss: 0.319133] \n",
      "[Epoch 40/100] [Batch 1] [loss: 0.319592] \n",
      "[Epoch 40/100] [Batch 2] [loss: 0.320778] \n",
      "[Epoch 40/100] [Batch 3] [loss: 0.318694] \n",
      "[Epoch 40/100] [Batch 4] [loss: 0.320502] \n",
      "[Epoch 40/100] [Batch 5] [loss: 0.320895] \n",
      "[Epoch 40/100] [Batch 6] [loss: 0.319796] \n",
      "[Epoch 40/100] [Batch 7] [loss: 0.320135] \n",
      "[Epoch 40/100] [Batch 8] [loss: 0.320799] \n",
      "[Epoch 41/100] [Batch 0] [loss: 0.319003] \n",
      "[Epoch 41/100] [Batch 1] [loss: 0.319447] \n",
      "[Epoch 41/100] [Batch 2] [loss: 0.320598] \n",
      "[Epoch 41/100] [Batch 3] [loss: 0.318577] \n",
      "[Epoch 41/100] [Batch 4] [loss: 0.320329] \n",
      "[Epoch 41/100] [Batch 5] [loss: 0.320714] \n",
      "[Epoch 41/100] [Batch 6] [loss: 0.319649] \n",
      "[Epoch 41/100] [Batch 7] [loss: 0.319974] \n",
      "[Epoch 41/100] [Batch 8] [loss: 0.320618] \n",
      "[Epoch 42/100] [Batch 0] [loss: 0.318878] \n",
      "[Epoch 42/100] [Batch 1] [loss: 0.319307] \n",
      "[Epoch 42/100] [Batch 2] [loss: 0.320424] \n",
      "[Epoch 42/100] [Batch 3] [loss: 0.318464] \n",
      "[Epoch 42/100] [Batch 4] [loss: 0.320161] \n",
      "[Epoch 42/100] [Batch 5] [loss: 0.320540] \n",
      "[Epoch 42/100] [Batch 6] [loss: 0.319506] \n",
      "[Epoch 42/100] [Batch 7] [loss: 0.319819] \n",
      "[Epoch 42/100] [Batch 8] [loss: 0.320444] \n",
      "[Epoch 43/100] [Batch 0] [loss: 0.318757] \n",
      "[Epoch 43/100] [Batch 1] [loss: 0.319172] \n",
      "[Epoch 43/100] [Batch 2] [loss: 0.320257] \n",
      "[Epoch 43/100] [Batch 3] [loss: 0.318355] \n",
      "[Epoch 43/100] [Batch 4] [loss: 0.320000] \n",
      "[Epoch 43/100] [Batch 5] [loss: 0.320372] \n",
      "[Epoch 43/100] [Batch 6] [loss: 0.319369] \n",
      "[Epoch 43/100] [Batch 7] [loss: 0.319670] \n",
      "[Epoch 43/100] [Batch 8] [loss: 0.320275] \n",
      "[Epoch 44/100] [Batch 0] [loss: 0.318640] \n",
      "[Epoch 44/100] [Batch 1] [loss: 0.319042] \n",
      "[Epoch 44/100] [Batch 2] [loss: 0.320096] \n",
      "[Epoch 44/100] [Batch 3] [loss: 0.318249] \n",
      "[Epoch 44/100] [Batch 4] [loss: 0.319844] \n",
      "[Epoch 44/100] [Batch 5] [loss: 0.320210] \n",
      "[Epoch 44/100] [Batch 6] [loss: 0.319236] \n",
      "[Epoch 44/100] [Batch 7] [loss: 0.319525] \n",
      "[Epoch 44/100] [Batch 8] [loss: 0.320113] \n",
      "[Epoch 45/100] [Batch 0] [loss: 0.318527] \n",
      "[Epoch 45/100] [Batch 1] [loss: 0.318916] \n",
      "[Epoch 45/100] [Batch 2] [loss: 0.319940] \n",
      "[Epoch 45/100] [Batch 3] [loss: 0.318147] \n",
      "[Epoch 45/100] [Batch 4] [loss: 0.319694] \n",
      "[Epoch 45/100] [Batch 5] [loss: 0.320053] \n",
      "[Epoch 45/100] [Batch 6] [loss: 0.319107] \n",
      "[Epoch 45/100] [Batch 7] [loss: 0.319386] \n",
      "[Epoch 45/100] [Batch 8] [loss: 0.319957] \n",
      "[Epoch 46/100] [Batch 0] [loss: 0.318418] \n",
      "[Epoch 46/100] [Batch 1] [loss: 0.318794] \n",
      "[Epoch 46/100] [Batch 2] [loss: 0.319790] \n",
      "[Epoch 46/100] [Batch 3] [loss: 0.318048] \n",
      "[Epoch 46/100] [Batch 4] [loss: 0.319549] \n",
      "[Epoch 46/100] [Batch 5] [loss: 0.319901] \n",
      "[Epoch 46/100] [Batch 6] [loss: 0.318983] \n",
      "[Epoch 46/100] [Batch 7] [loss: 0.319252] \n",
      "[Epoch 46/100] [Batch 8] [loss: 0.319806] \n",
      "[Epoch 47/100] [Batch 0] [loss: 0.318312] \n",
      "[Epoch 47/100] [Batch 1] [loss: 0.318677] \n",
      "[Epoch 47/100] [Batch 2] [loss: 0.319645] \n",
      "[Epoch 47/100] [Batch 3] [loss: 0.317952] \n",
      "[Epoch 47/100] [Batch 4] [loss: 0.319410] \n",
      "[Epoch 47/100] [Batch 5] [loss: 0.319755] \n",
      "[Epoch 47/100] [Batch 6] [loss: 0.318863] \n",
      "[Epoch 47/100] [Batch 7] [loss: 0.319122] \n",
      "[Epoch 47/100] [Batch 8] [loss: 0.319660] \n",
      "[Epoch 48/100] [Batch 0] [loss: 0.318209] \n",
      "[Epoch 48/100] [Batch 1] [loss: 0.318563] \n",
      "[Epoch 48/100] [Batch 2] [loss: 0.319505] \n",
      "[Epoch 48/100] [Batch 3] [loss: 0.317859] \n",
      "[Epoch 48/100] [Batch 4] [loss: 0.319275] \n",
      "[Epoch 48/100] [Batch 5] [loss: 0.319614] \n",
      "[Epoch 48/100] [Batch 6] [loss: 0.318747] \n",
      "[Epoch 48/100] [Batch 7] [loss: 0.318996] \n",
      "[Epoch 48/100] [Batch 8] [loss: 0.319519] \n",
      "[Epoch 49/100] [Batch 0] [loss: 0.318110] \n",
      "[Epoch 49/100] [Batch 1] [loss: 0.318453] \n",
      "[Epoch 49/100] [Batch 2] [loss: 0.319369] \n",
      "[Epoch 49/100] [Batch 3] [loss: 0.317769] \n",
      "[Epoch 49/100] [Batch 4] [loss: 0.319144] \n",
      "[Epoch 49/100] [Batch 5] [loss: 0.319477] \n",
      "[Epoch 49/100] [Batch 6] [loss: 0.318634] \n",
      "[Epoch 49/100] [Batch 7] [loss: 0.318875] \n",
      "[Epoch 49/100] [Batch 8] [loss: 0.319383] \n",
      "[Epoch 50/100] [Batch 0] [loss: 0.318014] \n",
      "[Epoch 50/100] [Batch 1] [loss: 0.318349] \n",
      "[Epoch 50/100] [Batch 2] [loss: 0.319241] \n",
      "[Epoch 50/100] [Batch 3] [loss: 0.317685] \n",
      "[Epoch 50/100] [Batch 4] [loss: 0.319027] \n",
      "[Epoch 50/100] [Batch 5] [loss: 0.319358] \n",
      "[Epoch 50/100] [Batch 6] [loss: 0.318536] \n",
      "[Epoch 50/100] [Batch 7] [loss: 0.318774] \n",
      "[Epoch 50/100] [Batch 8] [loss: 0.319271] \n",
      "[Epoch 51/100] [Batch 0] [loss: 0.317939] \n",
      "[Epoch 51/100] [Batch 1] [loss: 0.318266] \n",
      "[Epoch 51/100] [Batch 2] [loss: 0.319140] \n",
      "[Epoch 51/100] [Batch 3] [loss: 0.317617] \n",
      "[Epoch 51/100] [Batch 4] [loss: 0.318929] \n",
      "[Epoch 51/100] [Batch 5] [loss: 0.319255] \n",
      "[Epoch 51/100] [Batch 6] [loss: 0.318451] \n",
      "[Epoch 51/100] [Batch 7] [loss: 0.318682] \n",
      "[Epoch 51/100] [Batch 8] [loss: 0.319169] \n",
      "[Epoch 52/100] [Batch 0] [loss: 0.317866] \n",
      "[Epoch 52/100] [Batch 1] [loss: 0.318185] \n",
      "[Epoch 52/100] [Batch 2] [loss: 0.319041] \n",
      "[Epoch 52/100] [Batch 3] [loss: 0.317550] \n",
      "[Epoch 52/100] [Batch 4] [loss: 0.318833] \n",
      "[Epoch 52/100] [Batch 5] [loss: 0.319154] \n",
      "[Epoch 52/100] [Batch 6] [loss: 0.318368] \n",
      "[Epoch 52/100] [Batch 7] [loss: 0.318592] \n",
      "[Epoch 52/100] [Batch 8] [loss: 0.319069] \n",
      "[Epoch 53/100] [Batch 0] [loss: 0.317795] \n",
      "[Epoch 53/100] [Batch 1] [loss: 0.318106] \n",
      "[Epoch 53/100] [Batch 2] [loss: 0.318944] \n",
      "[Epoch 53/100] [Batch 3] [loss: 0.317485] \n",
      "[Epoch 53/100] [Batch 4] [loss: 0.318739] \n",
      "[Epoch 53/100] [Batch 5] [loss: 0.319056] \n",
      "[Epoch 53/100] [Batch 6] [loss: 0.318287] \n",
      "[Epoch 53/100] [Batch 7] [loss: 0.318505] \n",
      "[Epoch 53/100] [Batch 8] [loss: 0.318971] \n",
      "[Epoch 54/100] [Batch 0] [loss: 0.317725] \n",
      "[Epoch 54/100] [Batch 1] [loss: 0.318029] \n",
      "[Epoch 54/100] [Batch 2] [loss: 0.318849] \n",
      "[Epoch 54/100] [Batch 3] [loss: 0.317422] \n",
      "[Epoch 54/100] [Batch 4] [loss: 0.318648] \n",
      "[Epoch 54/100] [Batch 5] [loss: 0.318960] \n",
      "[Epoch 54/100] [Batch 6] [loss: 0.318208] \n",
      "[Epoch 54/100] [Batch 7] [loss: 0.318420] \n",
      "[Epoch 54/100] [Batch 8] [loss: 0.318875] \n",
      "[Epoch 55/100] [Batch 0] [loss: 0.317657] \n",
      "[Epoch 55/100] [Batch 1] [loss: 0.317954] \n",
      "[Epoch 55/100] [Batch 2] [loss: 0.318757] \n",
      "[Epoch 55/100] [Batch 3] [loss: 0.317359] \n",
      "[Epoch 55/100] [Batch 4] [loss: 0.318559] \n",
      "[Epoch 55/100] [Batch 5] [loss: 0.318867] \n",
      "[Epoch 55/100] [Batch 6] [loss: 0.318130] \n",
      "[Epoch 55/100] [Batch 7] [loss: 0.318336] \n",
      "[Epoch 55/100] [Batch 8] [loss: 0.318782] \n",
      "[Epoch 56/100] [Batch 0] [loss: 0.317590] \n",
      "[Epoch 56/100] [Batch 1] [loss: 0.317880] \n",
      "[Epoch 56/100] [Batch 2] [loss: 0.318667] \n",
      "[Epoch 56/100] [Batch 3] [loss: 0.317298] \n",
      "[Epoch 56/100] [Batch 4] [loss: 0.318472] \n",
      "[Epoch 56/100] [Batch 5] [loss: 0.318775] \n",
      "[Epoch 56/100] [Batch 6] [loss: 0.318054] \n",
      "[Epoch 56/100] [Batch 7] [loss: 0.318255] \n",
      "[Epoch 56/100] [Batch 8] [loss: 0.318692] \n",
      "[Epoch 57/100] [Batch 0] [loss: 0.317525] \n",
      "[Epoch 57/100] [Batch 1] [loss: 0.317808] \n",
      "[Epoch 57/100] [Batch 2] [loss: 0.318579] \n",
      "[Epoch 57/100] [Batch 3] [loss: 0.317239] \n",
      "[Epoch 57/100] [Batch 4] [loss: 0.318387] \n",
      "[Epoch 57/100] [Batch 5] [loss: 0.318686] \n",
      "[Epoch 57/100] [Batch 6] [loss: 0.317980] \n",
      "[Epoch 57/100] [Batch 7] [loss: 0.318176] \n",
      "[Epoch 57/100] [Batch 8] [loss: 0.318603] \n",
      "[Epoch 58/100] [Batch 0] [loss: 0.317461] \n",
      "[Epoch 58/100] [Batch 1] [loss: 0.317738] \n",
      "[Epoch 58/100] [Batch 2] [loss: 0.318493] \n",
      "[Epoch 58/100] [Batch 3] [loss: 0.317181] \n",
      "[Epoch 58/100] [Batch 4] [loss: 0.318304] \n",
      "[Epoch 58/100] [Batch 5] [loss: 0.318599] \n",
      "[Epoch 58/100] [Batch 6] [loss: 0.317908] \n",
      "[Epoch 58/100] [Batch 7] [loss: 0.318098] \n",
      "[Epoch 58/100] [Batch 8] [loss: 0.318516] \n",
      "[Epoch 59/100] [Batch 0] [loss: 0.317398] \n",
      "[Epoch 59/100] [Batch 1] [loss: 0.317669] \n",
      "[Epoch 59/100] [Batch 2] [loss: 0.318409] \n",
      "[Epoch 59/100] [Batch 3] [loss: 0.317124] \n",
      "[Epoch 59/100] [Batch 4] [loss: 0.318223] \n",
      "[Epoch 59/100] [Batch 5] [loss: 0.318513] \n",
      "[Epoch 59/100] [Batch 6] [loss: 0.317837] \n",
      "[Epoch 59/100] [Batch 7] [loss: 0.318022] \n",
      "[Epoch 59/100] [Batch 8] [loss: 0.318432] \n",
      "[Epoch 60/100] [Batch 0] [loss: 0.317337] \n",
      "[Epoch 60/100] [Batch 1] [loss: 0.317604] \n",
      "[Epoch 60/100] [Batch 2] [loss: 0.318329] \n",
      "[Epoch 60/100] [Batch 3] [loss: 0.317070] \n",
      "[Epoch 60/100] [Batch 4] [loss: 0.318150] \n",
      "[Epoch 60/100] [Batch 5] [loss: 0.318438] \n",
      "[Epoch 60/100] [Batch 6] [loss: 0.317775] \n",
      "[Epoch 60/100] [Batch 7] [loss: 0.317958] \n",
      "[Epoch 60/100] [Batch 8] [loss: 0.318362] \n",
      "[Epoch 61/100] [Batch 0] [loss: 0.317289] \n",
      "[Epoch 61/100] [Batch 1] [loss: 0.317551] \n",
      "[Epoch 61/100] [Batch 2] [loss: 0.318265] \n",
      "[Epoch 61/100] [Batch 3] [loss: 0.317026] \n",
      "[Epoch 61/100] [Batch 4] [loss: 0.318088] \n",
      "[Epoch 61/100] [Batch 5] [loss: 0.318373] \n",
      "[Epoch 61/100] [Batch 6] [loss: 0.317720] \n",
      "[Epoch 61/100] [Batch 7] [loss: 0.317900] \n",
      "[Epoch 61/100] [Batch 8] [loss: 0.318297] \n",
      "[Epoch 62/100] [Batch 0] [loss: 0.317242] \n",
      "[Epoch 62/100] [Batch 1] [loss: 0.317499] \n",
      "[Epoch 62/100] [Batch 2] [loss: 0.318202] \n",
      "[Epoch 62/100] [Batch 3] [loss: 0.316983] \n",
      "[Epoch 62/100] [Batch 4] [loss: 0.318027] \n",
      "[Epoch 62/100] [Batch 5] [loss: 0.318309] \n",
      "[Epoch 62/100] [Batch 6] [loss: 0.317667] \n",
      "[Epoch 62/100] [Batch 7] [loss: 0.317843] \n",
      "[Epoch 62/100] [Batch 8] [loss: 0.318233] \n",
      "[Epoch 63/100] [Batch 0] [loss: 0.317196] \n",
      "[Epoch 63/100] [Batch 1] [loss: 0.317448] \n",
      "[Epoch 63/100] [Batch 2] [loss: 0.318140] \n",
      "[Epoch 63/100] [Batch 3] [loss: 0.316940] \n",
      "[Epoch 63/100] [Batch 4] [loss: 0.317967] \n",
      "[Epoch 63/100] [Batch 5] [loss: 0.318245] \n",
      "[Epoch 63/100] [Batch 6] [loss: 0.317614] \n",
      "[Epoch 63/100] [Batch 7] [loss: 0.317786] \n",
      "[Epoch 63/100] [Batch 8] [loss: 0.318170] \n",
      "[Epoch 64/100] [Batch 0] [loss: 0.317150] \n",
      "[Epoch 64/100] [Batch 1] [loss: 0.317398] \n",
      "[Epoch 64/100] [Batch 2] [loss: 0.318079] \n",
      "[Epoch 64/100] [Batch 3] [loss: 0.316898] \n",
      "[Epoch 64/100] [Batch 4] [loss: 0.317908] \n",
      "[Epoch 64/100] [Batch 5] [loss: 0.318183] \n",
      "[Epoch 64/100] [Batch 6] [loss: 0.317562] \n",
      "[Epoch 64/100] [Batch 7] [loss: 0.317731] \n",
      "[Epoch 64/100] [Batch 8] [loss: 0.318108] \n",
      "[Epoch 65/100] [Batch 0] [loss: 0.317105] \n",
      "[Epoch 65/100] [Batch 1] [loss: 0.317349] \n",
      "[Epoch 65/100] [Batch 2] [loss: 0.318019] \n",
      "[Epoch 65/100] [Batch 3] [loss: 0.316857] \n",
      "[Epoch 65/100] [Batch 4] [loss: 0.317850] \n",
      "[Epoch 65/100] [Batch 5] [loss: 0.318122] \n",
      "[Epoch 65/100] [Batch 6] [loss: 0.317511] \n",
      "[Epoch 65/100] [Batch 7] [loss: 0.317676] \n",
      "[Epoch 65/100] [Batch 8] [loss: 0.318048] \n",
      "[Epoch 66/100] [Batch 0] [loss: 0.317061] \n",
      "[Epoch 66/100] [Batch 1] [loss: 0.317300] \n",
      "[Epoch 66/100] [Batch 2] [loss: 0.317960] \n",
      "[Epoch 66/100] [Batch 3] [loss: 0.316816] \n",
      "[Epoch 66/100] [Batch 4] [loss: 0.317793] \n",
      "[Epoch 66/100] [Batch 5] [loss: 0.318061] \n",
      "[Epoch 66/100] [Batch 6] [loss: 0.317460] \n",
      "[Epoch 66/100] [Batch 7] [loss: 0.317622] \n",
      "[Epoch 66/100] [Batch 8] [loss: 0.317988] \n",
      "[Epoch 67/100] [Batch 0] [loss: 0.317017] \n",
      "[Epoch 67/100] [Batch 1] [loss: 0.317252] \n",
      "[Epoch 67/100] [Batch 2] [loss: 0.317902] \n",
      "[Epoch 67/100] [Batch 3] [loss: 0.316776] \n",
      "[Epoch 67/100] [Batch 4] [loss: 0.317737] \n",
      "[Epoch 67/100] [Batch 5] [loss: 0.318002] \n",
      "[Epoch 67/100] [Batch 6] [loss: 0.317411] \n",
      "[Epoch 67/100] [Batch 7] [loss: 0.317570] \n",
      "[Epoch 67/100] [Batch 8] [loss: 0.317929] \n",
      "[Epoch 68/100] [Batch 0] [loss: 0.316974] \n",
      "[Epoch 68/100] [Batch 1] [loss: 0.317205] \n",
      "[Epoch 68/100] [Batch 2] [loss: 0.317845] \n",
      "[Epoch 68/100] [Batch 3] [loss: 0.316737] \n",
      "[Epoch 68/100] [Batch 4] [loss: 0.317682] \n",
      "[Epoch 68/100] [Batch 5] [loss: 0.317944] \n",
      "[Epoch 68/100] [Batch 6] [loss: 0.317362] \n",
      "[Epoch 68/100] [Batch 7] [loss: 0.317518] \n",
      "[Epoch 68/100] [Batch 8] [loss: 0.317871] \n",
      "[Epoch 69/100] [Batch 0] [loss: 0.316932] \n",
      "[Epoch 69/100] [Batch 1] [loss: 0.317159] \n",
      "[Epoch 69/100] [Batch 2] [loss: 0.317788] \n",
      "[Epoch 69/100] [Batch 3] [loss: 0.316698] \n",
      "[Epoch 69/100] [Batch 4] [loss: 0.317628] \n",
      "[Epoch 69/100] [Batch 5] [loss: 0.317887] \n",
      "[Epoch 69/100] [Batch 6] [loss: 0.317314] \n",
      "[Epoch 69/100] [Batch 7] [loss: 0.317467] \n",
      "[Epoch 69/100] [Batch 8] [loss: 0.317815] \n",
      "[Epoch 70/100] [Batch 0] [loss: 0.316890] \n",
      "[Epoch 70/100] [Batch 1] [loss: 0.317114] \n",
      "[Epoch 70/100] [Batch 2] [loss: 0.317735] \n",
      "[Epoch 70/100] [Batch 3] [loss: 0.316661] \n",
      "[Epoch 70/100] [Batch 4] [loss: 0.317578] \n",
      "[Epoch 70/100] [Batch 5] [loss: 0.317836] \n",
      "[Epoch 70/100] [Batch 6] [loss: 0.317272] \n",
      "[Epoch 70/100] [Batch 7] [loss: 0.317423] \n",
      "[Epoch 70/100] [Batch 8] [loss: 0.317767] \n",
      "[Epoch 71/100] [Batch 0] [loss: 0.316857] \n",
      "[Epoch 71/100] [Batch 1] [loss: 0.317079] \n",
      "[Epoch 71/100] [Batch 2] [loss: 0.317691] \n",
      "[Epoch 71/100] [Batch 3] [loss: 0.316631] \n",
      "[Epoch 71/100] [Batch 4] [loss: 0.317536] \n",
      "[Epoch 71/100] [Batch 5] [loss: 0.317791] \n",
      "[Epoch 71/100] [Batch 6] [loss: 0.317235] \n",
      "[Epoch 71/100] [Batch 7] [loss: 0.317384] \n",
      "[Epoch 71/100] [Batch 8] [loss: 0.317723] \n",
      "[Epoch 72/100] [Batch 0] [loss: 0.316824] \n",
      "[Epoch 72/100] [Batch 1] [loss: 0.317043] \n",
      "[Epoch 72/100] [Batch 2] [loss: 0.317648] \n",
      "[Epoch 72/100] [Batch 3] [loss: 0.316601] \n",
      "[Epoch 72/100] [Batch 4] [loss: 0.317494] \n",
      "[Epoch 72/100] [Batch 5] [loss: 0.317747] \n",
      "[Epoch 72/100] [Batch 6] [loss: 0.317198] \n",
      "[Epoch 72/100] [Batch 7] [loss: 0.317344] \n",
      "[Epoch 72/100] [Batch 8] [loss: 0.317680] \n",
      "[Epoch 73/100] [Batch 0] [loss: 0.316792] \n",
      "[Epoch 73/100] [Batch 1] [loss: 0.317008] \n",
      "[Epoch 73/100] [Batch 2] [loss: 0.317605] \n",
      "[Epoch 73/100] [Batch 3] [loss: 0.316572] \n",
      "[Epoch 73/100] [Batch 4] [loss: 0.317453] \n",
      "[Epoch 73/100] [Batch 5] [loss: 0.317704] \n",
      "[Epoch 73/100] [Batch 6] [loss: 0.317161] \n",
      "[Epoch 73/100] [Batch 7] [loss: 0.317305] \n",
      "[Epoch 73/100] [Batch 8] [loss: 0.317636] \n",
      "[Epoch 74/100] [Batch 0] [loss: 0.316760] \n",
      "[Epoch 74/100] [Batch 1] [loss: 0.316973] \n",
      "[Epoch 74/100] [Batch 2] [loss: 0.317563] \n",
      "[Epoch 74/100] [Batch 3] [loss: 0.316542] \n",
      "[Epoch 74/100] [Batch 4] [loss: 0.317413] \n",
      "[Epoch 74/100] [Batch 5] [loss: 0.317661] \n",
      "[Epoch 74/100] [Batch 6] [loss: 0.317125] \n",
      "[Epoch 74/100] [Batch 7] [loss: 0.317267] \n",
      "[Epoch 74/100] [Batch 8] [loss: 0.317594] \n",
      "[Epoch 75/100] [Batch 0] [loss: 0.316729] \n",
      "[Epoch 75/100] [Batch 1] [loss: 0.316939] \n",
      "[Epoch 75/100] [Batch 2] [loss: 0.317522] \n",
      "[Epoch 75/100] [Batch 3] [loss: 0.316513] \n",
      "[Epoch 75/100] [Batch 4] [loss: 0.317372] \n",
      "[Epoch 75/100] [Batch 5] [loss: 0.317618] \n",
      "[Epoch 75/100] [Batch 6] [loss: 0.317089] \n",
      "[Epoch 75/100] [Batch 7] [loss: 0.317229] \n",
      "[Epoch 75/100] [Batch 8] [loss: 0.317552] \n",
      "[Epoch 76/100] [Batch 0] [loss: 0.316698] \n",
      "[Epoch 76/100] [Batch 1] [loss: 0.316905] \n",
      "[Epoch 76/100] [Batch 2] [loss: 0.317481] \n",
      "[Epoch 76/100] [Batch 3] [loss: 0.316485] \n",
      "[Epoch 76/100] [Batch 4] [loss: 0.317333] \n",
      "[Epoch 76/100] [Batch 5] [loss: 0.317576] \n",
      "[Epoch 76/100] [Batch 6] [loss: 0.317054] \n",
      "[Epoch 76/100] [Batch 7] [loss: 0.317191] \n",
      "[Epoch 76/100] [Batch 8] [loss: 0.317510] \n",
      "[Epoch 77/100] [Batch 0] [loss: 0.316667] \n",
      "[Epoch 77/100] [Batch 1] [loss: 0.316871] \n",
      "[Epoch 77/100] [Batch 2] [loss: 0.317440] \n",
      "[Epoch 77/100] [Batch 3] [loss: 0.316456] \n",
      "[Epoch 77/100] [Batch 4] [loss: 0.317293] \n",
      "[Epoch 77/100] [Batch 5] [loss: 0.317534] \n",
      "[Epoch 77/100] [Batch 6] [loss: 0.317019] \n",
      "[Epoch 77/100] [Batch 7] [loss: 0.317154] \n",
      "[Epoch 77/100] [Batch 8] [loss: 0.317469] \n",
      "[Epoch 78/100] [Batch 0] [loss: 0.316636] \n",
      "[Epoch 78/100] [Batch 1] [loss: 0.316838] \n",
      "[Epoch 78/100] [Batch 2] [loss: 0.317400] \n",
      "[Epoch 78/100] [Batch 3] [loss: 0.316428] \n",
      "[Epoch 78/100] [Batch 4] [loss: 0.317255] \n",
      "[Epoch 78/100] [Batch 5] [loss: 0.317493] \n",
      "[Epoch 78/100] [Batch 6] [loss: 0.316984] \n",
      "[Epoch 78/100] [Batch 7] [loss: 0.317117] \n",
      "[Epoch 78/100] [Batch 8] [loss: 0.317428] \n",
      "[Epoch 79/100] [Batch 0] [loss: 0.316606] \n",
      "[Epoch 79/100] [Batch 1] [loss: 0.316805] \n",
      "[Epoch 79/100] [Batch 2] [loss: 0.317360] \n",
      "[Epoch 79/100] [Batch 3] [loss: 0.316400] \n",
      "[Epoch 79/100] [Batch 4] [loss: 0.317216] \n",
      "[Epoch 79/100] [Batch 5] [loss: 0.317453] \n",
      "[Epoch 79/100] [Batch 6] [loss: 0.316950] \n",
      "[Epoch 79/100] [Batch 7] [loss: 0.317081] \n",
      "[Epoch 79/100] [Batch 8] [loss: 0.317388] \n",
      "[Epoch 80/100] [Batch 0] [loss: 0.316577] \n",
      "[Epoch 80/100] [Batch 1] [loss: 0.316773] \n",
      "[Epoch 80/100] [Batch 2] [loss: 0.317322] \n",
      "[Epoch 80/100] [Batch 3] [loss: 0.316374] \n",
      "[Epoch 80/100] [Batch 4] [loss: 0.317181] \n",
      "[Epoch 80/100] [Batch 5] [loss: 0.317417] \n",
      "[Epoch 80/100] [Batch 6] [loss: 0.316920] \n",
      "[Epoch 80/100] [Batch 7] [loss: 0.317050] \n",
      "[Epoch 80/100] [Batch 8] [loss: 0.317354] \n",
      "[Epoch 81/100] [Batch 0] [loss: 0.316553] \n",
      "[Epoch 81/100] [Batch 1] [loss: 0.316748] \n",
      "[Epoch 81/100] [Batch 2] [loss: 0.317291] \n",
      "[Epoch 81/100] [Batch 3] [loss: 0.316352] \n",
      "[Epoch 81/100] [Batch 4] [loss: 0.317151] \n",
      "[Epoch 81/100] [Batch 5] [loss: 0.317385] \n",
      "[Epoch 81/100] [Batch 6] [loss: 0.316893] \n",
      "[Epoch 81/100] [Batch 7] [loss: 0.317022] \n",
      "[Epoch 81/100] [Batch 8] [loss: 0.317323] \n",
      "[Epoch 82/100] [Batch 0] [loss: 0.316529] \n",
      "[Epoch 82/100] [Batch 1] [loss: 0.316722] \n",
      "[Epoch 82/100] [Batch 2] [loss: 0.317260] \n",
      "[Epoch 82/100] [Batch 3] [loss: 0.316331] \n",
      "[Epoch 82/100] [Batch 4] [loss: 0.317121] \n",
      "[Epoch 82/100] [Batch 5] [loss: 0.317353] \n",
      "[Epoch 82/100] [Batch 6] [loss: 0.316867] \n",
      "[Epoch 82/100] [Batch 7] [loss: 0.316994] \n",
      "[Epoch 82/100] [Batch 8] [loss: 0.317292] \n",
      "[Epoch 83/100] [Batch 0] [loss: 0.316506] \n",
      "[Epoch 83/100] [Batch 1] [loss: 0.316697] \n",
      "[Epoch 83/100] [Batch 2] [loss: 0.317230] \n",
      "[Epoch 83/100] [Batch 3] [loss: 0.316309] \n",
      "[Epoch 83/100] [Batch 4] [loss: 0.317092] \n",
      "[Epoch 83/100] [Batch 5] [loss: 0.317322] \n",
      "[Epoch 83/100] [Batch 6] [loss: 0.316840] \n",
      "[Epoch 83/100] [Batch 7] [loss: 0.316966] \n",
      "[Epoch 83/100] [Batch 8] [loss: 0.317261] \n",
      "[Epoch 84/100] [Batch 0] [loss: 0.316483] \n",
      "[Epoch 84/100] [Batch 1] [loss: 0.316671] \n",
      "[Epoch 84/100] [Batch 2] [loss: 0.317199] \n",
      "[Epoch 84/100] [Batch 3] [loss: 0.316288] \n",
      "[Epoch 84/100] [Batch 4] [loss: 0.317062] \n",
      "[Epoch 84/100] [Batch 5] [loss: 0.317291] \n",
      "[Epoch 84/100] [Batch 6] [loss: 0.316814] \n",
      "[Epoch 84/100] [Batch 7] [loss: 0.316938] \n",
      "[Epoch 84/100] [Batch 8] [loss: 0.317230] \n",
      "[Epoch 85/100] [Batch 0] [loss: 0.316460] \n",
      "[Epoch 85/100] [Batch 1] [loss: 0.316647] \n",
      "[Epoch 85/100] [Batch 2] [loss: 0.317169] \n",
      "[Epoch 85/100] [Batch 3] [loss: 0.316267] \n",
      "[Epoch 85/100] [Batch 4] [loss: 0.317033] \n",
      "[Epoch 85/100] [Batch 5] [loss: 0.317260] \n",
      "[Epoch 85/100] [Batch 6] [loss: 0.316788] \n",
      "[Epoch 85/100] [Batch 7] [loss: 0.316910] \n",
      "[Epoch 85/100] [Batch 8] [loss: 0.317199] \n",
      "[Epoch 86/100] [Batch 0] [loss: 0.316437] \n",
      "[Epoch 86/100] [Batch 1] [loss: 0.316622] \n",
      "[Epoch 86/100] [Batch 2] [loss: 0.317139] \n",
      "[Epoch 86/100] [Batch 3] [loss: 0.316245] \n",
      "[Epoch 86/100] [Batch 4] [loss: 0.317005] \n",
      "[Epoch 86/100] [Batch 5] [loss: 0.317229] \n",
      "[Epoch 86/100] [Batch 6] [loss: 0.316762] \n",
      "[Epoch 86/100] [Batch 7] [loss: 0.316883] \n",
      "[Epoch 86/100] [Batch 8] [loss: 0.317169] \n",
      "[Epoch 87/100] [Batch 0] [loss: 0.316415] \n",
      "[Epoch 87/100] [Batch 1] [loss: 0.316597] \n",
      "[Epoch 87/100] [Batch 2] [loss: 0.317110] \n",
      "[Epoch 87/100] [Batch 3] [loss: 0.316225] \n",
      "[Epoch 87/100] [Batch 4] [loss: 0.316976] \n",
      "[Epoch 87/100] [Batch 5] [loss: 0.317199] \n",
      "[Epoch 87/100] [Batch 6] [loss: 0.316737] \n",
      "[Epoch 87/100] [Batch 7] [loss: 0.316856] \n",
      "[Epoch 87/100] [Batch 8] [loss: 0.317139] \n",
      "[Epoch 88/100] [Batch 0] [loss: 0.316392] \n",
      "[Epoch 88/100] [Batch 1] [loss: 0.316573] \n",
      "[Epoch 88/100] [Batch 2] [loss: 0.317080] \n",
      "[Epoch 88/100] [Batch 3] [loss: 0.316204] \n",
      "[Epoch 88/100] [Batch 4] [loss: 0.316948] \n",
      "[Epoch 88/100] [Batch 5] [loss: 0.317169] \n",
      "[Epoch 88/100] [Batch 6] [loss: 0.316711] \n",
      "[Epoch 88/100] [Batch 7] [loss: 0.316829] \n",
      "[Epoch 88/100] [Batch 8] [loss: 0.317109] \n",
      "[Epoch 89/100] [Batch 0] [loss: 0.316370] \n",
      "[Epoch 89/100] [Batch 1] [loss: 0.316549] \n",
      "[Epoch 89/100] [Batch 2] [loss: 0.317051] \n",
      "[Epoch 89/100] [Batch 3] [loss: 0.316183] \n",
      "[Epoch 89/100] [Batch 4] [loss: 0.316920] \n",
      "[Epoch 89/100] [Batch 5] [loss: 0.317139] \n",
      "[Epoch 89/100] [Batch 6] [loss: 0.316686] \n",
      "[Epoch 89/100] [Batch 7] [loss: 0.316802] \n",
      "[Epoch 89/100] [Batch 8] [loss: 0.317080] \n",
      "[Epoch 90/100] [Batch 0] [loss: 0.316348] \n",
      "[Epoch 90/100] [Batch 1] [loss: 0.316525] \n",
      "[Epoch 90/100] [Batch 2] [loss: 0.317023] \n",
      "[Epoch 90/100] [Batch 3] [loss: 0.316164] \n",
      "[Epoch 90/100] [Batch 4] [loss: 0.316894] \n",
      "[Epoch 90/100] [Batch 5] [loss: 0.317113] \n",
      "[Epoch 90/100] [Batch 6] [loss: 0.316664] \n",
      "[Epoch 90/100] [Batch 7] [loss: 0.316779] \n",
      "[Epoch 90/100] [Batch 8] [loss: 0.317055] \n",
      "[Epoch 91/100] [Batch 0] [loss: 0.316330] \n",
      "[Epoch 91/100] [Batch 1] [loss: 0.316506] \n",
      "[Epoch 91/100] [Batch 2] [loss: 0.317000] \n",
      "[Epoch 91/100] [Batch 3] [loss: 0.316148] \n",
      "[Epoch 91/100] [Batch 4] [loss: 0.316871] \n",
      "[Epoch 91/100] [Batch 5] [loss: 0.317089] \n",
      "[Epoch 91/100] [Batch 6] [loss: 0.316644] \n",
      "[Epoch 91/100] [Batch 7] [loss: 0.316758] \n",
      "[Epoch 91/100] [Batch 8] [loss: 0.317032] \n",
      "[Epoch 92/100] [Batch 0] [loss: 0.316313] \n",
      "[Epoch 92/100] [Batch 1] [loss: 0.316487] \n",
      "[Epoch 92/100] [Batch 2] [loss: 0.316977] \n",
      "[Epoch 92/100] [Batch 3] [loss: 0.316131] \n",
      "[Epoch 92/100] [Batch 4] [loss: 0.316849] \n",
      "[Epoch 92/100] [Batch 5] [loss: 0.317066] \n",
      "[Epoch 92/100] [Batch 6] [loss: 0.316624] \n",
      "[Epoch 92/100] [Batch 7] [loss: 0.316737] \n",
      "[Epoch 92/100] [Batch 8] [loss: 0.317009] \n",
      "[Epoch 93/100] [Batch 0] [loss: 0.316295] \n",
      "[Epoch 93/100] [Batch 1] [loss: 0.316468] \n",
      "[Epoch 93/100] [Batch 2] [loss: 0.316955] \n",
      "[Epoch 93/100] [Batch 3] [loss: 0.316115] \n",
      "[Epoch 93/100] [Batch 4] [loss: 0.316828] \n",
      "[Epoch 93/100] [Batch 5] [loss: 0.317042] \n",
      "[Epoch 93/100] [Batch 6] [loss: 0.316604] \n",
      "[Epoch 93/100] [Batch 7] [loss: 0.316716] \n",
      "[Epoch 93/100] [Batch 8] [loss: 0.316986] \n",
      "[Epoch 94/100] [Batch 0] [loss: 0.316278] \n",
      "[Epoch 94/100] [Batch 1] [loss: 0.316449] \n",
      "[Epoch 94/100] [Batch 2] [loss: 0.316932] \n",
      "[Epoch 94/100] [Batch 3] [loss: 0.316099] \n",
      "[Epoch 94/100] [Batch 4] [loss: 0.316806] \n",
      "[Epoch 94/100] [Batch 5] [loss: 0.317019] \n",
      "[Epoch 94/100] [Batch 6] [loss: 0.316585] \n",
      "[Epoch 94/100] [Batch 7] [loss: 0.316696] \n",
      "[Epoch 94/100] [Batch 8] [loss: 0.316963] \n",
      "[Epoch 95/100] [Batch 0] [loss: 0.316261] \n",
      "[Epoch 95/100] [Batch 1] [loss: 0.316431] \n",
      "[Epoch 95/100] [Batch 2] [loss: 0.316910] \n",
      "[Epoch 95/100] [Batch 3] [loss: 0.316083] \n",
      "[Epoch 95/100] [Batch 4] [loss: 0.316784] \n",
      "[Epoch 95/100] [Batch 5] [loss: 0.316996] \n",
      "[Epoch 95/100] [Batch 6] [loss: 0.316565] \n",
      "[Epoch 95/100] [Batch 7] [loss: 0.316675] \n",
      "[Epoch 95/100] [Batch 8] [loss: 0.316940] \n",
      "[Epoch 96/100] [Batch 0] [loss: 0.316244] \n",
      "[Epoch 96/100] [Batch 1] [loss: 0.316412] \n",
      "[Epoch 96/100] [Batch 2] [loss: 0.316887] \n",
      "[Epoch 96/100] [Batch 3] [loss: 0.316067] \n",
      "[Epoch 96/100] [Batch 4] [loss: 0.316762] \n",
      "[Epoch 96/100] [Batch 5] [loss: 0.316973] \n",
      "[Epoch 96/100] [Batch 6] [loss: 0.316546] \n",
      "[Epoch 96/100] [Batch 7] [loss: 0.316655] \n",
      "[Epoch 96/100] [Batch 8] [loss: 0.316917] \n",
      "[Epoch 97/100] [Batch 0] [loss: 0.316227] \n",
      "[Epoch 97/100] [Batch 1] [loss: 0.316394] \n",
      "[Epoch 97/100] [Batch 2] [loss: 0.316865] \n",
      "[Epoch 97/100] [Batch 3] [loss: 0.316052] \n",
      "[Epoch 97/100] [Batch 4] [loss: 0.316741] \n",
      "[Epoch 97/100] [Batch 5] [loss: 0.316950] \n",
      "[Epoch 97/100] [Batch 6] [loss: 0.316526] \n",
      "[Epoch 97/100] [Batch 7] [loss: 0.316634] \n",
      "[Epoch 97/100] [Batch 8] [loss: 0.316895] \n",
      "[Epoch 98/100] [Batch 0] [loss: 0.316210] \n",
      "[Epoch 98/100] [Batch 1] [loss: 0.316375] \n",
      "[Epoch 98/100] [Batch 2] [loss: 0.316843] \n",
      "[Epoch 98/100] [Batch 3] [loss: 0.316036] \n",
      "[Epoch 98/100] [Batch 4] [loss: 0.316720] \n",
      "[Epoch 98/100] [Batch 5] [loss: 0.316928] \n",
      "[Epoch 98/100] [Batch 6] [loss: 0.316507] \n",
      "[Epoch 98/100] [Batch 7] [loss: 0.316614] \n",
      "[Epoch 98/100] [Batch 8] [loss: 0.316872] \n",
      "[Epoch 99/100] [Batch 0] [loss: 0.316193] \n",
      "[Epoch 99/100] [Batch 1] [loss: 0.316357] \n",
      "[Epoch 99/100] [Batch 2] [loss: 0.316821] \n",
      "[Epoch 99/100] [Batch 3] [loss: 0.316020] \n",
      "[Epoch 99/100] [Batch 4] [loss: 0.316698] \n",
      "[Epoch 99/100] [Batch 5] [loss: 0.316905] \n",
      "[Epoch 99/100] [Batch 6] [loss: 0.316488] \n",
      "[Epoch 99/100] [Batch 7] [loss: 0.316594] \n",
      "[Epoch 99/100] [Batch 8] [loss: 0.316850] \n",
      "[0.5, 0.5, 0.5, 0.5, 0.7, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "acc_vec = []\n",
    "train_vec = []\n",
    "loss_vec = []\n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(0, 9):\n",
    "            fmri_data = train_fmri[i*batch_size:(i+1) * batch_size]\n",
    "            labels_data = train_labels[i*batch_size:(i+1) * batch_size]\n",
    "            labels_data = labels_data.long()\n",
    "            optimizer.zero_grad()\n",
    "            predict = semanticDecoder(fmri_data)\n",
    "            loss = loss_function(predict, labels_data)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_vec.append(loss.item())\n",
    "            print(\n",
    "                \"[Epoch %d/%d] [Batch %d] [loss: %f] \"\n",
    "                % (epoch, n_epochs, i, loss.item())\n",
    "            )\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "            test_fmri_data = test_fmri\n",
    "            test_label_data = test_labels.cpu().detach().numpy()\n",
    "            lbs = semanticDecoder(test_fmri_data)\n",
    "            cpu_labels = lbs.cpu().detach().numpy()\n",
    "            pred = [np.argmax(lb) for lb in cpu_labels]\n",
    "            num_correct = (pred == test_label_data).sum()\n",
    "            acc = num_correct / 10\n",
    "            acc_vec.append(acc)\n",
    "\n",
    "\n",
    "    scheduler.step()\n",
    "    lrd = optimizer.param_groups[0]['lr']\n",
    "\n",
    "print(acc_vec)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.title('Loss of classification task - 2 class digits')\n",
    "plt.plot(loss_vec)\n",
    "plt.xlabel('Epoch num')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# shape decoder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "fmri = torch.load('data/fMRI_data/demo1/digits-fmri')\n",
    "imgs = torch.load('data/images/demo1/raw_imgs/digits-images')\n",
    "train_fmri = np.concatenate([fmri[0:45], fmri[50:95]])\n",
    "test_fmri = np.concatenate([fmri[45:50], fmri[95:100]])\n",
    "train_imgs = np.concatenate([imgs[0:45], imgs[50:95]])\n",
    "test_imgs = np.concatenate([imgs[45:50], imgs[95:100]])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "\n",
    "class ShapeDecoder(nn.Module):\n",
    "    def __init__(self, input_size, latent_dim):\n",
    "        super(ShapeDecoder, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, latent_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.shape[0], -1)\n",
    "        x = self.model(img_flat)\n",
    "        return x\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "output_size_2=28\n",
    "n_epochs_2=101\n",
    "batch_size_2=10\n",
    "lr_2=0.0006\n",
    "b1=0.5\n",
    "b2=0.999"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train blocks:90\n",
      "batch num:9.0\n"
     ]
    }
   ],
   "source": [
    "latent_dim = output_size_2 *output_size_2\n",
    "rand_id = np.random.randint(low=0, high=train_fmri.shape[0], size=train_fmri.shape[0])\n",
    "train_fmri = train_fmri[rand_id]\n",
    "train_img = train_imgs[rand_id]\n",
    "raw_img = imgs\n",
    "fmri = np.concatenate([train_fmri, test_fmri])\n",
    "imgs = np.concatenate([train_img, test_imgs])\n",
    "total_blocks = fmri.shape[0]\n",
    "fmri_size = fmri.shape[1]\n",
    "train_num = total_blocks - 10\n",
    "batch_num = train_num / batch_size\n",
    "print('Train blocks:'+str(train_num))\n",
    "print('batch num:' + str(batch_num))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "# Use binary cross-entropy loss\n",
    "loss_function = torch.nn.BCELoss()\n",
    "pixelwise_loss = torch.nn.L1Loss()\n",
    "# Initialize generator and discriminator\n",
    "decoder = ShapeDecoder(input_size=fmri_size, latent_dim=latent_dim)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "cuda = True if torch.cuda.is_available() else False\n",
    "if cuda:\n",
    "    decoder.cuda()\n",
    "    loss_function.cuda()\n",
    "    pixelwise_loss.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(decoder.parameters(), lr=lr_2, betas=(b1, b2))\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.7, last_epoch=-1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3092)\n"
     ]
    }
   ],
   "source": [
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "\n",
    "print(fmri.shape)\n",
    "fmri = torch.from_numpy(fmri)\n",
    "fmri = fmri.type(Tensor)\n",
    "\n",
    "\n",
    "imgs = torch.from_numpy(imgs)\n",
    "imgs = imgs.type(Tensor)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/100] [Batch 0] [E loss: 29.266792]\n",
      "[Epoch 0/100] [Batch 1] [E loss: 31.002010]\n",
      "[Epoch 0/100] [Batch 2] [E loss: 32.397259]\n",
      "[Epoch 0/100] [Batch 3] [E loss: 37.525150]\n",
      "[Epoch 0/100] [Batch 4] [E loss: 35.120819]\n",
      "[Epoch 0/100] [Batch 5] [E loss: 31.532022]\n",
      "[Epoch 0/100] [Batch 6] [E loss: 35.334747]\n",
      "[Epoch 0/100] [Batch 7] [E loss: 33.944363]\n",
      "[Epoch 0/100] [Batch 8] [E loss: 39.315094]\n",
      "[Epoch 1/100] [Batch 0] [E loss: 29.250677]\n",
      "[Epoch 1/100] [Batch 1] [E loss: 30.986464]\n",
      "[Epoch 1/100] [Batch 2] [E loss: 32.385406]\n",
      "[Epoch 1/100] [Batch 3] [E loss: 37.513092]\n",
      "[Epoch 1/100] [Batch 4] [E loss: 35.105621]\n",
      "[Epoch 1/100] [Batch 5] [E loss: 31.521788]\n",
      "[Epoch 1/100] [Batch 6] [E loss: 35.320992]\n",
      "[Epoch 1/100] [Batch 7] [E loss: 33.929562]\n",
      "[Epoch 1/100] [Batch 8] [E loss: 39.300976]\n",
      "[Epoch 2/100] [Batch 0] [E loss: 29.240677]\n",
      "[Epoch 2/100] [Batch 1] [E loss: 30.975498]\n",
      "[Epoch 2/100] [Batch 2] [E loss: 32.375629]\n",
      "[Epoch 2/100] [Batch 3] [E loss: 37.503826]\n",
      "[Epoch 2/100] [Batch 4] [E loss: 35.092228]\n",
      "[Epoch 2/100] [Batch 5] [E loss: 31.513645]\n",
      "[Epoch 2/100] [Batch 6] [E loss: 35.309895]\n",
      "[Epoch 2/100] [Batch 7] [E loss: 33.917683]\n",
      "[Epoch 2/100] [Batch 8] [E loss: 39.289402]\n",
      "[Epoch 3/100] [Batch 0] [E loss: 29.232243]\n",
      "[Epoch 3/100] [Batch 1] [E loss: 30.966944]\n",
      "[Epoch 3/100] [Batch 2] [E loss: 32.367779]\n",
      "[Epoch 3/100] [Batch 3] [E loss: 37.495922]\n",
      "[Epoch 3/100] [Batch 4] [E loss: 35.081600]\n",
      "[Epoch 3/100] [Batch 5] [E loss: 31.506283]\n",
      "[Epoch 3/100] [Batch 6] [E loss: 35.301125]\n",
      "[Epoch 3/100] [Batch 7] [E loss: 33.907833]\n",
      "[Epoch 3/100] [Batch 8] [E loss: 39.279625]\n",
      "[Epoch 4/100] [Batch 0] [E loss: 29.225630]\n",
      "[Epoch 4/100] [Batch 1] [E loss: 30.959881]\n",
      "[Epoch 4/100] [Batch 2] [E loss: 32.361401]\n",
      "[Epoch 4/100] [Batch 3] [E loss: 37.489765]\n",
      "[Epoch 4/100] [Batch 4] [E loss: 35.072567]\n",
      "[Epoch 4/100] [Batch 5] [E loss: 31.500435]\n",
      "[Epoch 4/100] [Batch 6] [E loss: 35.293713]\n",
      "[Epoch 4/100] [Batch 7] [E loss: 33.900047]\n",
      "[Epoch 4/100] [Batch 8] [E loss: 39.271408]\n",
      "[Epoch 5/100] [Batch 0] [E loss: 29.220181]\n",
      "[Epoch 5/100] [Batch 1] [E loss: 30.954325]\n",
      "[Epoch 5/100] [Batch 2] [E loss: 32.356403]\n",
      "[Epoch 5/100] [Batch 3] [E loss: 37.484413]\n",
      "[Epoch 5/100] [Batch 4] [E loss: 35.065525]\n",
      "[Epoch 5/100] [Batch 5] [E loss: 31.495775]\n",
      "[Epoch 5/100] [Batch 6] [E loss: 35.288223]\n",
      "[Epoch 5/100] [Batch 7] [E loss: 33.893845]\n",
      "[Epoch 5/100] [Batch 8] [E loss: 39.264790]\n",
      "[Epoch 6/100] [Batch 0] [E loss: 29.215815]\n",
      "[Epoch 6/100] [Batch 1] [E loss: 30.949955]\n",
      "[Epoch 6/100] [Batch 2] [E loss: 32.351990]\n",
      "[Epoch 6/100] [Batch 3] [E loss: 37.480206]\n",
      "[Epoch 6/100] [Batch 4] [E loss: 35.059944]\n",
      "[Epoch 6/100] [Batch 5] [E loss: 31.491522]\n",
      "[Epoch 6/100] [Batch 6] [E loss: 35.283680]\n",
      "[Epoch 6/100] [Batch 7] [E loss: 33.888638]\n",
      "[Epoch 6/100] [Batch 8] [E loss: 39.259193]\n",
      "[Epoch 7/100] [Batch 0] [E loss: 29.212372]\n",
      "[Epoch 7/100] [Batch 1] [E loss: 30.946585]\n",
      "[Epoch 7/100] [Batch 2] [E loss: 32.348377]\n",
      "[Epoch 7/100] [Batch 3] [E loss: 37.476719]\n",
      "[Epoch 7/100] [Batch 4] [E loss: 35.055302]\n",
      "[Epoch 7/100] [Batch 5] [E loss: 31.488203]\n",
      "[Epoch 7/100] [Batch 6] [E loss: 35.279968]\n",
      "[Epoch 7/100] [Batch 7] [E loss: 33.884407]\n",
      "[Epoch 7/100] [Batch 8] [E loss: 39.254425]\n",
      "[Epoch 8/100] [Batch 0] [E loss: 29.209475]\n",
      "[Epoch 8/100] [Batch 1] [E loss: 30.943304]\n",
      "[Epoch 8/100] [Batch 2] [E loss: 32.345638]\n",
      "[Epoch 8/100] [Batch 3] [E loss: 37.473442]\n",
      "[Epoch 8/100] [Batch 4] [E loss: 35.051666]\n",
      "[Epoch 8/100] [Batch 5] [E loss: 31.485046]\n",
      "[Epoch 8/100] [Batch 6] [E loss: 35.276550]\n",
      "[Epoch 8/100] [Batch 7] [E loss: 33.880920]\n",
      "[Epoch 8/100] [Batch 8] [E loss: 39.250454]\n",
      "[Epoch 9/100] [Batch 0] [E loss: 29.206839]\n",
      "[Epoch 9/100] [Batch 1] [E loss: 30.940948]\n",
      "[Epoch 9/100] [Batch 2] [E loss: 32.342896]\n",
      "[Epoch 9/100] [Batch 3] [E loss: 37.470959]\n",
      "[Epoch 9/100] [Batch 4] [E loss: 35.047932]\n",
      "[Epoch 9/100] [Batch 5] [E loss: 31.482605]\n",
      "[Epoch 9/100] [Batch 6] [E loss: 35.273628]\n",
      "[Epoch 9/100] [Batch 7] [E loss: 33.878082]\n",
      "[Epoch 9/100] [Batch 8] [E loss: 39.246830]\n",
      "[Epoch 10/100] [Batch 0] [E loss: 29.204561]\n",
      "[Epoch 10/100] [Batch 1] [E loss: 30.938469]\n",
      "[Epoch 10/100] [Batch 2] [E loss: 32.340763]\n",
      "[Epoch 10/100] [Batch 3] [E loss: 37.468483]\n",
      "[Epoch 10/100] [Batch 4] [E loss: 35.045578]\n",
      "[Epoch 10/100] [Batch 5] [E loss: 31.480259]\n",
      "[Epoch 10/100] [Batch 6] [E loss: 35.271446]\n",
      "[Epoch 10/100] [Batch 7] [E loss: 33.875248]\n",
      "[Epoch 10/100] [Batch 8] [E loss: 39.243637]\n",
      "[Epoch 11/100] [Batch 0] [E loss: 29.202511]\n",
      "[Epoch 11/100] [Batch 1] [E loss: 30.936720]\n",
      "[Epoch 11/100] [Batch 2] [E loss: 32.338470]\n",
      "[Epoch 11/100] [Batch 3] [E loss: 37.466209]\n",
      "[Epoch 11/100] [Batch 4] [E loss: 35.042858]\n",
      "[Epoch 11/100] [Batch 5] [E loss: 31.478081]\n",
      "[Epoch 11/100] [Batch 6] [E loss: 35.269085]\n",
      "[Epoch 11/100] [Batch 7] [E loss: 33.872707]\n",
      "[Epoch 11/100] [Batch 8] [E loss: 39.240692]\n",
      "[Epoch 12/100] [Batch 0] [E loss: 29.200687]\n",
      "[Epoch 12/100] [Batch 1] [E loss: 30.934855]\n",
      "[Epoch 12/100] [Batch 2] [E loss: 32.336830]\n",
      "[Epoch 12/100] [Batch 3] [E loss: 37.464252]\n",
      "[Epoch 12/100] [Batch 4] [E loss: 35.040699]\n",
      "[Epoch 12/100] [Batch 5] [E loss: 31.476015]\n",
      "[Epoch 12/100] [Batch 6] [E loss: 35.267101]\n",
      "[Epoch 12/100] [Batch 7] [E loss: 33.870865]\n",
      "[Epoch 12/100] [Batch 8] [E loss: 39.237942]\n",
      "[Epoch 13/100] [Batch 0] [E loss: 29.199150]\n",
      "[Epoch 13/100] [Batch 1] [E loss: 30.933115]\n",
      "[Epoch 13/100] [Batch 2] [E loss: 32.335079]\n",
      "[Epoch 13/100] [Batch 3] [E loss: 37.462078]\n",
      "[Epoch 13/100] [Batch 4] [E loss: 35.039055]\n",
      "[Epoch 13/100] [Batch 5] [E loss: 31.474331]\n",
      "[Epoch 13/100] [Batch 6] [E loss: 35.265366]\n",
      "[Epoch 13/100] [Batch 7] [E loss: 33.869080]\n",
      "[Epoch 13/100] [Batch 8] [E loss: 39.235497]\n",
      "[Epoch 14/100] [Batch 0] [E loss: 29.197453]\n",
      "[Epoch 14/100] [Batch 1] [E loss: 30.931585]\n",
      "[Epoch 14/100] [Batch 2] [E loss: 32.333294]\n",
      "[Epoch 14/100] [Batch 3] [E loss: 37.460621]\n",
      "[Epoch 14/100] [Batch 4] [E loss: 35.037113]\n",
      "[Epoch 14/100] [Batch 5] [E loss: 31.472574]\n",
      "[Epoch 14/100] [Batch 6] [E loss: 35.263412]\n",
      "[Epoch 14/100] [Batch 7] [E loss: 33.867207]\n",
      "[Epoch 14/100] [Batch 8] [E loss: 39.233356]\n",
      "[Epoch 15/100] [Batch 0] [E loss: 29.196270]\n",
      "[Epoch 15/100] [Batch 1] [E loss: 30.930052]\n",
      "[Epoch 15/100] [Batch 2] [E loss: 32.332150]\n",
      "[Epoch 15/100] [Batch 3] [E loss: 37.458927]\n",
      "[Epoch 15/100] [Batch 4] [E loss: 35.035698]\n",
      "[Epoch 15/100] [Batch 5] [E loss: 31.471090]\n",
      "[Epoch 15/100] [Batch 6] [E loss: 35.261684]\n",
      "[Epoch 15/100] [Batch 7] [E loss: 33.865616]\n",
      "[Epoch 15/100] [Batch 8] [E loss: 39.231316]\n",
      "[Epoch 16/100] [Batch 0] [E loss: 29.195026]\n",
      "[Epoch 16/100] [Batch 1] [E loss: 30.928720]\n",
      "[Epoch 16/100] [Batch 2] [E loss: 32.330929]\n",
      "[Epoch 16/100] [Batch 3] [E loss: 37.457275]\n",
      "[Epoch 16/100] [Batch 4] [E loss: 35.034512]\n",
      "[Epoch 16/100] [Batch 5] [E loss: 31.469692]\n",
      "[Epoch 16/100] [Batch 6] [E loss: 35.260357]\n",
      "[Epoch 16/100] [Batch 7] [E loss: 33.863983]\n",
      "[Epoch 16/100] [Batch 8] [E loss: 39.229168]\n",
      "[Epoch 17/100] [Batch 0] [E loss: 29.193575]\n",
      "[Epoch 17/100] [Batch 1] [E loss: 30.927240]\n",
      "[Epoch 17/100] [Batch 2] [E loss: 32.329407]\n",
      "[Epoch 17/100] [Batch 3] [E loss: 37.455574]\n",
      "[Epoch 17/100] [Batch 4] [E loss: 35.033058]\n",
      "[Epoch 17/100] [Batch 5] [E loss: 31.468122]\n",
      "[Epoch 17/100] [Batch 6] [E loss: 35.258671]\n",
      "[Epoch 17/100] [Batch 7] [E loss: 33.862419]\n",
      "[Epoch 17/100] [Batch 8] [E loss: 39.227398]\n",
      "[Epoch 18/100] [Batch 0] [E loss: 29.192150]\n",
      "[Epoch 18/100] [Batch 1] [E loss: 30.925890]\n",
      "[Epoch 18/100] [Batch 2] [E loss: 32.328136]\n",
      "[Epoch 18/100] [Batch 3] [E loss: 37.454170]\n",
      "[Epoch 18/100] [Batch 4] [E loss: 35.031624]\n",
      "[Epoch 18/100] [Batch 5] [E loss: 31.466724]\n",
      "[Epoch 18/100] [Batch 6] [E loss: 35.257313]\n",
      "[Epoch 18/100] [Batch 7] [E loss: 33.860962]\n",
      "[Epoch 18/100] [Batch 8] [E loss: 39.225460]\n",
      "[Epoch 19/100] [Batch 0] [E loss: 29.190914]\n",
      "[Epoch 19/100] [Batch 1] [E loss: 30.924721]\n",
      "[Epoch 19/100] [Batch 2] [E loss: 32.326885]\n",
      "[Epoch 19/100] [Batch 3] [E loss: 37.452618]\n",
      "[Epoch 19/100] [Batch 4] [E loss: 35.030499]\n",
      "[Epoch 19/100] [Batch 5] [E loss: 31.465391]\n",
      "[Epoch 19/100] [Batch 6] [E loss: 35.255981]\n",
      "[Epoch 19/100] [Batch 7] [E loss: 33.859478]\n",
      "[Epoch 19/100] [Batch 8] [E loss: 39.223835]\n",
      "[Epoch 20/100] [Batch 0] [E loss: 29.189823]\n",
      "[Epoch 20/100] [Batch 1] [E loss: 30.923391]\n",
      "[Epoch 20/100] [Batch 2] [E loss: 32.325756]\n",
      "[Epoch 20/100] [Batch 3] [E loss: 37.451355]\n",
      "[Epoch 20/100] [Batch 4] [E loss: 35.029648]\n",
      "[Epoch 20/100] [Batch 5] [E loss: 31.464037]\n",
      "[Epoch 20/100] [Batch 6] [E loss: 35.254730]\n",
      "[Epoch 20/100] [Batch 7] [E loss: 33.858334]\n",
      "[Epoch 20/100] [Batch 8] [E loss: 39.222286]\n",
      "[Epoch 21/100] [Batch 0] [E loss: 29.188847]\n",
      "[Epoch 21/100] [Batch 1] [E loss: 30.922237]\n",
      "[Epoch 21/100] [Batch 2] [E loss: 32.324635]\n",
      "[Epoch 21/100] [Batch 3] [E loss: 37.450138]\n",
      "[Epoch 21/100] [Batch 4] [E loss: 35.028442]\n",
      "[Epoch 21/100] [Batch 5] [E loss: 31.462893]\n",
      "[Epoch 21/100] [Batch 6] [E loss: 35.253155]\n",
      "[Epoch 21/100] [Batch 7] [E loss: 33.856781]\n",
      "[Epoch 21/100] [Batch 8] [E loss: 39.220688]\n",
      "[Epoch 22/100] [Batch 0] [E loss: 29.187685]\n",
      "[Epoch 22/100] [Batch 1] [E loss: 30.921228]\n",
      "[Epoch 22/100] [Batch 2] [E loss: 32.323311]\n",
      "[Epoch 22/100] [Batch 3] [E loss: 37.448547]\n",
      "[Epoch 22/100] [Batch 4] [E loss: 35.027435]\n",
      "[Epoch 22/100] [Batch 5] [E loss: 31.461733]\n",
      "[Epoch 22/100] [Batch 6] [E loss: 35.252155]\n",
      "[Epoch 22/100] [Batch 7] [E loss: 33.855923]\n",
      "[Epoch 22/100] [Batch 8] [E loss: 39.219215]\n",
      "[Epoch 23/100] [Batch 0] [E loss: 29.186560]\n",
      "[Epoch 23/100] [Batch 1] [E loss: 30.919922]\n",
      "[Epoch 23/100] [Batch 2] [E loss: 32.322449]\n",
      "[Epoch 23/100] [Batch 3] [E loss: 37.447422]\n",
      "[Epoch 23/100] [Batch 4] [E loss: 35.026539]\n",
      "[Epoch 23/100] [Batch 5] [E loss: 31.460493]\n",
      "[Epoch 23/100] [Batch 6] [E loss: 35.250767]\n",
      "[Epoch 23/100] [Batch 7] [E loss: 33.854393]\n",
      "[Epoch 23/100] [Batch 8] [E loss: 39.217655]\n",
      "[Epoch 24/100] [Batch 0] [E loss: 29.185543]\n",
      "[Epoch 24/100] [Batch 1] [E loss: 30.918810]\n",
      "[Epoch 24/100] [Batch 2] [E loss: 32.321148]\n",
      "[Epoch 24/100] [Batch 3] [E loss: 37.446075]\n",
      "[Epoch 24/100] [Batch 4] [E loss: 35.025467]\n",
      "[Epoch 24/100] [Batch 5] [E loss: 31.459282]\n",
      "[Epoch 24/100] [Batch 6] [E loss: 35.249569]\n",
      "[Epoch 24/100] [Batch 7] [E loss: 33.853386]\n",
      "[Epoch 24/100] [Batch 8] [E loss: 39.216301]\n",
      "[Epoch 25/100] [Batch 0] [E loss: 29.184542]\n",
      "[Epoch 25/100] [Batch 1] [E loss: 30.917740]\n",
      "[Epoch 25/100] [Batch 2] [E loss: 32.320080]\n",
      "[Epoch 25/100] [Batch 3] [E loss: 37.444714]\n",
      "[Epoch 25/100] [Batch 4] [E loss: 35.024624]\n",
      "[Epoch 25/100] [Batch 5] [E loss: 31.458292]\n",
      "[Epoch 25/100] [Batch 6] [E loss: 35.248486]\n",
      "[Epoch 25/100] [Batch 7] [E loss: 33.852070]\n",
      "[Epoch 25/100] [Batch 8] [E loss: 39.215050]\n",
      "[Epoch 26/100] [Batch 0] [E loss: 29.183403]\n",
      "[Epoch 26/100] [Batch 1] [E loss: 30.916786]\n",
      "[Epoch 26/100] [Batch 2] [E loss: 32.319107]\n",
      "[Epoch 26/100] [Batch 3] [E loss: 37.443874]\n",
      "[Epoch 26/100] [Batch 4] [E loss: 35.023582]\n",
      "[Epoch 26/100] [Batch 5] [E loss: 31.457085]\n",
      "[Epoch 26/100] [Batch 6] [E loss: 35.247597]\n",
      "[Epoch 26/100] [Batch 7] [E loss: 33.850868]\n",
      "[Epoch 26/100] [Batch 8] [E loss: 39.213806]\n",
      "[Epoch 27/100] [Batch 0] [E loss: 29.182659]\n",
      "[Epoch 27/100] [Batch 1] [E loss: 30.915686]\n",
      "[Epoch 27/100] [Batch 2] [E loss: 32.318295]\n",
      "[Epoch 27/100] [Batch 3] [E loss: 37.442505]\n",
      "[Epoch 27/100] [Batch 4] [E loss: 35.022778]\n",
      "[Epoch 27/100] [Batch 5] [E loss: 31.456163]\n",
      "[Epoch 27/100] [Batch 6] [E loss: 35.246372]\n",
      "[Epoch 27/100] [Batch 7] [E loss: 33.849937]\n",
      "[Epoch 27/100] [Batch 8] [E loss: 39.212215]\n",
      "[Epoch 28/100] [Batch 0] [E loss: 29.181564]\n",
      "[Epoch 28/100] [Batch 1] [E loss: 30.914677]\n",
      "[Epoch 28/100] [Batch 2] [E loss: 32.317265]\n",
      "[Epoch 28/100] [Batch 3] [E loss: 37.441357]\n",
      "[Epoch 28/100] [Batch 4] [E loss: 35.022121]\n",
      "[Epoch 28/100] [Batch 5] [E loss: 31.455166]\n",
      "[Epoch 28/100] [Batch 6] [E loss: 35.245399]\n",
      "[Epoch 28/100] [Batch 7] [E loss: 33.848808]\n",
      "[Epoch 28/100] [Batch 8] [E loss: 39.211521]\n",
      "[Epoch 29/100] [Batch 0] [E loss: 29.180685]\n",
      "[Epoch 29/100] [Batch 1] [E loss: 30.913528]\n",
      "[Epoch 29/100] [Batch 2] [E loss: 32.316158]\n",
      "[Epoch 29/100] [Batch 3] [E loss: 37.440212]\n",
      "[Epoch 29/100] [Batch 4] [E loss: 35.021191]\n",
      "[Epoch 29/100] [Batch 5] [E loss: 31.454084]\n",
      "[Epoch 29/100] [Batch 6] [E loss: 35.244080]\n",
      "[Epoch 29/100] [Batch 7] [E loss: 33.847729]\n",
      "[Epoch 29/100] [Batch 8] [E loss: 39.210011]\n",
      "[Epoch 30/100] [Batch 0] [E loss: 29.179583]\n",
      "[Epoch 30/100] [Batch 1] [E loss: 30.912651]\n",
      "[Epoch 30/100] [Batch 2] [E loss: 32.315247]\n",
      "[Epoch 30/100] [Batch 3] [E loss: 37.439205]\n",
      "[Epoch 30/100] [Batch 4] [E loss: 35.020489]\n",
      "[Epoch 30/100] [Batch 5] [E loss: 31.453115]\n",
      "[Epoch 30/100] [Batch 6] [E loss: 35.242851]\n",
      "[Epoch 30/100] [Batch 7] [E loss: 33.846699]\n",
      "[Epoch 30/100] [Batch 8] [E loss: 39.208855]\n",
      "[Epoch 31/100] [Batch 0] [E loss: 29.178810]\n",
      "[Epoch 31/100] [Batch 1] [E loss: 30.911573]\n",
      "[Epoch 31/100] [Batch 2] [E loss: 32.314270]\n",
      "[Epoch 31/100] [Batch 3] [E loss: 37.438057]\n",
      "[Epoch 31/100] [Batch 4] [E loss: 35.019623]\n",
      "[Epoch 31/100] [Batch 5] [E loss: 31.452005]\n",
      "[Epoch 31/100] [Batch 6] [E loss: 35.241821]\n",
      "[Epoch 31/100] [Batch 7] [E loss: 33.845978]\n",
      "[Epoch 31/100] [Batch 8] [E loss: 39.207638]\n",
      "[Epoch 32/100] [Batch 0] [E loss: 29.177904]\n",
      "[Epoch 32/100] [Batch 1] [E loss: 30.910580]\n",
      "[Epoch 32/100] [Batch 2] [E loss: 32.313377]\n",
      "[Epoch 32/100] [Batch 3] [E loss: 37.436962]\n",
      "[Epoch 32/100] [Batch 4] [E loss: 35.019123]\n",
      "[Epoch 32/100] [Batch 5] [E loss: 31.451237]\n",
      "[Epoch 32/100] [Batch 6] [E loss: 35.241005]\n",
      "[Epoch 32/100] [Batch 7] [E loss: 33.844799]\n",
      "[Epoch 32/100] [Batch 8] [E loss: 39.206799]\n",
      "[Epoch 33/100] [Batch 0] [E loss: 29.177010]\n",
      "[Epoch 33/100] [Batch 1] [E loss: 30.909733]\n",
      "[Epoch 33/100] [Batch 2] [E loss: 32.312359]\n",
      "[Epoch 33/100] [Batch 3] [E loss: 37.436085]\n",
      "[Epoch 33/100] [Batch 4] [E loss: 35.018097]\n",
      "[Epoch 33/100] [Batch 5] [E loss: 31.450169]\n",
      "[Epoch 33/100] [Batch 6] [E loss: 35.239754]\n",
      "[Epoch 33/100] [Batch 7] [E loss: 33.843899]\n",
      "[Epoch 33/100] [Batch 8] [E loss: 39.205906]\n",
      "[Epoch 34/100] [Batch 0] [E loss: 29.176168]\n",
      "[Epoch 34/100] [Batch 1] [E loss: 30.908733]\n",
      "[Epoch 34/100] [Batch 2] [E loss: 32.311604]\n",
      "[Epoch 34/100] [Batch 3] [E loss: 37.434937]\n",
      "[Epoch 34/100] [Batch 4] [E loss: 35.017349]\n",
      "[Epoch 34/100] [Batch 5] [E loss: 31.449398]\n",
      "[Epoch 34/100] [Batch 6] [E loss: 35.239006]\n",
      "[Epoch 34/100] [Batch 7] [E loss: 33.843052]\n",
      "[Epoch 34/100] [Batch 8] [E loss: 39.204815]\n",
      "[Epoch 35/100] [Batch 0] [E loss: 29.175196]\n",
      "[Epoch 35/100] [Batch 1] [E loss: 30.907742]\n",
      "[Epoch 35/100] [Batch 2] [E loss: 32.310638]\n",
      "[Epoch 35/100] [Batch 3] [E loss: 37.434025]\n",
      "[Epoch 35/100] [Batch 4] [E loss: 35.016613]\n",
      "[Epoch 35/100] [Batch 5] [E loss: 31.448534]\n",
      "[Epoch 35/100] [Batch 6] [E loss: 35.237892]\n",
      "[Epoch 35/100] [Batch 7] [E loss: 33.841949]\n",
      "[Epoch 35/100] [Batch 8] [E loss: 39.203709]\n",
      "[Epoch 36/100] [Batch 0] [E loss: 29.174498]\n",
      "[Epoch 36/100] [Batch 1] [E loss: 30.907103]\n",
      "[Epoch 36/100] [Batch 2] [E loss: 32.309864]\n",
      "[Epoch 36/100] [Batch 3] [E loss: 37.433086]\n",
      "[Epoch 36/100] [Batch 4] [E loss: 35.016167]\n",
      "[Epoch 36/100] [Batch 5] [E loss: 31.447695]\n",
      "[Epoch 36/100] [Batch 6] [E loss: 35.237133]\n",
      "[Epoch 36/100] [Batch 7] [E loss: 33.841179]\n",
      "[Epoch 36/100] [Batch 8] [E loss: 39.202972]\n",
      "[Epoch 37/100] [Batch 0] [E loss: 29.173725]\n",
      "[Epoch 37/100] [Batch 1] [E loss: 30.906124]\n",
      "[Epoch 37/100] [Batch 2] [E loss: 32.309093]\n",
      "[Epoch 37/100] [Batch 3] [E loss: 37.432236]\n",
      "[Epoch 37/100] [Batch 4] [E loss: 35.015396]\n",
      "[Epoch 37/100] [Batch 5] [E loss: 31.446611]\n",
      "[Epoch 37/100] [Batch 6] [E loss: 35.236088]\n",
      "[Epoch 37/100] [Batch 7] [E loss: 33.840176]\n",
      "[Epoch 37/100] [Batch 8] [E loss: 39.201824]\n",
      "[Epoch 38/100] [Batch 0] [E loss: 29.172800]\n",
      "[Epoch 38/100] [Batch 1] [E loss: 30.905125]\n",
      "[Epoch 38/100] [Batch 2] [E loss: 32.308327]\n",
      "[Epoch 38/100] [Batch 3] [E loss: 37.431423]\n",
      "[Epoch 38/100] [Batch 4] [E loss: 35.014698]\n",
      "[Epoch 38/100] [Batch 5] [E loss: 31.445667]\n",
      "[Epoch 38/100] [Batch 6] [E loss: 35.235336]\n",
      "[Epoch 38/100] [Batch 7] [E loss: 33.839397]\n",
      "[Epoch 38/100] [Batch 8] [E loss: 39.201122]\n",
      "[Epoch 39/100] [Batch 0] [E loss: 29.172045]\n",
      "[Epoch 39/100] [Batch 1] [E loss: 30.904316]\n",
      "[Epoch 39/100] [Batch 2] [E loss: 32.307415]\n",
      "[Epoch 39/100] [Batch 3] [E loss: 37.430153]\n",
      "[Epoch 39/100] [Batch 4] [E loss: 35.013905]\n",
      "[Epoch 39/100] [Batch 5] [E loss: 31.444698]\n",
      "[Epoch 39/100] [Batch 6] [E loss: 35.233940]\n",
      "[Epoch 39/100] [Batch 7] [E loss: 33.838463]\n",
      "[Epoch 39/100] [Batch 8] [E loss: 39.199772]\n",
      "[Epoch 40/100] [Batch 0] [E loss: 29.171030]\n",
      "[Epoch 40/100] [Batch 1] [E loss: 30.903658]\n",
      "[Epoch 40/100] [Batch 2] [E loss: 32.306431]\n",
      "[Epoch 40/100] [Batch 3] [E loss: 37.429321]\n",
      "[Epoch 40/100] [Batch 4] [E loss: 35.013126]\n",
      "[Epoch 40/100] [Batch 5] [E loss: 31.444038]\n",
      "[Epoch 40/100] [Batch 6] [E loss: 35.233257]\n",
      "[Epoch 40/100] [Batch 7] [E loss: 33.837803]\n",
      "[Epoch 40/100] [Batch 8] [E loss: 39.199139]\n",
      "[Epoch 41/100] [Batch 0] [E loss: 29.170406]\n",
      "[Epoch 41/100] [Batch 1] [E loss: 30.902851]\n",
      "[Epoch 41/100] [Batch 2] [E loss: 32.305676]\n",
      "[Epoch 41/100] [Batch 3] [E loss: 37.428574]\n",
      "[Epoch 41/100] [Batch 4] [E loss: 35.012798]\n",
      "[Epoch 41/100] [Batch 5] [E loss: 31.443340]\n",
      "[Epoch 41/100] [Batch 6] [E loss: 35.232834]\n",
      "[Epoch 41/100] [Batch 7] [E loss: 33.836861]\n",
      "[Epoch 41/100] [Batch 8] [E loss: 39.198399]\n",
      "[Epoch 42/100] [Batch 0] [E loss: 29.169447]\n",
      "[Epoch 42/100] [Batch 1] [E loss: 30.902027]\n",
      "[Epoch 42/100] [Batch 2] [E loss: 32.304905]\n",
      "[Epoch 42/100] [Batch 3] [E loss: 37.427700]\n",
      "[Epoch 42/100] [Batch 4] [E loss: 35.012058]\n",
      "[Epoch 42/100] [Batch 5] [E loss: 31.442553]\n",
      "[Epoch 42/100] [Batch 6] [E loss: 35.231853]\n",
      "[Epoch 42/100] [Batch 7] [E loss: 33.835972]\n",
      "[Epoch 42/100] [Batch 8] [E loss: 39.197418]\n",
      "[Epoch 43/100] [Batch 0] [E loss: 29.168978]\n",
      "[Epoch 43/100] [Batch 1] [E loss: 30.901127]\n",
      "[Epoch 43/100] [Batch 2] [E loss: 32.304379]\n",
      "[Epoch 43/100] [Batch 3] [E loss: 37.426811]\n",
      "[Epoch 43/100] [Batch 4] [E loss: 35.011662]\n",
      "[Epoch 43/100] [Batch 5] [E loss: 31.441528]\n",
      "[Epoch 43/100] [Batch 6] [E loss: 35.230766]\n",
      "[Epoch 43/100] [Batch 7] [E loss: 33.835278]\n",
      "[Epoch 43/100] [Batch 8] [E loss: 39.196781]\n",
      "[Epoch 44/100] [Batch 0] [E loss: 29.168232]\n",
      "[Epoch 44/100] [Batch 1] [E loss: 30.900612]\n",
      "[Epoch 44/100] [Batch 2] [E loss: 32.303635]\n",
      "[Epoch 44/100] [Batch 3] [E loss: 37.426460]\n",
      "[Epoch 44/100] [Batch 4] [E loss: 35.010929]\n",
      "[Epoch 44/100] [Batch 5] [E loss: 31.440805]\n",
      "[Epoch 44/100] [Batch 6] [E loss: 35.229969]\n",
      "[Epoch 44/100] [Batch 7] [E loss: 33.834549]\n",
      "[Epoch 44/100] [Batch 8] [E loss: 39.195683]\n",
      "[Epoch 45/100] [Batch 0] [E loss: 29.167200]\n",
      "[Epoch 45/100] [Batch 1] [E loss: 30.899536]\n",
      "[Epoch 45/100] [Batch 2] [E loss: 32.302582]\n",
      "[Epoch 45/100] [Batch 3] [E loss: 37.425072]\n",
      "[Epoch 45/100] [Batch 4] [E loss: 35.010292]\n",
      "[Epoch 45/100] [Batch 5] [E loss: 31.440159]\n",
      "[Epoch 45/100] [Batch 6] [E loss: 35.229252]\n",
      "[Epoch 45/100] [Batch 7] [E loss: 33.833725]\n",
      "[Epoch 45/100] [Batch 8] [E loss: 39.195023]\n",
      "[Epoch 46/100] [Batch 0] [E loss: 29.166695]\n",
      "[Epoch 46/100] [Batch 1] [E loss: 30.898788]\n",
      "[Epoch 46/100] [Batch 2] [E loss: 32.301979]\n",
      "[Epoch 46/100] [Batch 3] [E loss: 37.424435]\n",
      "[Epoch 46/100] [Batch 4] [E loss: 35.009666]\n",
      "[Epoch 46/100] [Batch 5] [E loss: 31.439503]\n",
      "[Epoch 46/100] [Batch 6] [E loss: 35.228481]\n",
      "[Epoch 46/100] [Batch 7] [E loss: 33.832905]\n",
      "[Epoch 46/100] [Batch 8] [E loss: 39.194286]\n",
      "[Epoch 47/100] [Batch 0] [E loss: 29.165804]\n",
      "[Epoch 47/100] [Batch 1] [E loss: 30.898167]\n",
      "[Epoch 47/100] [Batch 2] [E loss: 32.301186]\n",
      "[Epoch 47/100] [Batch 3] [E loss: 37.423359]\n",
      "[Epoch 47/100] [Batch 4] [E loss: 35.009281]\n",
      "[Epoch 47/100] [Batch 5] [E loss: 31.438709]\n",
      "[Epoch 47/100] [Batch 6] [E loss: 35.227573]\n",
      "[Epoch 47/100] [Batch 7] [E loss: 33.832283]\n",
      "[Epoch 47/100] [Batch 8] [E loss: 39.193562]\n",
      "[Epoch 48/100] [Batch 0] [E loss: 29.165279]\n",
      "[Epoch 48/100] [Batch 1] [E loss: 30.897413]\n",
      "[Epoch 48/100] [Batch 2] [E loss: 32.300282]\n",
      "[Epoch 48/100] [Batch 3] [E loss: 37.422482]\n",
      "[Epoch 48/100] [Batch 4] [E loss: 35.008476]\n",
      "[Epoch 48/100] [Batch 5] [E loss: 31.437838]\n",
      "[Epoch 48/100] [Batch 6] [E loss: 35.226685]\n",
      "[Epoch 48/100] [Batch 7] [E loss: 33.831467]\n",
      "[Epoch 48/100] [Batch 8] [E loss: 39.192581]\n",
      "[Epoch 49/100] [Batch 0] [E loss: 29.164488]\n",
      "[Epoch 49/100] [Batch 1] [E loss: 30.896744]\n",
      "[Epoch 49/100] [Batch 2] [E loss: 32.299702]\n",
      "[Epoch 49/100] [Batch 3] [E loss: 37.421783]\n",
      "[Epoch 49/100] [Batch 4] [E loss: 35.008030]\n",
      "[Epoch 49/100] [Batch 5] [E loss: 31.437347]\n",
      "[Epoch 49/100] [Batch 6] [E loss: 35.226345]\n",
      "[Epoch 49/100] [Batch 7] [E loss: 33.830620]\n",
      "[Epoch 49/100] [Batch 8] [E loss: 39.191837]\n",
      "[Epoch 50/100] [Batch 0] [E loss: 29.163769]\n",
      "[Epoch 50/100] [Batch 1] [E loss: 30.896160]\n",
      "[Epoch 50/100] [Batch 2] [E loss: 32.298870]\n",
      "[Epoch 50/100] [Batch 3] [E loss: 37.421116]\n",
      "[Epoch 50/100] [Batch 4] [E loss: 35.007656]\n",
      "[Epoch 50/100] [Batch 5] [E loss: 31.436758]\n",
      "[Epoch 50/100] [Batch 6] [E loss: 35.225800]\n",
      "[Epoch 50/100] [Batch 7] [E loss: 33.829926]\n",
      "[Epoch 50/100] [Batch 8] [E loss: 39.191303]\n",
      "[Epoch 51/100] [Batch 0] [E loss: 29.163322]\n",
      "[Epoch 51/100] [Batch 1] [E loss: 30.895332]\n",
      "[Epoch 51/100] [Batch 2] [E loss: 32.298313]\n",
      "[Epoch 51/100] [Batch 3] [E loss: 37.420361]\n",
      "[Epoch 51/100] [Batch 4] [E loss: 35.006996]\n",
      "[Epoch 51/100] [Batch 5] [E loss: 31.435989]\n",
      "[Epoch 51/100] [Batch 6] [E loss: 35.225086]\n",
      "[Epoch 51/100] [Batch 7] [E loss: 33.829433]\n",
      "[Epoch 51/100] [Batch 8] [E loss: 39.190308]\n",
      "[Epoch 52/100] [Batch 0] [E loss: 29.162626]\n",
      "[Epoch 52/100] [Batch 1] [E loss: 30.894644]\n",
      "[Epoch 52/100] [Batch 2] [E loss: 32.297569]\n",
      "[Epoch 52/100] [Batch 3] [E loss: 37.419575]\n",
      "[Epoch 52/100] [Batch 4] [E loss: 35.006565]\n",
      "[Epoch 52/100] [Batch 5] [E loss: 31.435369]\n",
      "[Epoch 52/100] [Batch 6] [E loss: 35.224483]\n",
      "[Epoch 52/100] [Batch 7] [E loss: 33.828594]\n",
      "[Epoch 52/100] [Batch 8] [E loss: 39.189747]\n",
      "[Epoch 53/100] [Batch 0] [E loss: 29.162182]\n",
      "[Epoch 53/100] [Batch 1] [E loss: 30.893970]\n",
      "[Epoch 53/100] [Batch 2] [E loss: 32.296875]\n",
      "[Epoch 53/100] [Batch 3] [E loss: 37.418686]\n",
      "[Epoch 53/100] [Batch 4] [E loss: 35.006172]\n",
      "[Epoch 53/100] [Batch 5] [E loss: 31.434824]\n",
      "[Epoch 53/100] [Batch 6] [E loss: 35.223877]\n",
      "[Epoch 53/100] [Batch 7] [E loss: 33.827839]\n",
      "[Epoch 53/100] [Batch 8] [E loss: 39.188980]\n",
      "[Epoch 54/100] [Batch 0] [E loss: 29.161318]\n",
      "[Epoch 54/100] [Batch 1] [E loss: 30.893452]\n",
      "[Epoch 54/100] [Batch 2] [E loss: 32.296261]\n",
      "[Epoch 54/100] [Batch 3] [E loss: 37.418137]\n",
      "[Epoch 54/100] [Batch 4] [E loss: 35.005470]\n",
      "[Epoch 54/100] [Batch 5] [E loss: 31.433966]\n",
      "[Epoch 54/100] [Batch 6] [E loss: 35.223289]\n",
      "[Epoch 54/100] [Batch 7] [E loss: 33.826973]\n",
      "[Epoch 54/100] [Batch 8] [E loss: 39.188267]\n",
      "[Epoch 55/100] [Batch 0] [E loss: 29.160582]\n",
      "[Epoch 55/100] [Batch 1] [E loss: 30.892580]\n",
      "[Epoch 55/100] [Batch 2] [E loss: 32.295578]\n",
      "[Epoch 55/100] [Batch 3] [E loss: 37.417152]\n",
      "[Epoch 55/100] [Batch 4] [E loss: 35.004856]\n",
      "[Epoch 55/100] [Batch 5] [E loss: 31.433338]\n",
      "[Epoch 55/100] [Batch 6] [E loss: 35.222481]\n",
      "[Epoch 55/100] [Batch 7] [E loss: 33.826500]\n",
      "[Epoch 55/100] [Batch 8] [E loss: 39.187775]\n",
      "[Epoch 56/100] [Batch 0] [E loss: 29.160021]\n",
      "[Epoch 56/100] [Batch 1] [E loss: 30.892178]\n",
      "[Epoch 56/100] [Batch 2] [E loss: 32.294724]\n",
      "[Epoch 56/100] [Batch 3] [E loss: 37.416615]\n",
      "[Epoch 56/100] [Batch 4] [E loss: 35.004459]\n",
      "[Epoch 56/100] [Batch 5] [E loss: 31.432833]\n",
      "[Epoch 56/100] [Batch 6] [E loss: 35.222031]\n",
      "[Epoch 56/100] [Batch 7] [E loss: 33.825962]\n",
      "[Epoch 56/100] [Batch 8] [E loss: 39.187134]\n",
      "[Epoch 57/100] [Batch 0] [E loss: 29.159264]\n",
      "[Epoch 57/100] [Batch 1] [E loss: 30.891294]\n",
      "[Epoch 57/100] [Batch 2] [E loss: 32.294201]\n",
      "[Epoch 57/100] [Batch 3] [E loss: 37.415894]\n",
      "[Epoch 57/100] [Batch 4] [E loss: 35.003750]\n",
      "[Epoch 57/100] [Batch 5] [E loss: 31.432291]\n",
      "[Epoch 57/100] [Batch 6] [E loss: 35.221359]\n",
      "[Epoch 57/100] [Batch 7] [E loss: 33.825161]\n",
      "[Epoch 57/100] [Batch 8] [E loss: 39.186337]\n",
      "[Epoch 58/100] [Batch 0] [E loss: 29.158594]\n",
      "[Epoch 58/100] [Batch 1] [E loss: 30.890560]\n",
      "[Epoch 58/100] [Batch 2] [E loss: 32.293381]\n",
      "[Epoch 58/100] [Batch 3] [E loss: 37.415073]\n",
      "[Epoch 58/100] [Batch 4] [E loss: 35.003296]\n",
      "[Epoch 58/100] [Batch 5] [E loss: 31.431452]\n",
      "[Epoch 58/100] [Batch 6] [E loss: 35.220829]\n",
      "[Epoch 58/100] [Batch 7] [E loss: 33.824413]\n",
      "[Epoch 58/100] [Batch 8] [E loss: 39.185764]\n",
      "[Epoch 59/100] [Batch 0] [E loss: 29.158079]\n",
      "[Epoch 59/100] [Batch 1] [E loss: 30.890041]\n",
      "[Epoch 59/100] [Batch 2] [E loss: 32.292740]\n",
      "[Epoch 59/100] [Batch 3] [E loss: 37.414162]\n",
      "[Epoch 59/100] [Batch 4] [E loss: 35.002743]\n",
      "[Epoch 59/100] [Batch 5] [E loss: 31.431038]\n",
      "[Epoch 59/100] [Batch 6] [E loss: 35.220074]\n",
      "[Epoch 59/100] [Batch 7] [E loss: 33.823929]\n",
      "[Epoch 59/100] [Batch 8] [E loss: 39.184998]\n",
      "[Epoch 60/100] [Batch 0] [E loss: 29.157499]\n",
      "[Epoch 60/100] [Batch 1] [E loss: 30.889202]\n",
      "[Epoch 60/100] [Batch 2] [E loss: 32.292007]\n",
      "[Epoch 60/100] [Batch 3] [E loss: 37.413460]\n",
      "[Epoch 60/100] [Batch 4] [E loss: 35.002380]\n",
      "[Epoch 60/100] [Batch 5] [E loss: 31.430321]\n",
      "[Epoch 60/100] [Batch 6] [E loss: 35.219692]\n",
      "[Epoch 60/100] [Batch 7] [E loss: 33.823204]\n",
      "[Epoch 60/100] [Batch 8] [E loss: 39.184502]\n",
      "[Epoch 61/100] [Batch 0] [E loss: 29.157200]\n",
      "[Epoch 61/100] [Batch 1] [E loss: 30.888889]\n",
      "[Epoch 61/100] [Batch 2] [E loss: 32.291454]\n",
      "[Epoch 61/100] [Batch 3] [E loss: 37.413113]\n",
      "[Epoch 61/100] [Batch 4] [E loss: 35.001633]\n",
      "[Epoch 61/100] [Batch 5] [E loss: 31.429848]\n",
      "[Epoch 61/100] [Batch 6] [E loss: 35.219009]\n",
      "[Epoch 61/100] [Batch 7] [E loss: 33.822830]\n",
      "[Epoch 61/100] [Batch 8] [E loss: 39.183857]\n",
      "[Epoch 62/100] [Batch 0] [E loss: 29.156279]\n",
      "[Epoch 62/100] [Batch 1] [E loss: 30.888155]\n",
      "[Epoch 62/100] [Batch 2] [E loss: 32.290749]\n",
      "[Epoch 62/100] [Batch 3] [E loss: 37.412220]\n",
      "[Epoch 62/100] [Batch 4] [E loss: 35.001305]\n",
      "[Epoch 62/100] [Batch 5] [E loss: 31.429094]\n",
      "[Epoch 62/100] [Batch 6] [E loss: 35.218346]\n",
      "[Epoch 62/100] [Batch 7] [E loss: 33.822281]\n",
      "[Epoch 62/100] [Batch 8] [E loss: 39.183224]\n",
      "[Epoch 63/100] [Batch 0] [E loss: 29.156124]\n",
      "[Epoch 63/100] [Batch 1] [E loss: 30.887815]\n",
      "[Epoch 63/100] [Batch 2] [E loss: 32.290169]\n",
      "[Epoch 63/100] [Batch 3] [E loss: 37.411682]\n",
      "[Epoch 63/100] [Batch 4] [E loss: 35.000965]\n",
      "[Epoch 63/100] [Batch 5] [E loss: 31.428654]\n",
      "[Epoch 63/100] [Batch 6] [E loss: 35.217770]\n",
      "[Epoch 63/100] [Batch 7] [E loss: 33.821766]\n",
      "[Epoch 63/100] [Batch 8] [E loss: 39.182625]\n",
      "[Epoch 64/100] [Batch 0] [E loss: 29.155615]\n",
      "[Epoch 64/100] [Batch 1] [E loss: 30.887175]\n",
      "[Epoch 64/100] [Batch 2] [E loss: 32.289703]\n",
      "[Epoch 64/100] [Batch 3] [E loss: 37.411110]\n",
      "[Epoch 64/100] [Batch 4] [E loss: 35.000427]\n",
      "[Epoch 64/100] [Batch 5] [E loss: 31.428205]\n",
      "[Epoch 64/100] [Batch 6] [E loss: 35.217403]\n",
      "[Epoch 64/100] [Batch 7] [E loss: 33.821312]\n",
      "[Epoch 64/100] [Batch 8] [E loss: 39.182068]\n",
      "[Epoch 65/100] [Batch 0] [E loss: 29.155006]\n",
      "[Epoch 65/100] [Batch 1] [E loss: 30.886665]\n",
      "[Epoch 65/100] [Batch 2] [E loss: 32.289074]\n",
      "[Epoch 65/100] [Batch 3] [E loss: 37.410351]\n",
      "[Epoch 65/100] [Batch 4] [E loss: 34.999920]\n",
      "[Epoch 65/100] [Batch 5] [E loss: 31.427631]\n",
      "[Epoch 65/100] [Batch 6] [E loss: 35.216770]\n",
      "[Epoch 65/100] [Batch 7] [E loss: 33.820576]\n",
      "[Epoch 65/100] [Batch 8] [E loss: 39.181534]\n",
      "[Epoch 66/100] [Batch 0] [E loss: 29.154480]\n",
      "[Epoch 66/100] [Batch 1] [E loss: 30.885843]\n",
      "[Epoch 66/100] [Batch 2] [E loss: 32.288551]\n",
      "[Epoch 66/100] [Batch 3] [E loss: 37.409542]\n",
      "[Epoch 66/100] [Batch 4] [E loss: 34.999535]\n",
      "[Epoch 66/100] [Batch 5] [E loss: 31.427013]\n",
      "[Epoch 66/100] [Batch 6] [E loss: 35.216358]\n",
      "[Epoch 66/100] [Batch 7] [E loss: 33.820042]\n",
      "[Epoch 66/100] [Batch 8] [E loss: 39.181000]\n",
      "[Epoch 67/100] [Batch 0] [E loss: 29.154081]\n",
      "[Epoch 67/100] [Batch 1] [E loss: 30.885475]\n",
      "[Epoch 67/100] [Batch 2] [E loss: 32.287647]\n",
      "[Epoch 67/100] [Batch 3] [E loss: 37.408947]\n",
      "[Epoch 67/100] [Batch 4] [E loss: 34.998955]\n",
      "[Epoch 67/100] [Batch 5] [E loss: 31.426435]\n",
      "[Epoch 67/100] [Batch 6] [E loss: 35.215698]\n",
      "[Epoch 67/100] [Batch 7] [E loss: 33.819408]\n",
      "[Epoch 67/100] [Batch 8] [E loss: 39.180389]\n",
      "[Epoch 68/100] [Batch 0] [E loss: 29.153225]\n",
      "[Epoch 68/100] [Batch 1] [E loss: 30.884714]\n",
      "[Epoch 68/100] [Batch 2] [E loss: 32.287212]\n",
      "[Epoch 68/100] [Batch 3] [E loss: 37.408379]\n",
      "[Epoch 68/100] [Batch 4] [E loss: 34.998669]\n",
      "[Epoch 68/100] [Batch 5] [E loss: 31.425976]\n",
      "[Epoch 68/100] [Batch 6] [E loss: 35.215294]\n",
      "[Epoch 68/100] [Batch 7] [E loss: 33.819122]\n",
      "[Epoch 68/100] [Batch 8] [E loss: 39.179981]\n",
      "[Epoch 69/100] [Batch 0] [E loss: 29.152744]\n",
      "[Epoch 69/100] [Batch 1] [E loss: 30.884363]\n",
      "[Epoch 69/100] [Batch 2] [E loss: 32.286594]\n",
      "[Epoch 69/100] [Batch 3] [E loss: 37.407566]\n",
      "[Epoch 69/100] [Batch 4] [E loss: 34.998177]\n",
      "[Epoch 69/100] [Batch 5] [E loss: 31.425547]\n",
      "[Epoch 69/100] [Batch 6] [E loss: 35.214760]\n",
      "[Epoch 69/100] [Batch 7] [E loss: 33.818596]\n",
      "[Epoch 69/100] [Batch 8] [E loss: 39.179306]\n",
      "[Epoch 70/100] [Batch 0] [E loss: 29.152391]\n",
      "[Epoch 70/100] [Batch 1] [E loss: 30.883808]\n",
      "[Epoch 70/100] [Batch 2] [E loss: 32.286091]\n",
      "[Epoch 70/100] [Batch 3] [E loss: 37.407108]\n",
      "[Epoch 70/100] [Batch 4] [E loss: 34.997887]\n",
      "[Epoch 70/100] [Batch 5] [E loss: 31.424955]\n",
      "[Epoch 70/100] [Batch 6] [E loss: 35.214245]\n",
      "[Epoch 70/100] [Batch 7] [E loss: 33.817875]\n",
      "[Epoch 70/100] [Batch 8] [E loss: 39.178978]\n",
      "[Epoch 71/100] [Batch 0] [E loss: 29.151951]\n",
      "[Epoch 71/100] [Batch 1] [E loss: 30.883410]\n",
      "[Epoch 71/100] [Batch 2] [E loss: 32.285686]\n",
      "[Epoch 71/100] [Batch 3] [E loss: 37.406609]\n",
      "[Epoch 71/100] [Batch 4] [E loss: 34.997547]\n",
      "[Epoch 71/100] [Batch 5] [E loss: 31.424417]\n",
      "[Epoch 71/100] [Batch 6] [E loss: 35.213585]\n",
      "[Epoch 71/100] [Batch 7] [E loss: 33.817444]\n",
      "[Epoch 71/100] [Batch 8] [E loss: 39.178288]\n",
      "[Epoch 72/100] [Batch 0] [E loss: 29.151262]\n",
      "[Epoch 72/100] [Batch 1] [E loss: 30.882849]\n",
      "[Epoch 72/100] [Batch 2] [E loss: 32.284950]\n",
      "[Epoch 72/100] [Batch 3] [E loss: 37.405937]\n",
      "[Epoch 72/100] [Batch 4] [E loss: 34.996716]\n",
      "[Epoch 72/100] [Batch 5] [E loss: 31.423874]\n",
      "[Epoch 72/100] [Batch 6] [E loss: 35.212875]\n",
      "[Epoch 72/100] [Batch 7] [E loss: 33.816917]\n",
      "[Epoch 72/100] [Batch 8] [E loss: 39.177700]\n",
      "[Epoch 73/100] [Batch 0] [E loss: 29.150846]\n",
      "[Epoch 73/100] [Batch 1] [E loss: 30.882477]\n",
      "[Epoch 73/100] [Batch 2] [E loss: 32.284477]\n",
      "[Epoch 73/100] [Batch 3] [E loss: 37.405293]\n",
      "[Epoch 73/100] [Batch 4] [E loss: 34.996353]\n",
      "[Epoch 73/100] [Batch 5] [E loss: 31.423315]\n",
      "[Epoch 73/100] [Batch 6] [E loss: 35.212517]\n",
      "[Epoch 73/100] [Batch 7] [E loss: 33.816582]\n",
      "[Epoch 73/100] [Batch 8] [E loss: 39.177235]\n",
      "[Epoch 74/100] [Batch 0] [E loss: 29.150251]\n",
      "[Epoch 74/100] [Batch 1] [E loss: 30.881676]\n",
      "[Epoch 74/100] [Batch 2] [E loss: 32.283688]\n",
      "[Epoch 74/100] [Batch 3] [E loss: 37.404610]\n",
      "[Epoch 74/100] [Batch 4] [E loss: 34.995998]\n",
      "[Epoch 74/100] [Batch 5] [E loss: 31.422846]\n",
      "[Epoch 74/100] [Batch 6] [E loss: 35.211998]\n",
      "[Epoch 74/100] [Batch 7] [E loss: 33.816135]\n",
      "[Epoch 74/100] [Batch 8] [E loss: 39.176559]\n",
      "[Epoch 75/100] [Batch 0] [E loss: 29.150084]\n",
      "[Epoch 75/100] [Batch 1] [E loss: 30.881409]\n",
      "[Epoch 75/100] [Batch 2] [E loss: 32.283424]\n",
      "[Epoch 75/100] [Batch 3] [E loss: 37.404194]\n",
      "[Epoch 75/100] [Batch 4] [E loss: 34.995567]\n",
      "[Epoch 75/100] [Batch 5] [E loss: 31.422342]\n",
      "[Epoch 75/100] [Batch 6] [E loss: 35.211502]\n",
      "[Epoch 75/100] [Batch 7] [E loss: 33.815552]\n",
      "[Epoch 75/100] [Batch 8] [E loss: 39.176327]\n",
      "[Epoch 76/100] [Batch 0] [E loss: 29.149309]\n",
      "[Epoch 76/100] [Batch 1] [E loss: 30.880873]\n",
      "[Epoch 76/100] [Batch 2] [E loss: 32.282578]\n",
      "[Epoch 76/100] [Batch 3] [E loss: 37.403736]\n",
      "[Epoch 76/100] [Batch 4] [E loss: 34.995224]\n",
      "[Epoch 76/100] [Batch 5] [E loss: 31.421873]\n",
      "[Epoch 76/100] [Batch 6] [E loss: 35.211079]\n",
      "[Epoch 76/100] [Batch 7] [E loss: 33.814934]\n",
      "[Epoch 76/100] [Batch 8] [E loss: 39.175724]\n",
      "[Epoch 77/100] [Batch 0] [E loss: 29.148960]\n",
      "[Epoch 77/100] [Batch 1] [E loss: 30.880222]\n",
      "[Epoch 77/100] [Batch 2] [E loss: 32.282082]\n",
      "[Epoch 77/100] [Batch 3] [E loss: 37.403149]\n",
      "[Epoch 77/100] [Batch 4] [E loss: 34.994907]\n",
      "[Epoch 77/100] [Batch 5] [E loss: 31.421350]\n",
      "[Epoch 77/100] [Batch 6] [E loss: 35.210423]\n",
      "[Epoch 77/100] [Batch 7] [E loss: 33.814686]\n",
      "[Epoch 77/100] [Batch 8] [E loss: 39.175247]\n",
      "[Epoch 78/100] [Batch 0] [E loss: 29.148565]\n",
      "[Epoch 78/100] [Batch 1] [E loss: 30.879961]\n",
      "[Epoch 78/100] [Batch 2] [E loss: 32.281563]\n",
      "[Epoch 78/100] [Batch 3] [E loss: 37.402470]\n",
      "[Epoch 78/100] [Batch 4] [E loss: 34.994823]\n",
      "[Epoch 78/100] [Batch 5] [E loss: 31.420883]\n",
      "[Epoch 78/100] [Batch 6] [E loss: 35.210003]\n",
      "[Epoch 78/100] [Batch 7] [E loss: 33.814056]\n",
      "[Epoch 78/100] [Batch 8] [E loss: 39.174717]\n",
      "[Epoch 79/100] [Batch 0] [E loss: 29.148018]\n",
      "[Epoch 79/100] [Batch 1] [E loss: 30.879450]\n",
      "[Epoch 79/100] [Batch 2] [E loss: 32.280972]\n",
      "[Epoch 79/100] [Batch 3] [E loss: 37.401974]\n",
      "[Epoch 79/100] [Batch 4] [E loss: 34.994102]\n",
      "[Epoch 79/100] [Batch 5] [E loss: 31.420218]\n",
      "[Epoch 79/100] [Batch 6] [E loss: 35.209454]\n",
      "[Epoch 79/100] [Batch 7] [E loss: 33.813633]\n",
      "[Epoch 79/100] [Batch 8] [E loss: 39.174347]\n",
      "[Epoch 80/100] [Batch 0] [E loss: 29.147720]\n",
      "[Epoch 80/100] [Batch 1] [E loss: 30.878819]\n",
      "[Epoch 80/100] [Batch 2] [E loss: 32.280693]\n",
      "[Epoch 80/100] [Batch 3] [E loss: 37.401569]\n",
      "[Epoch 80/100] [Batch 4] [E loss: 34.993809]\n",
      "[Epoch 80/100] [Batch 5] [E loss: 31.419903]\n",
      "[Epoch 80/100] [Batch 6] [E loss: 35.209141]\n",
      "[Epoch 80/100] [Batch 7] [E loss: 33.813202]\n",
      "[Epoch 80/100] [Batch 8] [E loss: 39.173950]\n",
      "[Epoch 81/100] [Batch 0] [E loss: 29.147264]\n",
      "[Epoch 81/100] [Batch 1] [E loss: 30.878422]\n",
      "[Epoch 81/100] [Batch 2] [E loss: 32.280220]\n",
      "[Epoch 81/100] [Batch 3] [E loss: 37.401115]\n",
      "[Epoch 81/100] [Batch 4] [E loss: 34.993137]\n",
      "[Epoch 81/100] [Batch 5] [E loss: 31.419333]\n",
      "[Epoch 81/100] [Batch 6] [E loss: 35.208481]\n",
      "[Epoch 81/100] [Batch 7] [E loss: 33.812969]\n",
      "[Epoch 81/100] [Batch 8] [E loss: 39.173290]\n",
      "[Epoch 82/100] [Batch 0] [E loss: 29.146791]\n",
      "[Epoch 82/100] [Batch 1] [E loss: 30.877995]\n",
      "[Epoch 82/100] [Batch 2] [E loss: 32.279552]\n",
      "[Epoch 82/100] [Batch 3] [E loss: 37.400665]\n",
      "[Epoch 82/100] [Batch 4] [E loss: 34.992981]\n",
      "[Epoch 82/100] [Batch 5] [E loss: 31.418964]\n",
      "[Epoch 82/100] [Batch 6] [E loss: 35.208260]\n",
      "[Epoch 82/100] [Batch 7] [E loss: 33.812286]\n",
      "[Epoch 82/100] [Batch 8] [E loss: 39.172958]\n",
      "[Epoch 83/100] [Batch 0] [E loss: 29.146271]\n",
      "[Epoch 83/100] [Batch 1] [E loss: 30.877594]\n",
      "[Epoch 83/100] [Batch 2] [E loss: 32.279121]\n",
      "[Epoch 83/100] [Batch 3] [E loss: 37.400055]\n",
      "[Epoch 83/100] [Batch 4] [E loss: 34.992561]\n",
      "[Epoch 83/100] [Batch 5] [E loss: 31.418493]\n",
      "[Epoch 83/100] [Batch 6] [E loss: 35.207687]\n",
      "[Epoch 83/100] [Batch 7] [E loss: 33.812050]\n",
      "[Epoch 83/100] [Batch 8] [E loss: 39.172447]\n",
      "[Epoch 84/100] [Batch 0] [E loss: 29.145931]\n",
      "[Epoch 84/100] [Batch 1] [E loss: 30.877216]\n",
      "[Epoch 84/100] [Batch 2] [E loss: 32.278656]\n",
      "[Epoch 84/100] [Batch 3] [E loss: 37.399586]\n",
      "[Epoch 84/100] [Batch 4] [E loss: 34.992245]\n",
      "[Epoch 84/100] [Batch 5] [E loss: 31.418032]\n",
      "[Epoch 84/100] [Batch 6] [E loss: 35.207111]\n",
      "[Epoch 84/100] [Batch 7] [E loss: 33.811531]\n",
      "[Epoch 84/100] [Batch 8] [E loss: 39.172272]\n",
      "[Epoch 85/100] [Batch 0] [E loss: 29.145576]\n",
      "[Epoch 85/100] [Batch 1] [E loss: 30.876757]\n",
      "[Epoch 85/100] [Batch 2] [E loss: 32.278355]\n",
      "[Epoch 85/100] [Batch 3] [E loss: 37.398945]\n",
      "[Epoch 85/100] [Batch 4] [E loss: 34.991764]\n",
      "[Epoch 85/100] [Batch 5] [E loss: 31.417789]\n",
      "[Epoch 85/100] [Batch 6] [E loss: 35.206776]\n",
      "[Epoch 85/100] [Batch 7] [E loss: 33.811153]\n",
      "[Epoch 85/100] [Batch 8] [E loss: 39.171783]\n",
      "[Epoch 86/100] [Batch 0] [E loss: 29.145126]\n",
      "[Epoch 86/100] [Batch 1] [E loss: 30.876492]\n",
      "[Epoch 86/100] [Batch 2] [E loss: 32.277725]\n",
      "[Epoch 86/100] [Batch 3] [E loss: 37.398827]\n",
      "[Epoch 86/100] [Batch 4] [E loss: 34.991451]\n",
      "[Epoch 86/100] [Batch 5] [E loss: 31.417379]\n",
      "[Epoch 86/100] [Batch 6] [E loss: 35.206371]\n",
      "[Epoch 86/100] [Batch 7] [E loss: 33.810654]\n",
      "[Epoch 86/100] [Batch 8] [E loss: 39.171227]\n",
      "[Epoch 87/100] [Batch 0] [E loss: 29.144676]\n",
      "[Epoch 87/100] [Batch 1] [E loss: 30.876007]\n",
      "[Epoch 87/100] [Batch 2] [E loss: 32.277275]\n",
      "[Epoch 87/100] [Batch 3] [E loss: 37.398117]\n",
      "[Epoch 87/100] [Batch 4] [E loss: 34.991230]\n",
      "[Epoch 87/100] [Batch 5] [E loss: 31.417013]\n",
      "[Epoch 87/100] [Batch 6] [E loss: 35.206059]\n",
      "[Epoch 87/100] [Batch 7] [E loss: 33.810131]\n",
      "[Epoch 87/100] [Batch 8] [E loss: 39.170807]\n",
      "[Epoch 88/100] [Batch 0] [E loss: 29.144264]\n",
      "[Epoch 88/100] [Batch 1] [E loss: 30.875488]\n",
      "[Epoch 88/100] [Batch 2] [E loss: 32.276680]\n",
      "[Epoch 88/100] [Batch 3] [E loss: 37.397697]\n",
      "[Epoch 88/100] [Batch 4] [E loss: 34.990589]\n",
      "[Epoch 88/100] [Batch 5] [E loss: 31.416368]\n",
      "[Epoch 88/100] [Batch 6] [E loss: 35.205486]\n",
      "[Epoch 88/100] [Batch 7] [E loss: 33.809822]\n",
      "[Epoch 88/100] [Batch 8] [E loss: 39.170490]\n",
      "[Epoch 89/100] [Batch 0] [E loss: 29.144026]\n",
      "[Epoch 89/100] [Batch 1] [E loss: 30.874998]\n",
      "[Epoch 89/100] [Batch 2] [E loss: 32.276409]\n",
      "[Epoch 89/100] [Batch 3] [E loss: 37.397221]\n",
      "[Epoch 89/100] [Batch 4] [E loss: 34.990658]\n",
      "[Epoch 89/100] [Batch 5] [E loss: 31.416067]\n",
      "[Epoch 89/100] [Batch 6] [E loss: 35.205250]\n",
      "[Epoch 89/100] [Batch 7] [E loss: 33.809654]\n",
      "[Epoch 89/100] [Batch 8] [E loss: 39.170097]\n",
      "[Epoch 90/100] [Batch 0] [E loss: 29.143623]\n",
      "[Epoch 90/100] [Batch 1] [E loss: 30.874783]\n",
      "[Epoch 90/100] [Batch 2] [E loss: 32.275768]\n",
      "[Epoch 90/100] [Batch 3] [E loss: 37.396591]\n",
      "[Epoch 90/100] [Batch 4] [E loss: 34.989998]\n",
      "[Epoch 90/100] [Batch 5] [E loss: 31.415737]\n",
      "[Epoch 90/100] [Batch 6] [E loss: 35.205040]\n",
      "[Epoch 90/100] [Batch 7] [E loss: 33.809113]\n",
      "[Epoch 90/100] [Batch 8] [E loss: 39.169777]\n",
      "[Epoch 91/100] [Batch 0] [E loss: 29.143076]\n",
      "[Epoch 91/100] [Batch 1] [E loss: 30.874321]\n",
      "[Epoch 91/100] [Batch 2] [E loss: 32.275547]\n",
      "[Epoch 91/100] [Batch 3] [E loss: 37.396362]\n",
      "[Epoch 91/100] [Batch 4] [E loss: 34.989685]\n",
      "[Epoch 91/100] [Batch 5] [E loss: 31.415262]\n",
      "[Epoch 91/100] [Batch 6] [E loss: 35.204514]\n",
      "[Epoch 91/100] [Batch 7] [E loss: 33.808647]\n",
      "[Epoch 91/100] [Batch 8] [E loss: 39.169212]\n",
      "[Epoch 92/100] [Batch 0] [E loss: 29.142820]\n",
      "[Epoch 92/100] [Batch 1] [E loss: 30.874079]\n",
      "[Epoch 92/100] [Batch 2] [E loss: 32.275108]\n",
      "[Epoch 92/100] [Batch 3] [E loss: 37.395851]\n",
      "[Epoch 92/100] [Batch 4] [E loss: 34.989254]\n",
      "[Epoch 92/100] [Batch 5] [E loss: 31.414831]\n",
      "[Epoch 92/100] [Batch 6] [E loss: 35.203911]\n",
      "[Epoch 92/100] [Batch 7] [E loss: 33.808399]\n",
      "[Epoch 92/100] [Batch 8] [E loss: 39.168919]\n",
      "[Epoch 93/100] [Batch 0] [E loss: 29.142372]\n",
      "[Epoch 93/100] [Batch 1] [E loss: 30.873638]\n",
      "[Epoch 93/100] [Batch 2] [E loss: 32.274540]\n",
      "[Epoch 93/100] [Batch 3] [E loss: 37.395233]\n",
      "[Epoch 93/100] [Batch 4] [E loss: 34.988998]\n",
      "[Epoch 93/100] [Batch 5] [E loss: 31.414633]\n",
      "[Epoch 93/100] [Batch 6] [E loss: 35.203899]\n",
      "[Epoch 93/100] [Batch 7] [E loss: 33.808174]\n",
      "[Epoch 93/100] [Batch 8] [E loss: 39.168594]\n",
      "[Epoch 94/100] [Batch 0] [E loss: 29.142075]\n",
      "[Epoch 94/100] [Batch 1] [E loss: 30.873451]\n",
      "[Epoch 94/100] [Batch 2] [E loss: 32.274483]\n",
      "[Epoch 94/100] [Batch 3] [E loss: 37.395069]\n",
      "[Epoch 94/100] [Batch 4] [E loss: 34.988926]\n",
      "[Epoch 94/100] [Batch 5] [E loss: 31.414474]\n",
      "[Epoch 94/100] [Batch 6] [E loss: 35.203812]\n",
      "[Epoch 94/100] [Batch 7] [E loss: 33.807789]\n",
      "[Epoch 94/100] [Batch 8] [E loss: 39.168236]\n",
      "[Epoch 95/100] [Batch 0] [E loss: 29.141865]\n",
      "[Epoch 95/100] [Batch 1] [E loss: 30.872822]\n",
      "[Epoch 95/100] [Batch 2] [E loss: 32.274136]\n",
      "[Epoch 95/100] [Batch 3] [E loss: 37.394455]\n",
      "[Epoch 95/100] [Batch 4] [E loss: 34.988369]\n",
      "[Epoch 95/100] [Batch 5] [E loss: 31.413879]\n",
      "[Epoch 95/100] [Batch 6] [E loss: 35.203228]\n",
      "[Epoch 95/100] [Batch 7] [E loss: 33.807327]\n",
      "[Epoch 95/100] [Batch 8] [E loss: 39.167816]\n",
      "[Epoch 96/100] [Batch 0] [E loss: 29.141298]\n",
      "[Epoch 96/100] [Batch 1] [E loss: 30.872503]\n",
      "[Epoch 96/100] [Batch 2] [E loss: 32.273430]\n",
      "[Epoch 96/100] [Batch 3] [E loss: 37.394264]\n",
      "[Epoch 96/100] [Batch 4] [E loss: 34.987961]\n",
      "[Epoch 96/100] [Batch 5] [E loss: 31.413393]\n",
      "[Epoch 96/100] [Batch 6] [E loss: 35.202488]\n",
      "[Epoch 96/100] [Batch 7] [E loss: 33.806957]\n",
      "[Epoch 96/100] [Batch 8] [E loss: 39.167286]\n",
      "[Epoch 97/100] [Batch 0] [E loss: 29.140951]\n",
      "[Epoch 97/100] [Batch 1] [E loss: 30.872114]\n",
      "[Epoch 97/100] [Batch 2] [E loss: 32.273247]\n",
      "[Epoch 97/100] [Batch 3] [E loss: 37.393703]\n",
      "[Epoch 97/100] [Batch 4] [E loss: 34.987915]\n",
      "[Epoch 97/100] [Batch 5] [E loss: 31.413164]\n",
      "[Epoch 97/100] [Batch 6] [E loss: 35.202499]\n",
      "[Epoch 97/100] [Batch 7] [E loss: 33.806488]\n",
      "[Epoch 97/100] [Batch 8] [E loss: 39.167057]\n",
      "[Epoch 98/100] [Batch 0] [E loss: 29.140497]\n",
      "[Epoch 98/100] [Batch 1] [E loss: 30.871817]\n",
      "[Epoch 98/100] [Batch 2] [E loss: 32.272636]\n",
      "[Epoch 98/100] [Batch 3] [E loss: 37.393257]\n",
      "[Epoch 98/100] [Batch 4] [E loss: 34.987225]\n",
      "[Epoch 98/100] [Batch 5] [E loss: 31.412683]\n",
      "[Epoch 98/100] [Batch 6] [E loss: 35.202164]\n",
      "[Epoch 98/100] [Batch 7] [E loss: 33.806194]\n",
      "[Epoch 98/100] [Batch 8] [E loss: 39.166595]\n",
      "[Epoch 99/100] [Batch 0] [E loss: 29.140434]\n",
      "[Epoch 99/100] [Batch 1] [E loss: 30.871420]\n",
      "[Epoch 99/100] [Batch 2] [E loss: 32.272583]\n",
      "[Epoch 99/100] [Batch 3] [E loss: 37.392998]\n",
      "[Epoch 99/100] [Batch 4] [E loss: 34.987206]\n",
      "[Epoch 99/100] [Batch 5] [E loss: 31.412378]\n",
      "[Epoch 99/100] [Batch 6] [E loss: 35.201664]\n",
      "[Epoch 99/100] [Batch 7] [E loss: 33.805828]\n",
      "[Epoch 99/100] [Batch 8] [E loss: 39.166317]\n",
      "[Epoch 100/100] [Batch 0] [E loss: 29.139757]\n",
      "[Epoch 100/100] [Batch 1] [E loss: 30.871145]\n",
      "[Epoch 100/100] [Batch 2] [E loss: 32.271900]\n",
      "[Epoch 100/100] [Batch 3] [E loss: 37.392487]\n",
      "[Epoch 100/100] [Batch 4] [E loss: 34.986797]\n",
      "[Epoch 100/100] [Batch 5] [E loss: 31.412035]\n",
      "[Epoch 100/100] [Batch 6] [E loss: 35.201385]\n",
      "[Epoch 100/100] [Batch 7] [E loss: 33.805683]\n",
      "[Epoch 100/100] [Batch 8] [E loss: 39.165974]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs + 1):\n",
    "    for i in range(0, int(batch_num)):\n",
    "        fmri_data = fmri[i * batch_size:(i + 1) * batch_size]\n",
    "        real_imgs = imgs[i * batch_size:(i + 1) * batch_size]\n",
    "        optimizer.zero_grad()\n",
    "        latent_vector = decoder(fmri_data)\n",
    "        obj_vector = real_imgs.reshape(real_imgs.shape[0], -1)\n",
    "        e_loss = pixelwise_loss(obj_vector, latent_vector)\n",
    "\n",
    "        e_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(\n",
    "            \"[Epoch %d/%d] [Batch %d] [E loss: %f]\"\n",
    "            % (epoch, n_epochs, i, e_loss.item())\n",
    "        )\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        test_fmri_data = fmri[train_num:train_num + batch_size]\n",
    "        latent_v = decoder(test_fmri_data)\n",
    "        latent_v = latent_v.view(batch_size, 1, output_size_2, output_size_2)\n",
    "\n",
    "        tempv = latent_v.data\n",
    "\n",
    "imgs = decoder(fmri)\n",
    "imgs = imgs.view(fmri.shape[0], output_size_2, output_size_2)\n",
    "imgs = imgs.data.cpu() * 255.0\n",
    "imgs = np.asarray(imgs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

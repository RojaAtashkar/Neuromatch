{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Import Libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load the dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3092)\n",
      "(100, 1)\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "fmri_dataset = torch.load('data/fMRI_data/demo1/digits-fmri')\n",
    "# load the labels\n",
    "labels = torch.load('data/images/demo1/raw_imgs/digits-labels') - 1\n",
    "# print the shape\n",
    "print(fmri_dataset.shape)\n",
    "print(labels.shape)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total blocks : 100\n",
      "input fmri size : 3092\n"
     ]
    }
   ],
   "source": [
    "total_blocks = fmri_dataset.shape[0]\n",
    "fmri_size = fmri_dataset.shape[1]\n",
    "print('total blocks : '+str(total_blocks))\n",
    "print('input fmri size : '+str(fmri_size))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 10\n",
    "test_size = 10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# define the model\n",
    "\n",
    "\n",
    "class SemanticDecoder(nn.Module):\n",
    "  \"\"\"\n",
    "  Initialize MLP Network\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, actv, input_feature_num, hidden_unit_nums, output_feature_num):\n",
    "    \"\"\"\n",
    "    Initialize MLP Network parameters\n",
    "\n",
    "    Args:\n",
    "      actv: string\n",
    "        Activation function\n",
    "      input_feature_num: int\n",
    "        Number of input features\n",
    "      hidden_unit_nums: list\n",
    "        Number of units in the hidden layer\n",
    "      output_feature_num: int\n",
    "        Number of output features\n",
    "\n",
    "    Returns:\n",
    "      Nothing\n",
    "    \"\"\"\n",
    "    super(SemanticDecoder, self).__init__()\n",
    "    self.input_feature_num = input_feature_num # Save the input size for reshaping later\n",
    "    self.model = nn.Sequential() # Initialize layers of MLP\n",
    "\n",
    "    in_num = input_feature_num # Initialize the temporary input feature to each layer\n",
    "    for i in range(len(hidden_unit_nums)): # Loop over layers and create each one\n",
    "\n",
    "      out_num = hidden_unit_nums[i] # Assign the current layer hidden unit from list\n",
    "      layer = nn.Linear(in_num, out_num) # Use nn.Linear to define the layer\n",
    "\n",
    "      in_num = out_num # Assign next layer input using current layer output\n",
    "      self.model.add_module('Linear_%d'%i, layer) # Append layer to the model with a name\n",
    "\n",
    "      actv_layer = eval('nn.%s'%actv) # Assign activation function (eval allows us to instantiate object from string)\n",
    "      self.model.add_module('Activation_%d'%i, actv_layer) # Append activation to the model with a name\n",
    "\n",
    "    out_layer = nn.Linear(in_num, output_feature_num) # Create final layer\n",
    "    self.model.add_module('Output_Linear', out_layer) # Append the final layer\n",
    "\n",
    "    actv_layer = nn.Sigmoid()\n",
    "    self.model.add_module('LastActivation', actv_layer)\n",
    "\n",
    "  def forward(self, x):\n",
    "    \"\"\"\n",
    "    Simulate forward pass of MLP Network\n",
    "\n",
    "    Args:\n",
    "      x: torch.tensor\n",
    "        Input data\n",
    "\n",
    "    Returns:\n",
    "      logits: Instance of MLP\n",
    "        Forward pass of MLP\n",
    "    \"\"\"\n",
    "    # Reshape inputs to (batch_size, input_feature_num)\n",
    "    # Just in case the input vector is not 2D, like an image!\n",
    "    x = x.view(x.shape[0], -1)\n",
    "    logits = self.model(x) # Forward pass of MLP\n",
    "    return logits\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "hidden_layers_shape = [1024, 64]\n",
    "activation = 'Tanh()'\n",
    "semanticDecoder = SemanticDecoder(actv=activation, input_feature_num=fmri_size, hidden_unit_nums=hidden_layers_shape, output_feature_num=2)\n",
    "# y = net()\n",
    "# print(f'The output shape is {y.shape} for an input of shape {fmri_size.shape}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[0.5241, 0.5044],\n        [0.5236, 0.5065],\n        [0.5238, 0.5062],\n        [0.5231, 0.5055],\n        [0.5225, 0.5076],\n        [0.5228, 0.5047],\n        [0.5218, 0.5075],\n        [0.5218, 0.5084],\n        [0.5243, 0.5077],\n        [0.5211, 0.5081],\n        [0.5233, 0.5072],\n        [0.5209, 0.5066],\n        [0.5215, 0.5075],\n        [0.5212, 0.5073],\n        [0.5233, 0.5058],\n        [0.5216, 0.5093],\n        [0.5221, 0.5062],\n        [0.5231, 0.5082],\n        [0.5237, 0.5054],\n        [0.5207, 0.5076],\n        [0.5220, 0.5076],\n        [0.5226, 0.5064],\n        [0.5218, 0.5071],\n        [0.5227, 0.5063],\n        [0.5212, 0.5081],\n        [0.5233, 0.5078],\n        [0.5210, 0.5072],\n        [0.5216, 0.5075],\n        [0.5220, 0.5078],\n        [0.5215, 0.5081],\n        [0.5221, 0.5069],\n        [0.5217, 0.5081],\n        [0.5225, 0.5058],\n        [0.5221, 0.5064],\n        [0.5210, 0.5081],\n        [0.5221, 0.5081],\n        [0.5226, 0.5079],\n        [0.5218, 0.5078],\n        [0.5221, 0.5075],\n        [0.5222, 0.5073],\n        [0.5219, 0.5078],\n        [0.5219, 0.5069],\n        [0.5220, 0.5080],\n        [0.5224, 0.5068],\n        [0.5210, 0.5090],\n        [0.5223, 0.5078],\n        [0.5224, 0.5081],\n        [0.5222, 0.5067],\n        [0.5240, 0.5081],\n        [0.5230, 0.5080],\n        [0.5260, 0.5045],\n        [0.5230, 0.5064],\n        [0.5217, 0.5060],\n        [0.5214, 0.5060],\n        [0.5236, 0.5055],\n        [0.5240, 0.5073],\n        [0.5234, 0.5075],\n        [0.5230, 0.5070],\n        [0.5230, 0.5091],\n        [0.5218, 0.5066],\n        [0.5225, 0.5070],\n        [0.5229, 0.5066],\n        [0.5223, 0.5072],\n        [0.5220, 0.5065],\n        [0.5222, 0.5061],\n        [0.5224, 0.5056],\n        [0.5229, 0.5058],\n        [0.5214, 0.5073],\n        [0.5226, 0.5058],\n        [0.5233, 0.5079],\n        [0.5219, 0.5067],\n        [0.5213, 0.5083],\n        [0.5223, 0.5070],\n        [0.5219, 0.5073],\n        [0.5215, 0.5059],\n        [0.5227, 0.5079],\n        [0.5219, 0.5068],\n        [0.5219, 0.5065],\n        [0.5217, 0.5082],\n        [0.5227, 0.5092],\n        [0.5218, 0.5073],\n        [0.5224, 0.5084],\n        [0.5224, 0.5076],\n        [0.5227, 0.5072],\n        [0.5227, 0.5068],\n        [0.5220, 0.5070],\n        [0.5220, 0.5080],\n        [0.5235, 0.5072],\n        [0.5223, 0.5090],\n        [0.5230, 0.5078],\n        [0.5224, 0.5064],\n        [0.5229, 0.5084],\n        [0.5218, 0.5075],\n        [0.5228, 0.5075],\n        [0.5226, 0.5089],\n        [0.5217, 0.5068],\n        [0.5220, 0.5074],\n        [0.5222, 0.5065],\n        [0.5218, 0.5069],\n        [0.5212, 0.5086]], grad_fn=<SigmoidBackward0>)"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda = True if torch.cuda.is_available() else False\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "fmri = torch.from_numpy(fmri_dataset)\n",
    "fmri = fmri.type(Tensor)\n",
    "print(type(fmri_dataset))\n",
    "semanticDecoder.forward(fmri)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "# define the loss function\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# define optimizer\n",
    "# tuning the hyperparameters\n",
    "lr = 0.0002\n",
    "b1 = 0.5\n",
    "b2 = 0.999\n",
    "\n",
    "gamma_1 = 0.8\n",
    "step_1 = 10\n",
    "last_epoch_1 = -1\n",
    "optimizer = torch.optim.Adam(semanticDecoder.parameters(), lr=lr, betas=(b1, b2))\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_1, gamma=gamma_1, last_epoch=last_epoch_1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3092)\n"
     ]
    }
   ],
   "source": [
    "train_fmri = np.concatenate([fmri[0:45], fmri[50:95]])\n",
    "test_fmri = np.concatenate([fmri[45:50], fmri[95:100]])\n",
    "\n",
    "rand_id = np.random.randint(low=0, high=train_fmri.shape[0], size=train_fmri.shape[0])\n",
    "train_fmri = train_fmri[rand_id]\n",
    "fmri = np.concatenate([train_fmri, test_fmri])\n",
    "print(fmri.shape)\n",
    "\n",
    "train_labels = np.concatenate([labels[0:45], labels[50:95]])\n",
    "test_labels = np.concatenate([labels[45:50], labels[95:100]])\n",
    "train_labels = train_labels[rand_id]\n",
    "labels = np.concatenate([train_labels, test_labels])\n",
    "\n",
    "fmri = torch.from_numpy(fmri)\n",
    "fmri = fmri.type(Tensor)\n",
    "\n",
    "train_fmri = torch.from_numpy(train_fmri)\n",
    "train_labels = torch.from_numpy(train_labels)\n",
    "train_labels = train_labels.squeeze()\n",
    "train_fmri = train_fmri.type(Tensor)\n",
    "train_labels = train_labels.type(Tensor)\n",
    "\n",
    "test_fmri = torch.from_numpy(test_fmri)\n",
    "test_labels = torch.from_numpy(test_labels)\n",
    "test_labels = test_labels.squeeze()\n",
    "test_fmri = test_fmri.type(Tensor)\n",
    "test_labels = test_labels.type(Tensor)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "n_epochs = 100"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/100] [Batch 0] [loss: 0.694888] \n",
      "[Epoch 0/100] [Batch 1] [loss: 0.691317] \n",
      "[Epoch 0/100] [Batch 2] [loss: 0.688377] \n",
      "[Epoch 0/100] [Batch 3] [loss: 0.695828] \n",
      "[Epoch 0/100] [Batch 4] [loss: 0.697494] \n",
      "[Epoch 0/100] [Batch 5] [loss: 0.682810] \n",
      "[Epoch 0/100] [Batch 6] [loss: 0.686512] \n",
      "[Epoch 0/100] [Batch 7] [loss: 0.690262] \n",
      "[Epoch 0/100] [Batch 8] [loss: 0.678635] \n",
      "[Epoch 1/100] [Batch 0] [loss: 0.672777] \n",
      "[Epoch 1/100] [Batch 1] [loss: 0.670550] \n",
      "[Epoch 1/100] [Batch 2] [loss: 0.664640] \n",
      "[Epoch 1/100] [Batch 3] [loss: 0.690136] \n",
      "[Epoch 1/100] [Batch 4] [loss: 0.697352] \n",
      "[Epoch 1/100] [Batch 5] [loss: 0.646685] \n",
      "[Epoch 1/100] [Batch 6] [loss: 0.666480] \n",
      "[Epoch 1/100] [Batch 7] [loss: 0.678998] \n",
      "[Epoch 1/100] [Batch 8] [loss: 0.644244] \n",
      "[Epoch 2/100] [Batch 0] [loss: 0.638278] \n",
      "[Epoch 2/100] [Batch 1] [loss: 0.635577] \n",
      "[Epoch 2/100] [Batch 2] [loss: 0.623418] \n",
      "[Epoch 2/100] [Batch 3] [loss: 0.668093] \n",
      "[Epoch 2/100] [Batch 4] [loss: 0.674630] \n",
      "[Epoch 2/100] [Batch 5] [loss: 0.601031] \n",
      "[Epoch 2/100] [Batch 6] [loss: 0.622544] \n",
      "[Epoch 2/100] [Batch 7] [loss: 0.635536] \n",
      "[Epoch 2/100] [Batch 8] [loss: 0.616344] \n",
      "[Epoch 3/100] [Batch 0] [loss: 0.588916] \n",
      "[Epoch 3/100] [Batch 1] [loss: 0.581658] \n",
      "[Epoch 3/100] [Batch 2] [loss: 0.557876] \n",
      "[Epoch 3/100] [Batch 3] [loss: 0.604618] \n",
      "[Epoch 3/100] [Batch 4] [loss: 0.594932] \n",
      "[Epoch 3/100] [Batch 5] [loss: 0.552299] \n",
      "[Epoch 3/100] [Batch 6] [loss: 0.550113] \n",
      "[Epoch 3/100] [Batch 7] [loss: 0.550361] \n",
      "[Epoch 3/100] [Batch 8] [loss: 0.589069] \n",
      "[Epoch 4/100] [Batch 0] [loss: 0.524136] \n",
      "[Epoch 4/100] [Batch 1] [loss: 0.510739] \n",
      "[Epoch 4/100] [Batch 2] [loss: 0.482626] \n",
      "[Epoch 4/100] [Batch 3] [loss: 0.527218] \n",
      "[Epoch 4/100] [Batch 4] [loss: 0.508580] \n",
      "[Epoch 4/100] [Batch 5] [loss: 0.487173] \n",
      "[Epoch 4/100] [Batch 6] [loss: 0.484505] \n",
      "[Epoch 4/100] [Batch 7] [loss: 0.474509] \n",
      "[Epoch 4/100] [Batch 8] [loss: 0.539466] \n",
      "[Epoch 5/100] [Batch 0] [loss: 0.464315] \n",
      "[Epoch 5/100] [Batch 1] [loss: 0.450799] \n",
      "[Epoch 5/100] [Batch 2] [loss: 0.431290] \n",
      "[Epoch 5/100] [Batch 3] [loss: 0.467083] \n",
      "[Epoch 5/100] [Batch 4] [loss: 0.445366] \n",
      "[Epoch 5/100] [Batch 5] [loss: 0.434058] \n",
      "[Epoch 5/100] [Batch 6] [loss: 0.441152] \n",
      "[Epoch 5/100] [Batch 7] [loss: 0.422164] \n",
      "[Epoch 5/100] [Batch 8] [loss: 0.490820] \n",
      "[Epoch 6/100] [Batch 0] [loss: 0.422633] \n",
      "[Epoch 6/100] [Batch 1] [loss: 0.409525] \n",
      "[Epoch 6/100] [Batch 2] [loss: 0.401189] \n",
      "[Epoch 6/100] [Batch 3] [loss: 0.426783] \n",
      "[Epoch 6/100] [Batch 4] [loss: 0.405349] \n",
      "[Epoch 6/100] [Batch 5] [loss: 0.398990] \n",
      "[Epoch 6/100] [Batch 6] [loss: 0.413954] \n",
      "[Epoch 6/100] [Batch 7] [loss: 0.389304] \n",
      "[Epoch 6/100] [Batch 8] [loss: 0.447334] \n",
      "[Epoch 7/100] [Batch 0] [loss: 0.395161] \n",
      "[Epoch 7/100] [Batch 1] [loss: 0.382367] \n",
      "[Epoch 7/100] [Batch 2] [loss: 0.381227] \n",
      "[Epoch 7/100] [Batch 3] [loss: 0.399235] \n",
      "[Epoch 7/100] [Batch 4] [loss: 0.380644] \n",
      "[Epoch 7/100] [Batch 5] [loss: 0.376004] \n",
      "[Epoch 7/100] [Batch 6] [loss: 0.394579] \n",
      "[Epoch 7/100] [Batch 7] [loss: 0.368845] \n",
      "[Epoch 7/100] [Batch 8] [loss: 0.411754] \n",
      "[Epoch 8/100] [Batch 0] [loss: 0.377002] \n",
      "[Epoch 8/100] [Batch 1] [loss: 0.364663] \n",
      "[Epoch 8/100] [Batch 2] [loss: 0.365852] \n",
      "[Epoch 8/100] [Batch 3] [loss: 0.379450] \n",
      "[Epoch 8/100] [Batch 4] [loss: 0.364848] \n",
      "[Epoch 8/100] [Batch 5] [loss: 0.360544] \n",
      "[Epoch 8/100] [Batch 6] [loss: 0.378427] \n",
      "[Epoch 8/100] [Batch 7] [loss: 0.355783] \n",
      "[Epoch 8/100] [Batch 8] [loss: 0.385459] \n",
      "[Epoch 9/100] [Batch 0] [loss: 0.364506] \n",
      "[Epoch 9/100] [Batch 1] [loss: 0.353086] \n",
      "[Epoch 9/100] [Batch 2] [loss: 0.353920] \n",
      "[Epoch 9/100] [Batch 3] [loss: 0.365067] \n",
      "[Epoch 9/100] [Batch 4] [loss: 0.354229] \n",
      "[Epoch 9/100] [Batch 5] [loss: 0.350015] \n",
      "[Epoch 9/100] [Batch 6] [loss: 0.364211] \n",
      "[Epoch 9/100] [Batch 7] [loss: 0.347149] \n",
      "[Epoch 9/100] [Batch 8] [loss: 0.366996] \n",
      "[Epoch 10/100] [Batch 0] [loss: 0.355218] \n",
      "[Epoch 10/100] [Batch 1] [loss: 0.345517] \n",
      "[Epoch 10/100] [Batch 2] [loss: 0.344786] \n",
      "[Epoch 10/100] [Batch 3] [loss: 0.354765] \n",
      "[Epoch 10/100] [Batch 4] [loss: 0.347128] \n",
      "[Epoch 10/100] [Batch 5] [loss: 0.343272] \n",
      "[Epoch 10/100] [Batch 6] [loss: 0.353544] \n",
      "[Epoch 10/100] [Batch 7] [loss: 0.342513] \n",
      "[Epoch 10/100] [Batch 8] [loss: 0.353759] \n",
      "[Epoch 11/100] [Batch 0] [loss: 0.348988] \n",
      "[Epoch 11/100] [Batch 1] [loss: 0.340982] \n",
      "[Epoch 11/100] [Batch 2] [loss: 0.340088] \n",
      "[Epoch 11/100] [Batch 3] [loss: 0.348602] \n",
      "[Epoch 11/100] [Batch 4] [loss: 0.342419] \n",
      "[Epoch 11/100] [Batch 5] [loss: 0.338836] \n",
      "[Epoch 11/100] [Batch 6] [loss: 0.346157] \n",
      "[Epoch 11/100] [Batch 7] [loss: 0.338546] \n",
      "[Epoch 11/100] [Batch 8] [loss: 0.347186] \n",
      "[Epoch 12/100] [Batch 0] [loss: 0.344085] \n",
      "[Epoch 12/100] [Batch 1] [loss: 0.337398] \n",
      "[Epoch 12/100] [Batch 2] [loss: 0.336635] \n",
      "[Epoch 12/100] [Batch 3] [loss: 0.343881] \n",
      "[Epoch 12/100] [Batch 4] [loss: 0.338744] \n",
      "[Epoch 12/100] [Batch 5] [loss: 0.335433] \n",
      "[Epoch 12/100] [Batch 6] [loss: 0.340665] \n",
      "[Epoch 12/100] [Batch 7] [loss: 0.335394] \n",
      "[Epoch 12/100] [Batch 8] [loss: 0.342232] \n",
      "[Epoch 13/100] [Batch 0] [loss: 0.340165] \n",
      "[Epoch 13/100] [Batch 1] [loss: 0.334540] \n",
      "[Epoch 13/100] [Batch 2] [loss: 0.333867] \n",
      "[Epoch 13/100] [Batch 3] [loss: 0.340087] \n",
      "[Epoch 13/100] [Batch 4] [loss: 0.335755] \n",
      "[Epoch 13/100] [Batch 5] [loss: 0.332747] \n",
      "[Epoch 13/100] [Batch 6] [loss: 0.336565] \n",
      "[Epoch 13/100] [Batch 7] [loss: 0.332852] \n",
      "[Epoch 13/100] [Batch 8] [loss: 0.338395] \n",
      "[Epoch 14/100] [Batch 0] [loss: 0.336990] \n",
      "[Epoch 14/100] [Batch 1] [loss: 0.332222] \n",
      "[Epoch 14/100] [Batch 2] [loss: 0.331619] \n",
      "[Epoch 14/100] [Batch 3] [loss: 0.337001] \n",
      "[Epoch 14/100] [Batch 4] [loss: 0.333297] \n",
      "[Epoch 14/100] [Batch 5] [loss: 0.330589] \n",
      "[Epoch 14/100] [Batch 6] [loss: 0.333448] \n",
      "[Epoch 14/100] [Batch 7] [loss: 0.330772] \n",
      "[Epoch 14/100] [Batch 8] [loss: 0.335365] \n",
      "[Epoch 15/100] [Batch 0] [loss: 0.334391] \n",
      "[Epoch 15/100] [Batch 1] [loss: 0.330315] \n",
      "[Epoch 15/100] [Batch 2] [loss: 0.329766] \n",
      "[Epoch 15/100] [Batch 3] [loss: 0.334461] \n",
      "[Epoch 15/100] [Batch 4] [loss: 0.331254] \n",
      "[Epoch 15/100] [Batch 5] [loss: 0.328824] \n",
      "[Epoch 15/100] [Batch 6] [loss: 0.331020] \n",
      "[Epoch 15/100] [Batch 7] [loss: 0.329047] \n",
      "[Epoch 15/100] [Batch 8] [loss: 0.332925] \n",
      "[Epoch 16/100] [Batch 0] [loss: 0.332237] \n",
      "[Epoch 16/100] [Batch 1] [loss: 0.328723] \n",
      "[Epoch 16/100] [Batch 2] [loss: 0.328220] \n",
      "[Epoch 16/100] [Batch 3] [loss: 0.332345] \n",
      "[Epoch 16/100] [Batch 4] [loss: 0.329539] \n",
      "[Epoch 16/100] [Batch 5] [loss: 0.327359] \n",
      "[Epoch 16/100] [Batch 6] [loss: 0.329084] \n",
      "[Epoch 16/100] [Batch 7] [loss: 0.327600] \n",
      "[Epoch 16/100] [Batch 8] [loss: 0.330925] \n",
      "[Epoch 17/100] [Batch 0] [loss: 0.330434] \n",
      "[Epoch 17/100] [Batch 1] [loss: 0.327378] \n",
      "[Epoch 17/100] [Batch 2] [loss: 0.326913] \n",
      "[Epoch 17/100] [Batch 3] [loss: 0.330564] \n",
      "[Epoch 17/100] [Batch 4] [loss: 0.328086] \n",
      "[Epoch 17/100] [Batch 5] [loss: 0.326126] \n",
      "[Epoch 17/100] [Batch 6] [loss: 0.327509] \n",
      "[Epoch 17/100] [Batch 7] [loss: 0.326373] \n",
      "[Epoch 17/100] [Batch 8] [loss: 0.329261] \n",
      "[Epoch 18/100] [Batch 0] [loss: 0.328906] \n",
      "[Epoch 18/100] [Batch 1] [loss: 0.326229] \n",
      "[Epoch 18/100] [Batch 2] [loss: 0.325797] \n",
      "[Epoch 18/100] [Batch 3] [loss: 0.329049] \n",
      "[Epoch 18/100] [Batch 4] [loss: 0.326842] \n",
      "[Epoch 18/100] [Batch 5] [loss: 0.325076] \n",
      "[Epoch 18/100] [Batch 6] [loss: 0.326204] \n",
      "[Epoch 18/100] [Batch 7] [loss: 0.325321] \n",
      "[Epoch 18/100] [Batch 8] [loss: 0.327858] \n",
      "[Epoch 19/100] [Batch 0] [loss: 0.327599] \n",
      "[Epoch 19/100] [Batch 1] [loss: 0.325238] \n",
      "[Epoch 19/100] [Batch 2] [loss: 0.324835] \n",
      "[Epoch 19/100] [Batch 3] [loss: 0.327748] \n",
      "[Epoch 19/100] [Batch 4] [loss: 0.325769] \n",
      "[Epoch 19/100] [Batch 5] [loss: 0.324173] \n",
      "[Epoch 19/100] [Batch 6] [loss: 0.325107] \n",
      "[Epoch 19/100] [Batch 7] [loss: 0.324411] \n",
      "[Epoch 19/100] [Batch 8] [loss: 0.326661] \n",
      "[Epoch 20/100] [Batch 0] [loss: 0.326472] \n",
      "[Epoch 20/100] [Batch 1] [loss: 0.324402] \n",
      "[Epoch 20/100] [Batch 2] [loss: 0.323992] \n",
      "[Epoch 20/100] [Batch 3] [loss: 0.326650] \n",
      "[Epoch 20/100] [Batch 4] [loss: 0.324885] \n",
      "[Epoch 20/100] [Batch 5] [loss: 0.323455] \n",
      "[Epoch 20/100] [Batch 6] [loss: 0.324257] \n",
      "[Epoch 20/100] [Batch 7] [loss: 0.323756] \n",
      "[Epoch 20/100] [Batch 8] [loss: 0.325679] \n",
      "[Epoch 21/100] [Batch 0] [loss: 0.325646] \n",
      "[Epoch 21/100] [Batch 1] [loss: 0.323782] \n",
      "[Epoch 21/100] [Batch 2] [loss: 0.323413] \n",
      "[Epoch 21/100] [Batch 3] [loss: 0.325863] \n",
      "[Epoch 21/100] [Batch 4] [loss: 0.324224] \n",
      "[Epoch 21/100] [Batch 5] [loss: 0.322893] \n",
      "[Epoch 21/100] [Batch 6] [loss: 0.323598] \n",
      "[Epoch 21/100] [Batch 7] [loss: 0.323178] \n",
      "[Epoch 21/100] [Batch 8] [loss: 0.324948] \n",
      "[Epoch 22/100] [Batch 0] [loss: 0.324931] \n",
      "[Epoch 22/100] [Batch 1] [loss: 0.323223] \n",
      "[Epoch 22/100] [Batch 2] [loss: 0.322877] \n",
      "[Epoch 22/100] [Batch 3] [loss: 0.325143] \n",
      "[Epoch 22/100] [Batch 4] [loss: 0.323620] \n",
      "[Epoch 22/100] [Batch 5] [loss: 0.322382] \n",
      "[Epoch 22/100] [Batch 6] [loss: 0.323004] \n",
      "[Epoch 22/100] [Batch 7] [loss: 0.322649] \n",
      "[Epoch 22/100] [Batch 8] [loss: 0.324291] \n",
      "[Epoch 23/100] [Batch 0] [loss: 0.324285] \n",
      "[Epoch 23/100] [Batch 1] [loss: 0.322714] \n",
      "[Epoch 23/100] [Batch 2] [loss: 0.322386] \n",
      "[Epoch 23/100] [Batch 3] [loss: 0.324489] \n",
      "[Epoch 23/100] [Batch 4] [loss: 0.323070] \n",
      "[Epoch 23/100] [Batch 5] [loss: 0.321916] \n",
      "[Epoch 23/100] [Batch 6] [loss: 0.322469] \n",
      "[Epoch 23/100] [Batch 7] [loss: 0.322168] \n",
      "[Epoch 23/100] [Batch 8] [loss: 0.323696] \n",
      "[Epoch 24/100] [Batch 0] [loss: 0.323697] \n",
      "[Epoch 24/100] [Batch 1] [loss: 0.322248] \n",
      "[Epoch 24/100] [Batch 2] [loss: 0.321937] \n",
      "[Epoch 24/100] [Batch 3] [loss: 0.323893] \n",
      "[Epoch 24/100] [Batch 4] [loss: 0.322568] \n",
      "[Epoch 24/100] [Batch 5] [loss: 0.321491] \n",
      "[Epoch 24/100] [Batch 6] [loss: 0.321983] \n",
      "[Epoch 24/100] [Batch 7] [loss: 0.321728] \n",
      "[Epoch 24/100] [Batch 8] [loss: 0.323154] \n",
      "[Epoch 25/100] [Batch 0] [loss: 0.323161] \n",
      "[Epoch 25/100] [Batch 1] [loss: 0.321820] \n",
      "[Epoch 25/100] [Batch 2] [loss: 0.321525] \n",
      "[Epoch 25/100] [Batch 3] [loss: 0.323348] \n",
      "[Epoch 25/100] [Batch 4] [loss: 0.322108] \n",
      "[Epoch 25/100] [Batch 5] [loss: 0.321101] \n",
      "[Epoch 25/100] [Batch 6] [loss: 0.321542] \n",
      "[Epoch 25/100] [Batch 7] [loss: 0.321324] \n",
      "[Epoch 25/100] [Batch 8] [loss: 0.322658] \n",
      "[Epoch 26/100] [Batch 0] [loss: 0.322670] \n",
      "[Epoch 26/100] [Batch 1] [loss: 0.321426] \n",
      "[Epoch 26/100] [Batch 2] [loss: 0.321145] \n",
      "[Epoch 26/100] [Batch 3] [loss: 0.322848] \n",
      "[Epoch 26/100] [Batch 4] [loss: 0.321685] \n",
      "[Epoch 26/100] [Batch 5] [loss: 0.320742] \n",
      "[Epoch 26/100] [Batch 6] [loss: 0.321139] \n",
      "[Epoch 26/100] [Batch 7] [loss: 0.320953] \n",
      "[Epoch 26/100] [Batch 8] [loss: 0.322204] \n",
      "[Epoch 27/100] [Batch 0] [loss: 0.322218] \n",
      "[Epoch 27/100] [Batch 1] [loss: 0.321063] \n",
      "[Epoch 27/100] [Batch 2] [loss: 0.320795] \n",
      "[Epoch 27/100] [Batch 3] [loss: 0.322388] \n",
      "[Epoch 27/100] [Batch 4] [loss: 0.321296] \n",
      "[Epoch 27/100] [Batch 5] [loss: 0.320411] \n",
      "[Epoch 27/100] [Batch 6] [loss: 0.320770] \n",
      "[Epoch 27/100] [Batch 7] [loss: 0.320611] \n",
      "[Epoch 27/100] [Batch 8] [loss: 0.321786] \n",
      "[Epoch 28/100] [Batch 0] [loss: 0.321803] \n",
      "[Epoch 28/100] [Batch 1] [loss: 0.320726] \n",
      "[Epoch 28/100] [Batch 2] [loss: 0.320470] \n",
      "[Epoch 28/100] [Batch 3] [loss: 0.321965] \n",
      "[Epoch 28/100] [Batch 4] [loss: 0.320936] \n",
      "[Epoch 28/100] [Batch 5] [loss: 0.320105] \n",
      "[Epoch 28/100] [Batch 6] [loss: 0.320430] \n",
      "[Epoch 28/100] [Batch 7] [loss: 0.320294] \n",
      "[Epoch 28/100] [Batch 8] [loss: 0.321400] \n",
      "[Epoch 29/100] [Batch 0] [loss: 0.321419] \n",
      "[Epoch 29/100] [Batch 1] [loss: 0.320414] \n",
      "[Epoch 29/100] [Batch 2] [loss: 0.320170] \n",
      "[Epoch 29/100] [Batch 3] [loss: 0.321574] \n",
      "[Epoch 29/100] [Batch 4] [loss: 0.320604] \n",
      "[Epoch 29/100] [Batch 5] [loss: 0.319821] \n",
      "[Epoch 29/100] [Batch 6] [loss: 0.320117] \n",
      "[Epoch 29/100] [Batch 7] [loss: 0.320000] \n",
      "[Epoch 29/100] [Batch 8] [loss: 0.321044] \n",
      "[Epoch 30/100] [Batch 0] [loss: 0.321064] \n",
      "[Epoch 30/100] [Batch 1] [loss: 0.320132] \n",
      "[Epoch 30/100] [Batch 2] [loss: 0.319892] \n",
      "[Epoch 30/100] [Batch 3] [loss: 0.321223] \n",
      "[Epoch 30/100] [Batch 4] [loss: 0.320312] \n",
      "[Epoch 30/100] [Batch 5] [loss: 0.319581] \n",
      "[Epoch 30/100] [Batch 6] [loss: 0.319856] \n",
      "[Epoch 30/100] [Batch 7] [loss: 0.319771] \n",
      "[Epoch 30/100] [Batch 8] [loss: 0.320743] \n",
      "[Epoch 31/100] [Batch 0] [loss: 0.320792] \n",
      "[Epoch 31/100] [Batch 1] [loss: 0.319913] \n",
      "[Epoch 31/100] [Batch 2] [loss: 0.319685] \n",
      "[Epoch 31/100] [Batch 3] [loss: 0.320954] \n",
      "[Epoch 31/100] [Batch 4] [loss: 0.320081] \n",
      "[Epoch 31/100] [Batch 5] [loss: 0.319382] \n",
      "[Epoch 31/100] [Batch 6] [loss: 0.319639] \n",
      "[Epoch 31/100] [Batch 7] [loss: 0.319565] \n",
      "[Epoch 31/100] [Batch 8] [loss: 0.320491] \n",
      "[Epoch 32/100] [Batch 0] [loss: 0.320540] \n",
      "[Epoch 32/100] [Batch 1] [loss: 0.319705] \n",
      "[Epoch 32/100] [Batch 2] [loss: 0.319486] \n",
      "[Epoch 32/100] [Batch 3] [loss: 0.320697] \n",
      "[Epoch 32/100] [Batch 4] [loss: 0.319861] \n",
      "[Epoch 32/100] [Batch 5] [loss: 0.319193] \n",
      "[Epoch 32/100] [Batch 6] [loss: 0.319433] \n",
      "[Epoch 32/100] [Batch 7] [loss: 0.319369] \n",
      "[Epoch 32/100] [Batch 8] [loss: 0.320254] \n",
      "[Epoch 33/100] [Batch 0] [loss: 0.320301] \n",
      "[Epoch 33/100] [Batch 1] [loss: 0.319508] \n",
      "[Epoch 33/100] [Batch 2] [loss: 0.319297] \n",
      "[Epoch 33/100] [Batch 3] [loss: 0.320454] \n",
      "[Epoch 33/100] [Batch 4] [loss: 0.319653] \n",
      "[Epoch 33/100] [Batch 5] [loss: 0.319014] \n",
      "[Epoch 33/100] [Batch 6] [loss: 0.319238] \n",
      "[Epoch 33/100] [Batch 7] [loss: 0.319182] \n",
      "[Epoch 33/100] [Batch 8] [loss: 0.320031] \n",
      "[Epoch 34/100] [Batch 0] [loss: 0.320076] \n",
      "[Epoch 34/100] [Batch 1] [loss: 0.319321] \n",
      "[Epoch 34/100] [Batch 2] [loss: 0.319117] \n",
      "[Epoch 34/100] [Batch 3] [loss: 0.320223] \n",
      "[Epoch 34/100] [Batch 4] [loss: 0.319454] \n",
      "[Epoch 34/100] [Batch 5] [loss: 0.318843] \n",
      "[Epoch 34/100] [Batch 6] [loss: 0.319053] \n",
      "[Epoch 34/100] [Batch 7] [loss: 0.319004] \n",
      "[Epoch 34/100] [Batch 8] [loss: 0.319820] \n",
      "[Epoch 35/100] [Batch 0] [loss: 0.319863] \n",
      "[Epoch 35/100] [Batch 1] [loss: 0.319143] \n",
      "[Epoch 35/100] [Batch 2] [loss: 0.318946] \n",
      "[Epoch 35/100] [Batch 3] [loss: 0.320004] \n",
      "[Epoch 35/100] [Batch 4] [loss: 0.319266] \n",
      "[Epoch 35/100] [Batch 5] [loss: 0.318680] \n",
      "[Epoch 35/100] [Batch 6] [loss: 0.318877] \n",
      "[Epoch 35/100] [Batch 7] [loss: 0.318834] \n",
      "[Epoch 35/100] [Batch 8] [loss: 0.319619] \n",
      "[Epoch 36/100] [Batch 0] [loss: 0.319660] \n",
      "[Epoch 36/100] [Batch 1] [loss: 0.318973] \n",
      "[Epoch 36/100] [Batch 2] [loss: 0.318782] \n",
      "[Epoch 36/100] [Batch 3] [loss: 0.319796] \n",
      "[Epoch 36/100] [Batch 4] [loss: 0.319086] \n",
      "[Epoch 36/100] [Batch 5] [loss: 0.318525] \n",
      "[Epoch 36/100] [Batch 6] [loss: 0.318710] \n",
      "[Epoch 36/100] [Batch 7] [loss: 0.318673] \n",
      "[Epoch 36/100] [Batch 8] [loss: 0.319427] \n",
      "[Epoch 37/100] [Batch 0] [loss: 0.319467] \n",
      "[Epoch 37/100] [Batch 1] [loss: 0.318811] \n",
      "[Epoch 37/100] [Batch 2] [loss: 0.318626] \n",
      "[Epoch 37/100] [Batch 3] [loss: 0.319598] \n",
      "[Epoch 37/100] [Batch 4] [loss: 0.318916] \n",
      "[Epoch 37/100] [Batch 5] [loss: 0.318377] \n",
      "[Epoch 37/100] [Batch 6] [loss: 0.318551] \n",
      "[Epoch 37/100] [Batch 7] [loss: 0.318519] \n",
      "[Epoch 37/100] [Batch 8] [loss: 0.319246] \n",
      "[Epoch 38/100] [Batch 0] [loss: 0.319283] \n",
      "[Epoch 38/100] [Batch 1] [loss: 0.318656] \n",
      "[Epoch 38/100] [Batch 2] [loss: 0.318477] \n",
      "[Epoch 38/100] [Batch 3] [loss: 0.319409] \n",
      "[Epoch 38/100] [Batch 4] [loss: 0.318753] \n",
      "[Epoch 38/100] [Batch 5] [loss: 0.318236] \n",
      "[Epoch 38/100] [Batch 6] [loss: 0.318400] \n",
      "[Epoch 38/100] [Batch 7] [loss: 0.318373] \n",
      "[Epoch 38/100] [Batch 8] [loss: 0.319072] \n",
      "[Epoch 39/100] [Batch 0] [loss: 0.319108] \n",
      "[Epoch 39/100] [Batch 1] [loss: 0.318509] \n",
      "[Epoch 39/100] [Batch 2] [loss: 0.318335] \n",
      "[Epoch 39/100] [Batch 3] [loss: 0.319229] \n",
      "[Epoch 39/100] [Batch 4] [loss: 0.318598] \n",
      "[Epoch 39/100] [Batch 5] [loss: 0.318102] \n",
      "[Epoch 39/100] [Batch 6] [loss: 0.318256] \n",
      "[Epoch 39/100] [Batch 7] [loss: 0.318233] \n",
      "[Epoch 39/100] [Batch 8] [loss: 0.318907] \n",
      "[Epoch 40/100] [Batch 0] [loss: 0.318941] \n",
      "[Epoch 40/100] [Batch 1] [loss: 0.318371] \n",
      "[Epoch 40/100] [Batch 2] [loss: 0.318201] \n",
      "[Epoch 40/100] [Batch 3] [loss: 0.319064] \n",
      "[Epoch 40/100] [Batch 4] [loss: 0.318458] \n",
      "[Epoch 40/100] [Batch 5] [loss: 0.317985] \n",
      "[Epoch 40/100] [Batch 6] [loss: 0.318132] \n",
      "[Epoch 40/100] [Batch 7] [loss: 0.318119] \n",
      "[Epoch 40/100] [Batch 8] [loss: 0.318767] \n",
      "[Epoch 41/100] [Batch 0] [loss: 0.318811] \n",
      "[Epoch 41/100] [Batch 1] [loss: 0.318262] \n",
      "[Epoch 41/100] [Batch 2] [loss: 0.318097] \n",
      "[Epoch 41/100] [Batch 3] [loss: 0.318933] \n",
      "[Epoch 41/100] [Batch 4] [loss: 0.318344] \n",
      "[Epoch 41/100] [Batch 5] [loss: 0.317886] \n",
      "[Epoch 41/100] [Batch 6] [loss: 0.318027] \n",
      "[Epoch 41/100] [Batch 7] [loss: 0.318017] \n",
      "[Epoch 41/100] [Batch 8] [loss: 0.318644] \n",
      "[Epoch 42/100] [Batch 0] [loss: 0.318687] \n",
      "[Epoch 42/100] [Batch 1] [loss: 0.318157] \n",
      "[Epoch 42/100] [Batch 2] [loss: 0.317997] \n",
      "[Epoch 42/100] [Batch 3] [loss: 0.318806] \n",
      "[Epoch 42/100] [Batch 4] [loss: 0.318234] \n",
      "[Epoch 42/100] [Batch 5] [loss: 0.317790] \n",
      "[Epoch 42/100] [Batch 6] [loss: 0.317925] \n",
      "[Epoch 42/100] [Batch 7] [loss: 0.317917] \n",
      "[Epoch 42/100] [Batch 8] [loss: 0.318525] \n",
      "[Epoch 43/100] [Batch 0] [loss: 0.318567] \n",
      "[Epoch 43/100] [Batch 1] [loss: 0.318055] \n",
      "[Epoch 43/100] [Batch 2] [loss: 0.317899] \n",
      "[Epoch 43/100] [Batch 3] [loss: 0.318684] \n",
      "[Epoch 43/100] [Batch 4] [loss: 0.318128] \n",
      "[Epoch 43/100] [Batch 5] [loss: 0.317696] \n",
      "[Epoch 43/100] [Batch 6] [loss: 0.317826] \n",
      "[Epoch 43/100] [Batch 7] [loss: 0.317820] \n",
      "[Epoch 43/100] [Batch 8] [loss: 0.318411] \n",
      "[Epoch 44/100] [Batch 0] [loss: 0.318451] \n",
      "[Epoch 44/100] [Batch 1] [loss: 0.317956] \n",
      "[Epoch 44/100] [Batch 2] [loss: 0.317804] \n",
      "[Epoch 44/100] [Batch 3] [loss: 0.318565] \n",
      "[Epoch 44/100] [Batch 4] [loss: 0.318025] \n",
      "[Epoch 44/100] [Batch 5] [loss: 0.317606] \n",
      "[Epoch 44/100] [Batch 6] [loss: 0.317730] \n",
      "[Epoch 44/100] [Batch 7] [loss: 0.317726] \n",
      "[Epoch 44/100] [Batch 8] [loss: 0.318301] \n",
      "[Epoch 45/100] [Batch 0] [loss: 0.318340] \n",
      "[Epoch 45/100] [Batch 1] [loss: 0.317861] \n",
      "[Epoch 45/100] [Batch 2] [loss: 0.317712] \n",
      "[Epoch 45/100] [Batch 3] [loss: 0.318450] \n",
      "[Epoch 45/100] [Batch 4] [loss: 0.317925] \n",
      "[Epoch 45/100] [Batch 5] [loss: 0.317519] \n",
      "[Epoch 45/100] [Batch 6] [loss: 0.317637] \n",
      "[Epoch 45/100] [Batch 7] [loss: 0.317635] \n",
      "[Epoch 45/100] [Batch 8] [loss: 0.318195] \n",
      "[Epoch 46/100] [Batch 0] [loss: 0.318232] \n",
      "[Epoch 46/100] [Batch 1] [loss: 0.317768] \n",
      "[Epoch 46/100] [Batch 2] [loss: 0.317623] \n",
      "[Epoch 46/100] [Batch 3] [loss: 0.318339] \n",
      "[Epoch 46/100] [Batch 4] [loss: 0.317828] \n",
      "[Epoch 46/100] [Batch 5] [loss: 0.317434] \n",
      "[Epoch 46/100] [Batch 6] [loss: 0.317547] \n",
      "[Epoch 46/100] [Batch 7] [loss: 0.317547] \n",
      "[Epoch 46/100] [Batch 8] [loss: 0.318092] \n",
      "[Epoch 47/100] [Batch 0] [loss: 0.318127] \n",
      "[Epoch 47/100] [Batch 1] [loss: 0.317678] \n",
      "[Epoch 47/100] [Batch 2] [loss: 0.317536] \n",
      "[Epoch 47/100] [Batch 3] [loss: 0.318232] \n",
      "[Epoch 47/100] [Batch 4] [loss: 0.317734] \n",
      "[Epoch 47/100] [Batch 5] [loss: 0.317352] \n",
      "[Epoch 47/100] [Batch 6] [loss: 0.317460] \n",
      "[Epoch 47/100] [Batch 7] [loss: 0.317461] \n",
      "[Epoch 47/100] [Batch 8] [loss: 0.317992] \n",
      "[Epoch 48/100] [Batch 0] [loss: 0.318026] \n",
      "[Epoch 48/100] [Batch 1] [loss: 0.317591] \n",
      "[Epoch 48/100] [Batch 2] [loss: 0.317452] \n",
      "[Epoch 48/100] [Batch 3] [loss: 0.318127] \n",
      "[Epoch 48/100] [Batch 4] [loss: 0.317643] \n",
      "[Epoch 48/100] [Batch 5] [loss: 0.317272] \n",
      "[Epoch 48/100] [Batch 6] [loss: 0.317376] \n",
      "[Epoch 48/100] [Batch 7] [loss: 0.317378] \n",
      "[Epoch 48/100] [Batch 8] [loss: 0.317896] \n",
      "[Epoch 49/100] [Batch 0] [loss: 0.317928] \n",
      "[Epoch 49/100] [Batch 1] [loss: 0.317506] \n",
      "[Epoch 49/100] [Batch 2] [loss: 0.317371] \n",
      "[Epoch 49/100] [Batch 3] [loss: 0.318027] \n",
      "[Epoch 49/100] [Batch 4] [loss: 0.317555] \n",
      "[Epoch 49/100] [Batch 5] [loss: 0.317195] \n",
      "[Epoch 49/100] [Batch 6] [loss: 0.317295] \n",
      "[Epoch 49/100] [Batch 7] [loss: 0.317298] \n",
      "[Epoch 49/100] [Batch 8] [loss: 0.317802] \n",
      "[Epoch 50/100] [Batch 0] [loss: 0.317833] \n",
      "[Epoch 50/100] [Batch 1] [loss: 0.317427] \n",
      "[Epoch 50/100] [Batch 2] [loss: 0.317294] \n",
      "[Epoch 50/100] [Batch 3] [loss: 0.317933] \n",
      "[Epoch 50/100] [Batch 4] [loss: 0.317475] \n",
      "[Epoch 50/100] [Batch 5] [loss: 0.317127] \n",
      "[Epoch 50/100] [Batch 6] [loss: 0.317224] \n",
      "[Epoch 50/100] [Batch 7] [loss: 0.317231] \n",
      "[Epoch 50/100] [Batch 8] [loss: 0.317722] \n",
      "[Epoch 51/100] [Batch 0] [loss: 0.317759] \n",
      "[Epoch 51/100] [Batch 1] [loss: 0.317363] \n",
      "[Epoch 51/100] [Batch 2] [loss: 0.317232] \n",
      "[Epoch 51/100] [Batch 3] [loss: 0.317857] \n",
      "[Epoch 51/100] [Batch 4] [loss: 0.317409] \n",
      "[Epoch 51/100] [Batch 5] [loss: 0.317069] \n",
      "[Epoch 51/100] [Batch 6] [loss: 0.317162] \n",
      "[Epoch 51/100] [Batch 7] [loss: 0.317171] \n",
      "[Epoch 51/100] [Batch 8] [loss: 0.317651] \n",
      "[Epoch 52/100] [Batch 0] [loss: 0.317687] \n",
      "[Epoch 52/100] [Batch 1] [loss: 0.317300] \n",
      "[Epoch 52/100] [Batch 2] [loss: 0.317172] \n",
      "[Epoch 52/100] [Batch 3] [loss: 0.317783] \n",
      "[Epoch 52/100] [Batch 4] [loss: 0.317344] \n",
      "[Epoch 52/100] [Batch 5] [loss: 0.317011] \n",
      "[Epoch 52/100] [Batch 6] [loss: 0.317102] \n",
      "[Epoch 52/100] [Batch 7] [loss: 0.317111] \n",
      "[Epoch 52/100] [Batch 8] [loss: 0.317581] \n",
      "[Epoch 53/100] [Batch 0] [loss: 0.317616] \n",
      "[Epoch 53/100] [Batch 1] [loss: 0.317239] \n",
      "[Epoch 53/100] [Batch 2] [loss: 0.317114] \n",
      "[Epoch 53/100] [Batch 3] [loss: 0.317710] \n",
      "[Epoch 53/100] [Batch 4] [loss: 0.317280] \n",
      "[Epoch 53/100] [Batch 5] [loss: 0.316955] \n",
      "[Epoch 53/100] [Batch 6] [loss: 0.317043] \n",
      "[Epoch 53/100] [Batch 7] [loss: 0.317053] \n",
      "[Epoch 53/100] [Batch 8] [loss: 0.317513] \n",
      "[Epoch 54/100] [Batch 0] [loss: 0.317547] \n",
      "[Epoch 54/100] [Batch 1] [loss: 0.317179] \n",
      "[Epoch 54/100] [Batch 2] [loss: 0.317056] \n",
      "[Epoch 54/100] [Batch 3] [loss: 0.317639] \n",
      "[Epoch 54/100] [Batch 4] [loss: 0.317218] \n",
      "[Epoch 54/100] [Batch 5] [loss: 0.316900] \n",
      "[Epoch 54/100] [Batch 6] [loss: 0.316986] \n",
      "[Epoch 54/100] [Batch 7] [loss: 0.316996] \n",
      "[Epoch 54/100] [Batch 8] [loss: 0.317447] \n",
      "[Epoch 55/100] [Batch 0] [loss: 0.317479] \n",
      "[Epoch 55/100] [Batch 1] [loss: 0.317120] \n",
      "[Epoch 55/100] [Batch 2] [loss: 0.317000] \n",
      "[Epoch 55/100] [Batch 3] [loss: 0.317570] \n",
      "[Epoch 55/100] [Batch 4] [loss: 0.317157] \n",
      "[Epoch 55/100] [Batch 5] [loss: 0.316846] \n",
      "[Epoch 55/100] [Batch 6] [loss: 0.316929] \n",
      "[Epoch 55/100] [Batch 7] [loss: 0.316940] \n",
      "[Epoch 55/100] [Batch 8] [loss: 0.317382] \n",
      "[Epoch 56/100] [Batch 0] [loss: 0.317414] \n",
      "[Epoch 56/100] [Batch 1] [loss: 0.317063] \n",
      "[Epoch 56/100] [Batch 2] [loss: 0.316944] \n",
      "[Epoch 56/100] [Batch 3] [loss: 0.317502] \n",
      "[Epoch 56/100] [Batch 4] [loss: 0.317098] \n",
      "[Epoch 56/100] [Batch 5] [loss: 0.316794] \n",
      "[Epoch 56/100] [Batch 6] [loss: 0.316874] \n",
      "[Epoch 56/100] [Batch 7] [loss: 0.316885] \n",
      "[Epoch 56/100] [Batch 8] [loss: 0.317319] \n",
      "[Epoch 57/100] [Batch 0] [loss: 0.317349] \n",
      "[Epoch 57/100] [Batch 1] [loss: 0.317007] \n",
      "[Epoch 57/100] [Batch 2] [loss: 0.316890] \n",
      "[Epoch 57/100] [Batch 3] [loss: 0.317436] \n",
      "[Epoch 57/100] [Batch 4] [loss: 0.317040] \n",
      "[Epoch 57/100] [Batch 5] [loss: 0.316742] \n",
      "[Epoch 57/100] [Batch 6] [loss: 0.316820] \n",
      "[Epoch 57/100] [Batch 7] [loss: 0.316831] \n",
      "[Epoch 57/100] [Batch 8] [loss: 0.317257] \n",
      "[Epoch 58/100] [Batch 0] [loss: 0.317286] \n",
      "[Epoch 58/100] [Batch 1] [loss: 0.316952] \n",
      "[Epoch 58/100] [Batch 2] [loss: 0.316837] \n",
      "[Epoch 58/100] [Batch 3] [loss: 0.317371] \n",
      "[Epoch 58/100] [Batch 4] [loss: 0.316983] \n",
      "[Epoch 58/100] [Batch 5] [loss: 0.316692] \n",
      "[Epoch 58/100] [Batch 6] [loss: 0.316767] \n",
      "[Epoch 58/100] [Batch 7] [loss: 0.316779] \n",
      "[Epoch 58/100] [Batch 8] [loss: 0.317196] \n",
      "[Epoch 59/100] [Batch 0] [loss: 0.317225] \n",
      "[Epoch 59/100] [Batch 1] [loss: 0.316898] \n",
      "[Epoch 59/100] [Batch 2] [loss: 0.316785] \n",
      "[Epoch 59/100] [Batch 3] [loss: 0.317308] \n",
      "[Epoch 59/100] [Batch 4] [loss: 0.316927] \n",
      "[Epoch 59/100] [Batch 5] [loss: 0.316642] \n",
      "[Epoch 59/100] [Batch 6] [loss: 0.316715] \n",
      "[Epoch 59/100] [Batch 7] [loss: 0.316727] \n",
      "[Epoch 59/100] [Batch 8] [loss: 0.317137] \n",
      "[Epoch 60/100] [Batch 0] [loss: 0.317164] \n",
      "[Epoch 60/100] [Batch 1] [loss: 0.316846] \n",
      "[Epoch 60/100] [Batch 2] [loss: 0.316736] \n",
      "[Epoch 60/100] [Batch 3] [loss: 0.317248] \n",
      "[Epoch 60/100] [Batch 4] [loss: 0.316876] \n",
      "[Epoch 60/100] [Batch 5] [loss: 0.316599] \n",
      "[Epoch 60/100] [Batch 6] [loss: 0.316670] \n",
      "[Epoch 60/100] [Batch 7] [loss: 0.316685] \n",
      "[Epoch 60/100] [Batch 8] [loss: 0.317086] \n",
      "[Epoch 61/100] [Batch 0] [loss: 0.317117] \n",
      "[Epoch 61/100] [Batch 1] [loss: 0.316805] \n",
      "[Epoch 61/100] [Batch 2] [loss: 0.316696] \n",
      "[Epoch 61/100] [Batch 3] [loss: 0.317200] \n",
      "[Epoch 61/100] [Batch 4] [loss: 0.316833] \n",
      "[Epoch 61/100] [Batch 5] [loss: 0.316561] \n",
      "[Epoch 61/100] [Batch 6] [loss: 0.316630] \n",
      "[Epoch 61/100] [Batch 7] [loss: 0.316645] \n",
      "[Epoch 61/100] [Batch 8] [loss: 0.317040] \n",
      "[Epoch 62/100] [Batch 0] [loss: 0.317070] \n",
      "[Epoch 62/100] [Batch 1] [loss: 0.316764] \n",
      "[Epoch 62/100] [Batch 2] [loss: 0.316657] \n",
      "[Epoch 62/100] [Batch 3] [loss: 0.317152] \n",
      "[Epoch 62/100] [Batch 4] [loss: 0.316791] \n",
      "[Epoch 62/100] [Batch 5] [loss: 0.316523] \n",
      "[Epoch 62/100] [Batch 6] [loss: 0.316591] \n",
      "[Epoch 62/100] [Batch 7] [loss: 0.316606] \n",
      "[Epoch 62/100] [Batch 8] [loss: 0.316995] \n",
      "[Epoch 63/100] [Batch 0] [loss: 0.317024] \n",
      "[Epoch 63/100] [Batch 1] [loss: 0.316724] \n",
      "[Epoch 63/100] [Batch 2] [loss: 0.316618] \n",
      "[Epoch 63/100] [Batch 3] [loss: 0.317105] \n",
      "[Epoch 63/100] [Batch 4] [loss: 0.316749] \n",
      "[Epoch 63/100] [Batch 5] [loss: 0.316486] \n",
      "[Epoch 63/100] [Batch 6] [loss: 0.316553] \n",
      "[Epoch 63/100] [Batch 7] [loss: 0.316568] \n",
      "[Epoch 63/100] [Batch 8] [loss: 0.316951] \n",
      "[Epoch 64/100] [Batch 0] [loss: 0.316979] \n",
      "[Epoch 64/100] [Batch 1] [loss: 0.316684] \n",
      "[Epoch 64/100] [Batch 2] [loss: 0.316580] \n",
      "[Epoch 64/100] [Batch 3] [loss: 0.317058] \n",
      "[Epoch 64/100] [Batch 4] [loss: 0.316709] \n",
      "[Epoch 64/100] [Batch 5] [loss: 0.316450] \n",
      "[Epoch 64/100] [Batch 6] [loss: 0.316515] \n",
      "[Epoch 64/100] [Batch 7] [loss: 0.316530] \n",
      "[Epoch 64/100] [Batch 8] [loss: 0.316907] \n",
      "[Epoch 65/100] [Batch 0] [loss: 0.316935] \n",
      "[Epoch 65/100] [Batch 1] [loss: 0.316645] \n",
      "[Epoch 65/100] [Batch 2] [loss: 0.316542] \n",
      "[Epoch 65/100] [Batch 3] [loss: 0.317013] \n",
      "[Epoch 65/100] [Batch 4] [loss: 0.316668] \n",
      "[Epoch 65/100] [Batch 5] [loss: 0.316414] \n",
      "[Epoch 65/100] [Batch 6] [loss: 0.316477] \n",
      "[Epoch 65/100] [Batch 7] [loss: 0.316493] \n",
      "[Epoch 65/100] [Batch 8] [loss: 0.316864] \n",
      "[Epoch 66/100] [Batch 0] [loss: 0.316891] \n",
      "[Epoch 66/100] [Batch 1] [loss: 0.316606] \n",
      "[Epoch 66/100] [Batch 2] [loss: 0.316505] \n",
      "[Epoch 66/100] [Batch 3] [loss: 0.316968] \n",
      "[Epoch 66/100] [Batch 4] [loss: 0.316629] \n",
      "[Epoch 66/100] [Batch 5] [loss: 0.316378] \n",
      "[Epoch 66/100] [Batch 6] [loss: 0.316440] \n",
      "[Epoch 66/100] [Batch 7] [loss: 0.316456] \n",
      "[Epoch 66/100] [Batch 8] [loss: 0.316822] \n",
      "[Epoch 67/100] [Batch 0] [loss: 0.316848] \n",
      "[Epoch 67/100] [Batch 1] [loss: 0.316569] \n",
      "[Epoch 67/100] [Batch 2] [loss: 0.316469] \n",
      "[Epoch 67/100] [Batch 3] [loss: 0.316923] \n",
      "[Epoch 67/100] [Batch 4] [loss: 0.316590] \n",
      "[Epoch 67/100] [Batch 5] [loss: 0.316344] \n",
      "[Epoch 67/100] [Batch 6] [loss: 0.316404] \n",
      "[Epoch 67/100] [Batch 7] [loss: 0.316420] \n",
      "[Epoch 67/100] [Batch 8] [loss: 0.316780] \n",
      "[Epoch 68/100] [Batch 0] [loss: 0.316806] \n",
      "[Epoch 68/100] [Batch 1] [loss: 0.316531] \n",
      "[Epoch 68/100] [Batch 2] [loss: 0.316433] \n",
      "[Epoch 68/100] [Batch 3] [loss: 0.316880] \n",
      "[Epoch 68/100] [Batch 4] [loss: 0.316551] \n",
      "[Epoch 68/100] [Batch 5] [loss: 0.316309] \n",
      "[Epoch 68/100] [Batch 6] [loss: 0.316368] \n",
      "[Epoch 68/100] [Batch 7] [loss: 0.316384] \n",
      "[Epoch 68/100] [Batch 8] [loss: 0.316739] \n",
      "[Epoch 69/100] [Batch 0] [loss: 0.316764] \n",
      "[Epoch 69/100] [Batch 1] [loss: 0.316494] \n",
      "[Epoch 69/100] [Batch 2] [loss: 0.316397] \n",
      "[Epoch 69/100] [Batch 3] [loss: 0.316837] \n",
      "[Epoch 69/100] [Batch 4] [loss: 0.316513] \n",
      "[Epoch 69/100] [Batch 5] [loss: 0.316275] \n",
      "[Epoch 69/100] [Batch 6] [loss: 0.316333] \n",
      "[Epoch 69/100] [Batch 7] [loss: 0.316349] \n",
      "[Epoch 69/100] [Batch 8] [loss: 0.316699] \n",
      "[Epoch 70/100] [Batch 0] [loss: 0.316723] \n",
      "[Epoch 70/100] [Batch 1] [loss: 0.316459] \n",
      "[Epoch 70/100] [Batch 2] [loss: 0.316363] \n",
      "[Epoch 70/100] [Batch 3] [loss: 0.316796] \n",
      "[Epoch 70/100] [Batch 4] [loss: 0.316478] \n",
      "[Epoch 70/100] [Batch 5] [loss: 0.316245] \n",
      "[Epoch 70/100] [Batch 6] [loss: 0.316302] \n",
      "[Epoch 70/100] [Batch 7] [loss: 0.316319] \n",
      "[Epoch 70/100] [Batch 8] [loss: 0.316664] \n",
      "[Epoch 71/100] [Batch 0] [loss: 0.316691] \n",
      "[Epoch 71/100] [Batch 1] [loss: 0.316430] \n",
      "[Epoch 71/100] [Batch 2] [loss: 0.316335] \n",
      "[Epoch 71/100] [Batch 3] [loss: 0.316763] \n",
      "[Epoch 71/100] [Batch 4] [loss: 0.316449] \n",
      "[Epoch 71/100] [Batch 5] [loss: 0.316219] \n",
      "[Epoch 71/100] [Batch 6] [loss: 0.316275] \n",
      "[Epoch 71/100] [Batch 7] [loss: 0.316292] \n",
      "[Epoch 71/100] [Batch 8] [loss: 0.316633] \n",
      "[Epoch 72/100] [Batch 0] [loss: 0.316659] \n",
      "[Epoch 72/100] [Batch 1] [loss: 0.316402] \n",
      "[Epoch 72/100] [Batch 2] [loss: 0.316308] \n",
      "[Epoch 72/100] [Batch 3] [loss: 0.316730] \n",
      "[Epoch 72/100] [Batch 4] [loss: 0.316420] \n",
      "[Epoch 72/100] [Batch 5] [loss: 0.316193] \n",
      "[Epoch 72/100] [Batch 6] [loss: 0.316248] \n",
      "[Epoch 72/100] [Batch 7] [loss: 0.316265] \n",
      "[Epoch 72/100] [Batch 8] [loss: 0.316601] \n",
      "[Epoch 73/100] [Batch 0] [loss: 0.316627] \n",
      "[Epoch 73/100] [Batch 1] [loss: 0.316374] \n",
      "[Epoch 73/100] [Batch 2] [loss: 0.316281] \n",
      "[Epoch 73/100] [Batch 3] [loss: 0.316697] \n",
      "[Epoch 73/100] [Batch 4] [loss: 0.316391] \n",
      "[Epoch 73/100] [Batch 5] [loss: 0.316167] \n",
      "[Epoch 73/100] [Batch 6] [loss: 0.316221] \n",
      "[Epoch 73/100] [Batch 7] [loss: 0.316238] \n",
      "[Epoch 73/100] [Batch 8] [loss: 0.316571] \n",
      "[Epoch 74/100] [Batch 0] [loss: 0.316595] \n",
      "[Epoch 74/100] [Batch 1] [loss: 0.316346] \n",
      "[Epoch 74/100] [Batch 2] [loss: 0.316254] \n",
      "[Epoch 74/100] [Batch 3] [loss: 0.316665] \n",
      "[Epoch 74/100] [Batch 4] [loss: 0.316362] \n",
      "[Epoch 74/100] [Batch 5] [loss: 0.316141] \n",
      "[Epoch 74/100] [Batch 6] [loss: 0.316194] \n",
      "[Epoch 74/100] [Batch 7] [loss: 0.316211] \n",
      "[Epoch 74/100] [Batch 8] [loss: 0.316540] \n",
      "[Epoch 75/100] [Batch 0] [loss: 0.316564] \n",
      "[Epoch 75/100] [Batch 1] [loss: 0.316319] \n",
      "[Epoch 75/100] [Batch 2] [loss: 0.316228] \n",
      "[Epoch 75/100] [Batch 3] [loss: 0.316633] \n",
      "[Epoch 75/100] [Batch 4] [loss: 0.316334] \n",
      "[Epoch 75/100] [Batch 5] [loss: 0.316116] \n",
      "[Epoch 75/100] [Batch 6] [loss: 0.316168] \n",
      "[Epoch 75/100] [Batch 7] [loss: 0.316185] \n",
      "[Epoch 75/100] [Batch 8] [loss: 0.316510] \n",
      "[Epoch 76/100] [Batch 0] [loss: 0.316534] \n",
      "[Epoch 76/100] [Batch 1] [loss: 0.316291] \n",
      "[Epoch 76/100] [Batch 2] [loss: 0.316202] \n",
      "[Epoch 76/100] [Batch 3] [loss: 0.316602] \n",
      "[Epoch 76/100] [Batch 4] [loss: 0.316306] \n",
      "[Epoch 76/100] [Batch 5] [loss: 0.316091] \n",
      "[Epoch 76/100] [Batch 6] [loss: 0.316142] \n",
      "[Epoch 76/100] [Batch 7] [loss: 0.316159] \n",
      "[Epoch 76/100] [Batch 8] [loss: 0.316480] \n",
      "[Epoch 77/100] [Batch 0] [loss: 0.316504] \n",
      "[Epoch 77/100] [Batch 1] [loss: 0.316265] \n",
      "[Epoch 77/100] [Batch 2] [loss: 0.316176] \n",
      "[Epoch 77/100] [Batch 3] [loss: 0.316571] \n",
      "[Epoch 77/100] [Batch 4] [loss: 0.316278] \n",
      "[Epoch 77/100] [Batch 5] [loss: 0.316066] \n",
      "[Epoch 77/100] [Batch 6] [loss: 0.316116] \n",
      "[Epoch 77/100] [Batch 7] [loss: 0.316133] \n",
      "[Epoch 77/100] [Batch 8] [loss: 0.316451] \n",
      "[Epoch 78/100] [Batch 0] [loss: 0.316474] \n",
      "[Epoch 78/100] [Batch 1] [loss: 0.316238] \n",
      "[Epoch 78/100] [Batch 2] [loss: 0.316150] \n",
      "[Epoch 78/100] [Batch 3] [loss: 0.316540] \n",
      "[Epoch 78/100] [Batch 4] [loss: 0.316251] \n",
      "[Epoch 78/100] [Batch 5] [loss: 0.316042] \n",
      "[Epoch 78/100] [Batch 6] [loss: 0.316091] \n",
      "[Epoch 78/100] [Batch 7] [loss: 0.316108] \n",
      "[Epoch 78/100] [Batch 8] [loss: 0.316421] \n",
      "[Epoch 79/100] [Batch 0] [loss: 0.316444] \n",
      "[Epoch 79/100] [Batch 1] [loss: 0.316211] \n",
      "[Epoch 79/100] [Batch 2] [loss: 0.316125] \n",
      "[Epoch 79/100] [Batch 3] [loss: 0.316509] \n",
      "[Epoch 79/100] [Batch 4] [loss: 0.316224] \n",
      "[Epoch 79/100] [Batch 5] [loss: 0.316017] \n",
      "[Epoch 79/100] [Batch 6] [loss: 0.316065] \n",
      "[Epoch 79/100] [Batch 7] [loss: 0.316083] \n",
      "[Epoch 79/100] [Batch 8] [loss: 0.316393] \n",
      "[Epoch 80/100] [Batch 0] [loss: 0.316415] \n",
      "[Epoch 80/100] [Batch 1] [loss: 0.316186] \n",
      "[Epoch 80/100] [Batch 2] [loss: 0.316100] \n",
      "[Epoch 80/100] [Batch 3] [loss: 0.316480] \n",
      "[Epoch 80/100] [Batch 4] [loss: 0.316199] \n",
      "[Epoch 80/100] [Batch 5] [loss: 0.315996] \n",
      "[Epoch 80/100] [Batch 6] [loss: 0.316043] \n",
      "[Epoch 80/100] [Batch 7] [loss: 0.316061] \n",
      "[Epoch 80/100] [Batch 8] [loss: 0.316368] \n",
      "[Epoch 81/100] [Batch 0] [loss: 0.316391] \n",
      "[Epoch 81/100] [Batch 1] [loss: 0.316165] \n",
      "[Epoch 81/100] [Batch 2] [loss: 0.316080] \n",
      "[Epoch 81/100] [Batch 3] [loss: 0.316456] \n",
      "[Epoch 81/100] [Batch 4] [loss: 0.316178] \n",
      "[Epoch 81/100] [Batch 5] [loss: 0.315977] \n",
      "[Epoch 81/100] [Batch 6] [loss: 0.316023] \n",
      "[Epoch 81/100] [Batch 7] [loss: 0.316041] \n",
      "[Epoch 81/100] [Batch 8] [loss: 0.316345] \n",
      "[Epoch 82/100] [Batch 0] [loss: 0.316368] \n",
      "[Epoch 82/100] [Batch 1] [loss: 0.316145] \n",
      "[Epoch 82/100] [Batch 2] [loss: 0.316060] \n",
      "[Epoch 82/100] [Batch 3] [loss: 0.316433] \n",
      "[Epoch 82/100] [Batch 4] [loss: 0.316156] \n",
      "[Epoch 82/100] [Batch 5] [loss: 0.315958] \n",
      "[Epoch 82/100] [Batch 6] [loss: 0.316004] \n",
      "[Epoch 82/100] [Batch 7] [loss: 0.316022] \n",
      "[Epoch 82/100] [Batch 8] [loss: 0.316323] \n",
      "[Epoch 83/100] [Batch 0] [loss: 0.316345] \n",
      "[Epoch 83/100] [Batch 1] [loss: 0.316124] \n",
      "[Epoch 83/100] [Batch 2] [loss: 0.316041] \n",
      "[Epoch 83/100] [Batch 3] [loss: 0.316409] \n",
      "[Epoch 83/100] [Batch 4] [loss: 0.316136] \n",
      "[Epoch 83/100] [Batch 5] [loss: 0.315939] \n",
      "[Epoch 83/100] [Batch 6] [loss: 0.315984] \n",
      "[Epoch 83/100] [Batch 7] [loss: 0.316002] \n",
      "[Epoch 83/100] [Batch 8] [loss: 0.316300] \n",
      "[Epoch 84/100] [Batch 0] [loss: 0.316323] \n",
      "[Epoch 84/100] [Batch 1] [loss: 0.316104] \n",
      "[Epoch 84/100] [Batch 2] [loss: 0.316021] \n",
      "[Epoch 84/100] [Batch 3] [loss: 0.316386] \n",
      "[Epoch 84/100] [Batch 4] [loss: 0.316115] \n",
      "[Epoch 84/100] [Batch 5] [loss: 0.315920] \n",
      "[Epoch 84/100] [Batch 6] [loss: 0.315965] \n",
      "[Epoch 84/100] [Batch 7] [loss: 0.315983] \n",
      "[Epoch 84/100] [Batch 8] [loss: 0.316278] \n",
      "[Epoch 85/100] [Batch 0] [loss: 0.316300] \n",
      "[Epoch 85/100] [Batch 1] [loss: 0.316084] \n",
      "[Epoch 85/100] [Batch 2] [loss: 0.316002] \n",
      "[Epoch 85/100] [Batch 3] [loss: 0.316363] \n",
      "[Epoch 85/100] [Batch 4] [loss: 0.316094] \n",
      "[Epoch 85/100] [Batch 5] [loss: 0.315902] \n",
      "[Epoch 85/100] [Batch 6] [loss: 0.315946] \n",
      "[Epoch 85/100] [Batch 7] [loss: 0.315964] \n",
      "[Epoch 85/100] [Batch 8] [loss: 0.316256] \n",
      "[Epoch 86/100] [Batch 0] [loss: 0.316278] \n",
      "[Epoch 86/100] [Batch 1] [loss: 0.316064] \n",
      "[Epoch 86/100] [Batch 2] [loss: 0.315983] \n",
      "[Epoch 86/100] [Batch 3] [loss: 0.316340] \n",
      "[Epoch 86/100] [Batch 4] [loss: 0.316074] \n",
      "[Epoch 86/100] [Batch 5] [loss: 0.315883] \n",
      "[Epoch 86/100] [Batch 6] [loss: 0.315927] \n",
      "[Epoch 86/100] [Batch 7] [loss: 0.315944] \n",
      "[Epoch 86/100] [Batch 8] [loss: 0.316234] \n",
      "[Epoch 87/100] [Batch 0] [loss: 0.316256] \n",
      "[Epoch 87/100] [Batch 1] [loss: 0.316044] \n",
      "[Epoch 87/100] [Batch 2] [loss: 0.315964] \n",
      "[Epoch 87/100] [Batch 3] [loss: 0.316317] \n",
      "[Epoch 87/100] [Batch 4] [loss: 0.316053] \n",
      "[Epoch 87/100] [Batch 5] [loss: 0.315865] \n",
      "[Epoch 87/100] [Batch 6] [loss: 0.315908] \n",
      "[Epoch 87/100] [Batch 7] [loss: 0.315926] \n",
      "[Epoch 87/100] [Batch 8] [loss: 0.316213] \n",
      "[Epoch 88/100] [Batch 0] [loss: 0.316234] \n",
      "[Epoch 88/100] [Batch 1] [loss: 0.316025] \n",
      "[Epoch 88/100] [Batch 2] [loss: 0.315945] \n",
      "[Epoch 88/100] [Batch 3] [loss: 0.316294] \n",
      "[Epoch 88/100] [Batch 4] [loss: 0.316033] \n",
      "[Epoch 88/100] [Batch 5] [loss: 0.315847] \n",
      "[Epoch 88/100] [Batch 6] [loss: 0.315889] \n",
      "[Epoch 88/100] [Batch 7] [loss: 0.315907] \n",
      "[Epoch 88/100] [Batch 8] [loss: 0.316191] \n",
      "[Epoch 89/100] [Batch 0] [loss: 0.316212] \n",
      "[Epoch 89/100] [Batch 1] [loss: 0.316005] \n",
      "[Epoch 89/100] [Batch 2] [loss: 0.315926] \n",
      "[Epoch 89/100] [Batch 3] [loss: 0.316271] \n",
      "[Epoch 89/100] [Batch 4] [loss: 0.316013] \n",
      "[Epoch 89/100] [Batch 5] [loss: 0.315829] \n",
      "[Epoch 89/100] [Batch 6] [loss: 0.315870] \n",
      "[Epoch 89/100] [Batch 7] [loss: 0.315888] \n",
      "[Epoch 89/100] [Batch 8] [loss: 0.316170] \n",
      "[Epoch 90/100] [Batch 0] [loss: 0.316190] \n",
      "[Epoch 90/100] [Batch 1] [loss: 0.315986] \n",
      "[Epoch 90/100] [Batch 2] [loss: 0.315908] \n",
      "[Epoch 90/100] [Batch 3] [loss: 0.316250] \n",
      "[Epoch 90/100] [Batch 4] [loss: 0.315995] \n",
      "[Epoch 90/100] [Batch 5] [loss: 0.315813] \n",
      "[Epoch 90/100] [Batch 6] [loss: 0.315854] \n",
      "[Epoch 90/100] [Batch 7] [loss: 0.315872] \n",
      "[Epoch 90/100] [Batch 8] [loss: 0.316152] \n",
      "[Epoch 91/100] [Batch 0] [loss: 0.316173] \n",
      "[Epoch 91/100] [Batch 1] [loss: 0.315971] \n",
      "[Epoch 91/100] [Batch 2] [loss: 0.315893] \n",
      "[Epoch 91/100] [Batch 3] [loss: 0.316232] \n",
      "[Epoch 91/100] [Batch 4] [loss: 0.315979] \n",
      "[Epoch 91/100] [Batch 5] [loss: 0.315798] \n",
      "[Epoch 91/100] [Batch 6] [loss: 0.315839] \n",
      "[Epoch 91/100] [Batch 7] [loss: 0.315857] \n",
      "[Epoch 91/100] [Batch 8] [loss: 0.316135] \n",
      "[Epoch 92/100] [Batch 0] [loss: 0.316156] \n",
      "[Epoch 92/100] [Batch 1] [loss: 0.315955] \n",
      "[Epoch 92/100] [Batch 2] [loss: 0.315878] \n",
      "[Epoch 92/100] [Batch 3] [loss: 0.316215] \n",
      "[Epoch 92/100] [Batch 4] [loss: 0.315963] \n",
      "[Epoch 92/100] [Batch 5] [loss: 0.315784] \n",
      "[Epoch 92/100] [Batch 6] [loss: 0.315824] \n",
      "[Epoch 92/100] [Batch 7] [loss: 0.315843] \n",
      "[Epoch 92/100] [Batch 8] [loss: 0.316118] \n",
      "[Epoch 93/100] [Batch 0] [loss: 0.316139] \n",
      "[Epoch 93/100] [Batch 1] [loss: 0.315940] \n",
      "[Epoch 93/100] [Batch 2] [loss: 0.315863] \n",
      "[Epoch 93/100] [Batch 3] [loss: 0.316197] \n",
      "[Epoch 93/100] [Batch 4] [loss: 0.315948] \n",
      "[Epoch 93/100] [Batch 5] [loss: 0.315770] \n",
      "[Epoch 93/100] [Batch 6] [loss: 0.315810] \n",
      "[Epoch 93/100] [Batch 7] [loss: 0.315828] \n",
      "[Epoch 93/100] [Batch 8] [loss: 0.316101] \n",
      "[Epoch 94/100] [Batch 0] [loss: 0.316122] \n",
      "[Epoch 94/100] [Batch 1] [loss: 0.315925] \n",
      "[Epoch 94/100] [Batch 2] [loss: 0.315849] \n",
      "[Epoch 94/100] [Batch 3] [loss: 0.316180] \n",
      "[Epoch 94/100] [Batch 4] [loss: 0.315932] \n",
      "[Epoch 94/100] [Batch 5] [loss: 0.315756] \n",
      "[Epoch 94/100] [Batch 6] [loss: 0.315795] \n",
      "[Epoch 94/100] [Batch 7] [loss: 0.315813] \n",
      "[Epoch 94/100] [Batch 8] [loss: 0.316085] \n",
      "[Epoch 95/100] [Batch 0] [loss: 0.316105] \n",
      "[Epoch 95/100] [Batch 1] [loss: 0.315910] \n",
      "[Epoch 95/100] [Batch 2] [loss: 0.315834] \n",
      "[Epoch 95/100] [Batch 3] [loss: 0.316162] \n",
      "[Epoch 95/100] [Batch 4] [loss: 0.315916] \n",
      "[Epoch 95/100] [Batch 5] [loss: 0.315742] \n",
      "[Epoch 95/100] [Batch 6] [loss: 0.315781] \n",
      "[Epoch 95/100] [Batch 7] [loss: 0.315799] \n",
      "[Epoch 95/100] [Batch 8] [loss: 0.316068] \n",
      "[Epoch 96/100] [Batch 0] [loss: 0.316088] \n",
      "[Epoch 96/100] [Batch 1] [loss: 0.315895] \n",
      "[Epoch 96/100] [Batch 2] [loss: 0.315819] \n",
      "[Epoch 96/100] [Batch 3] [loss: 0.316145] \n",
      "[Epoch 96/100] [Batch 4] [loss: 0.315901] \n",
      "[Epoch 96/100] [Batch 5] [loss: 0.315728] \n",
      "[Epoch 96/100] [Batch 6] [loss: 0.315766] \n",
      "[Epoch 96/100] [Batch 7] [loss: 0.315784] \n",
      "[Epoch 96/100] [Batch 8] [loss: 0.316052] \n",
      "[Epoch 97/100] [Batch 0] [loss: 0.316071] \n",
      "[Epoch 97/100] [Batch 1] [loss: 0.315880] \n",
      "[Epoch 97/100] [Batch 2] [loss: 0.315805] \n",
      "[Epoch 97/100] [Batch 3] [loss: 0.316128] \n",
      "[Epoch 97/100] [Batch 4] [loss: 0.315886] \n",
      "[Epoch 97/100] [Batch 5] [loss: 0.315714] \n",
      "[Epoch 97/100] [Batch 6] [loss: 0.315752] \n",
      "[Epoch 97/100] [Batch 7] [loss: 0.315770] \n",
      "[Epoch 97/100] [Batch 8] [loss: 0.316035] \n",
      "[Epoch 98/100] [Batch 0] [loss: 0.316054] \n",
      "[Epoch 98/100] [Batch 1] [loss: 0.315865] \n",
      "[Epoch 98/100] [Batch 2] [loss: 0.315791] \n",
      "[Epoch 98/100] [Batch 3] [loss: 0.316111] \n",
      "[Epoch 98/100] [Batch 4] [loss: 0.315870] \n",
      "[Epoch 98/100] [Batch 5] [loss: 0.315701] \n",
      "[Epoch 98/100] [Batch 6] [loss: 0.315738] \n",
      "[Epoch 98/100] [Batch 7] [loss: 0.315756] \n",
      "[Epoch 98/100] [Batch 8] [loss: 0.316019] \n",
      "[Epoch 99/100] [Batch 0] [loss: 0.316038] \n",
      "[Epoch 99/100] [Batch 1] [loss: 0.315850] \n",
      "[Epoch 99/100] [Batch 2] [loss: 0.315776] \n",
      "[Epoch 99/100] [Batch 3] [loss: 0.316094] \n",
      "[Epoch 99/100] [Batch 4] [loss: 0.315855] \n",
      "[Epoch 99/100] [Batch 5] [loss: 0.315687] \n",
      "[Epoch 99/100] [Batch 6] [loss: 0.315724] \n",
      "[Epoch 99/100] [Batch 7] [loss: 0.315742] \n",
      "[Epoch 99/100] [Batch 8] [loss: 0.316003] \n",
      "[0.5, 0.5, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "acc_vec = []\n",
    "train_vec = []\n",
    "loss_vec = []\n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(0, 9):\n",
    "            fmri_data = train_fmri[i*batch_size:(i+1) * batch_size]\n",
    "            labels_data = train_labels[i*batch_size:(i+1) * batch_size]\n",
    "            labels_data = labels_data.long()\n",
    "            optimizer.zero_grad()\n",
    "            predict = semanticDecoder(fmri_data)\n",
    "            loss = loss_function(predict, labels_data)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_vec.append(loss.item())\n",
    "            print(\n",
    "                \"[Epoch %d/%d] [Batch %d] [loss: %f] \"\n",
    "                % (epoch, n_epochs, i, loss.item())\n",
    "            )\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "            test_fmri_data = test_fmri\n",
    "            test_label_data = test_labels.cpu().detach().numpy()\n",
    "            lbs = semanticDecoder(test_fmri_data)\n",
    "            cpu_labels = lbs.cpu().detach().numpy()\n",
    "            pred = [np.argmax(lb) for lb in cpu_labels]\n",
    "            num_correct = (pred == test_label_data).sum()\n",
    "            acc = num_correct / 10\n",
    "            acc_vec.append(acc)\n",
    "\n",
    "\n",
    "    scheduler.step()\n",
    "    lrd = optimizer.param_groups[0]['lr']\n",
    "\n",
    "print(acc_vec)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.title('Loss of classification task - 2 class digits')\n",
    "plt.plot(loss_vec)\n",
    "plt.xlabel('Epoch num')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

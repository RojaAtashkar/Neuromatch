{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Import Libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load the dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3092)\n",
      "(100, 1)\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "fmri_dataset = torch.load('data/fMRI_data/demo1/digits-fmri')\n",
    "# load the labels\n",
    "labels = torch.load('data/images/demo1/raw_imgs/digits-labels') - 1\n",
    "# print the shape\n",
    "print(fmri_dataset.shape)\n",
    "print(labels.shape)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total blocks : 100\n",
      "input fmri size : 3092\n"
     ]
    }
   ],
   "source": [
    "total_blocks = fmri_dataset.shape[0]\n",
    "fmri_size = fmri_dataset.shape[1]\n",
    "print('total blocks : '+str(total_blocks))\n",
    "print('input fmri size : '+str(fmri_size))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 10\n",
    "test_size = 10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "# define the model\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "  \"\"\"\n",
    "  Initialize MLP Network\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, actv, input_feature_num, hidden_unit_nums, output_feature_num):\n",
    "    \"\"\"\n",
    "    Initialize MLP Network parameters\n",
    "\n",
    "    Args:\n",
    "      actv: string\n",
    "        Activation function\n",
    "      input_feature_num: int\n",
    "        Number of input features\n",
    "      hidden_unit_nums: list\n",
    "        Number of units in the hidden layer\n",
    "      output_feature_num: int\n",
    "        Number of output features\n",
    "\n",
    "    Returns:\n",
    "      Nothing\n",
    "    \"\"\"\n",
    "    super(Net, self).__init__()\n",
    "    self.input_feature_num = input_feature_num # Save the input size for reshaping later\n",
    "    self.model = nn.Sequential() # Initialize layers of MLP\n",
    "\n",
    "    in_num = input_feature_num # Initialize the temporary input feature to each layer\n",
    "    for i in range(len(hidden_unit_nums)): # Loop over layers and create each one\n",
    "\n",
    "      out_num = hidden_unit_nums[i] # Assign the current layer hidden unit from list\n",
    "      layer = nn.Linear(in_num, out_num) # Use nn.Linear to define the layer\n",
    "\n",
    "      in_num = out_num # Assign next layer input using current layer output\n",
    "      self.model.add_module('Linear_%d'%i, layer) # Append layer to the model with a name\n",
    "\n",
    "      actv_layer = eval('nn.%s'%actv) # Assign activation function (eval allows us to instantiate object from string)\n",
    "      self.model.add_module('Activation_%d'%i, actv_layer) # Append activation to the model with a name\n",
    "\n",
    "    out_layer = nn.Linear(in_num, output_feature_num) # Create final layer\n",
    "    self.model.add_module('Output_Linear', out_layer) # Append the final layer\n",
    "\n",
    "  def forward(self, x):\n",
    "    \"\"\"\n",
    "    Simulate forward pass of MLP Network\n",
    "\n",
    "    Args:\n",
    "      x: torch.tensor\n",
    "        Input data\n",
    "\n",
    "    Returns:\n",
    "      logits: Instance of MLP\n",
    "        Forward pass of MLP\n",
    "    \"\"\"\n",
    "    # Reshape inputs to (batch_size, input_feature_num)\n",
    "    # Just in case the input vector is not 2D, like an image!\n",
    "    x = x.view(x.shape[0], -1)\n",
    "    logits = self.model(x) # Forward pass of MLP\n",
    "    return logits\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "hidden_layers_shape = [1024, 64]\n",
    "activation = 'Tanh()'\n",
    "net = Net(actv=activation, input_feature_num=fmri_size, hidden_unit_nums=hidden_layers_shape, output_feature_num=2)\n",
    "# y = net()\n",
    "# print(f'The output shape is {y.shape} for an input of shape {fmri_size.shape}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[-0.0009, -0.1368],\n        [-0.0017, -0.1358],\n        [-0.0039, -0.1356],\n        [-0.0193, -0.1315],\n        [-0.0122, -0.1353],\n        [-0.0062, -0.1308],\n        [-0.0084, -0.1273],\n        [-0.0122, -0.1331],\n        [-0.0091, -0.1342],\n        [-0.0075, -0.1321],\n        [-0.0110, -0.1288],\n        [-0.0114, -0.1314],\n        [-0.0102, -0.1326],\n        [-0.0132, -0.1323],\n        [-0.0139, -0.1305],\n        [-0.0068, -0.1322],\n        [-0.0108, -0.1373],\n        [-0.0033, -0.1332],\n        [-0.0056, -0.1255],\n        [-0.0009, -0.1313],\n        [-0.0084, -0.1315],\n        [-0.0042, -0.1268],\n        [-0.0097, -0.1282],\n        [-0.0134, -0.1256],\n        [-0.0166, -0.1348],\n        [-0.0085, -0.1321],\n        [-0.0129, -0.1314],\n        [-0.0121, -0.1336],\n        [-0.0096, -0.1286],\n        [-0.0138, -0.1320],\n        [-0.0124, -0.1308],\n        [-0.0116, -0.1308],\n        [-0.0149, -0.1305],\n        [-0.0074, -0.1287],\n        [-0.0096, -0.1276],\n        [-0.0076, -0.1338],\n        [-0.0105, -0.1261],\n        [-0.0105, -0.1316],\n        [-0.0155, -0.1300],\n        [-0.0066, -0.1282],\n        [-0.0080, -0.1296],\n        [-0.0111, -0.1337],\n        [-0.0075, -0.1288],\n        [-0.0152, -0.1291],\n        [-0.0057, -0.1317],\n        [-0.0155, -0.1283],\n        [-0.0056, -0.1285],\n        [-0.0090, -0.1260],\n        [-0.0079, -0.1315],\n        [-0.0097, -0.1331],\n        [-0.0027, -0.1371],\n        [-0.0041, -0.1313],\n        [-0.0096, -0.1257],\n        [-0.0107, -0.1286],\n        [-0.0040, -0.1342],\n        [-0.0063, -0.1327],\n        [-0.0108, -0.1350],\n        [-0.0106, -0.1337],\n        [-0.0073, -0.1299],\n        [-0.0115, -0.1294],\n        [-0.0123, -0.1267],\n        [-0.0083, -0.1282],\n        [-0.0095, -0.1304],\n        [-0.0079, -0.1313],\n        [-0.0094, -0.1258],\n        [-0.0089, -0.1272],\n        [-0.0114, -0.1327],\n        [-0.0152, -0.1314],\n        [-0.0126, -0.1294],\n        [-0.0103, -0.1352],\n        [-0.0109, -0.1338],\n        [-0.0156, -0.1341],\n        [-0.0174, -0.1303],\n        [-0.0140, -0.1264],\n        [-0.0101, -0.1277],\n        [-0.0083, -0.1257],\n        [-0.0110, -0.1314],\n        [-0.0132, -0.1288],\n        [-0.0147, -0.1252],\n        [-0.0079, -0.1325],\n        [-0.0107, -0.1315],\n        [-0.0098, -0.1315],\n        [-0.0117, -0.1338],\n        [-0.0122, -0.1275],\n        [-0.0079, -0.1265],\n        [-0.0085, -0.1332],\n        [-0.0157, -0.1329],\n        [-0.0104, -0.1341],\n        [-0.0128, -0.1345],\n        [-0.0107, -0.1347],\n        [-0.0133, -0.1327],\n        [-0.0103, -0.1308],\n        [-0.0139, -0.1317],\n        [-0.0115, -0.1292],\n        [-0.0090, -0.1319],\n        [-0.0080, -0.1269],\n        [-0.0077, -0.1320],\n        [-0.0108, -0.1290],\n        [-0.0102, -0.1316],\n        [-0.0111, -0.1322]], grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda = True if torch.cuda.is_available() else False\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "fmri = torch.from_numpy(fmri_dataset)\n",
    "fmri = fmri.type(Tensor)\n",
    "print(type(fmri_dataset))\n",
    "net.forward(fmri)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
